<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>AI on Notes from the digital underground by Lngnmn</title>
    <link>https://lngnmn2.github.io/categories/ai/</link>
    <description>Recent content in AI on Notes from the digital underground by Lngnmn</description>
    <generator>Hugo -- 0.131.0</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 27 Jan 2025 11:13:51 +0545</lastBuildDate>
    <atom:link href="https://lngnmn2.github.io/categories/ai/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Deepseek R1</title>
      <link>https://lngnmn2.github.io/articles/deepseek-r1/</link>
      <pubDate>Sun, 26 Jan 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/deepseek-r1/</guid>
      <description>DESCRIPTION: Memes and mirrors.
Nowadays things are moving way too fast. It is not just controlled trial-and-error, it is literally throwing everything at the wall (to see what sticks).
It started with that meme &amp;ldquo;Attention Is All You Need&amp;rdquo;, when they just came up with an &amp;ldquo;architecture&amp;rdquo; that sticks.
That &amp;ldquo;attention&amp;rdquo; and &amp;ldquo;multi head attention&amp;rdquo; turned out to be just a few additional layers of a particular kind.
No one can explain the actual mechanisms of how exactly or even why the layers are as they are (abstract bullshit aside).</description>
    </item>
    <item>
      <title>LLMs und AI</title>
      <link>https://lngnmn2.github.io/articles/llms-und-ai/</link>
      <pubDate>Wed, 20 Nov 2024 16:53:58 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/llms-und-ai/</guid>
      <description>DATE: &amp;lt;2024-11-20 Wed&amp;gt;
Lets write a few paragraphs which will destroy the current LLM narrative (naive bullshit), while neither any single piece nor the whole article can be refuted.
This is a high-level proper (classic Eastern) philosophy, which is many levels away from simple logical forms, but it still can be reduced to these, if one wants to. The Proper Philosophy isn&amp;rsquo;t dead, not even it is dying. It cannot, lmao.</description>
    </item>
    <item>
      <title>Attention Is All bullshit.</title>
      <link>https://lngnmn2.github.io/articles/attention-is-all-bullshit/</link>
      <pubDate>Tue, 04 Jun 2024 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/attention-is-all-bullshit/</guid>
      <description>To see things as they really are.</description>
    </item>
    <item>
      <title>LLM Philosophy 101</title>
      <link>https://lngnmn2.github.io/articles/llm-phil-101/</link>
      <pubDate>Tue, 21 May 2024 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/llm-phil-101/</guid>
      <description>Bullshit, bullshit, bullshit... (K-PAX)</description>
    </item>
    <item>
      <title>Late to the party.</title>
      <link>https://lngnmn2.github.io/articles/late/</link>
      <pubDate>Mon, 27 Nov 2023 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/late/</guid>
      <description>This is sort of an answer to this question.
https://news.ycombinator.com/item?id=38425475
So, what if you are late to the party?
Unfortunately, nowadays it is even much harder to get through all the utter bullshit and hype, but there is a sort of a shortcut or &amp;ldquo;the Hard Way&amp;rdquo;.
There are two and a half key figures: Geoffrey Hinton, who did most of the mathematical heavy lifting, Andrew Ng, who not just did all the derivations, but became the most famous practitioner, and Andrej Karpathy who us just a narcissistic asshole, similar to Lex Friedman.</description>
    </item>
    <item>
      <title>Selfawareness</title>
      <link>https://lngnmn2.github.io/articles/selfawareness/</link>
      <pubDate>Mon, 20 Nov 2023 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/selfawareness/</guid>
      <description>Abstract bullshitting is not enough.</description>
    </item>
    <item>
      <title>A small step towards GAI</title>
      <link>https://lngnmn2.github.io/articles/look-ma-no-i/</link>
      <pubDate>Sat, 21 Oct 2023 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/look-ma-no-i/</guid>
      <description>DESCRIPTION: There is no &amp;ldquo;I&amp;rdquo; in your AI.
Lets put all the memes and bullshit aside, for a moment and talk serously about GAI (hello, mr. Carmack, sir).
There is what every &amp;ldquo;AI researcher&amp;rdquo; should know about Knowledge and Intelligence (yes, both capitalized).
There is so-called &amp;ldquo;reality&amp;rdquo; prior to any knowledge or intelligence. Any reasonable thinker has been arrived at the ultimate reality.
&amp;ldquo;I am That&amp;rdquo; (&amp;ldquo;That Thou Art&amp;rdquo;) of Chandogya Upanishad is the &amp;ldquo;end of knowledge&amp;rdquo; and the &amp;ldquo;arrival&amp;rdquo; to the ultimate &amp;ldquo;truth&amp;rdquo;, with implies existence of &amp;ldquo;That&amp;rdquo; and one being just a sub-process (a wave) in It.</description>
    </item>
    <item>
      <title>LLMS For Coding</title>
      <link>https://lngnmn2.github.io/articles/llms-for-coding/</link>
      <pubDate>Sat, 26 Aug 2023 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/llms-for-coding/</guid>
      <description>Today https://news.ycombinator.com/ is glowing bright with AI memes and buzzwords like a Christmas tree. Everyone is there, including billion dollar corporations announcing a &amp;ldquo;CodeLama-34b&amp;rdquo; which is &amp;ldquo;designed for general code synthesis and understanding.&amp;rdquo;
First of all, I personaly do not want to rely in any part of my life on any &amp;ldquo;synthesized&amp;rdquo; (and &amp;ldquo;understood&amp;rdquo; software, and demand an explicit opt-out. Yes, yes, I know.
If I have any understanding of these subjects at all, this is a bubble and irrational exuberance.</description>
    </item>
    <item>
      <title>GNU Emacs</title>
      <link>https://lngnmn2.github.io/articles/llm-predictions/</link>
      <pubDate>Fri, 28 Jul 2023 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/llm-predictions/</guid>
      <description>  The monument and a world-heritage &amp;#34;site&amp;#34;.
  </description>
    </item>
  </channel>
</rss>
