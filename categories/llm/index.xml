<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>LLM on Notes from the digital underground by Lngnmn</title>
    <link>https://lngnmn2.github.io/categories/llm/</link>
    <description>Recent content in LLM on Notes from the digital underground by Lngnmn</description>
    <generator>Hugo -- 0.147.7</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 08 Sep 2025 11:47:25 +0545</lastBuildDate>
    <atom:link href="https://lngnmn2.github.io/categories/llm/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>LLM (and Math) Philosophy 202</title>
      <link>https://lngnmn2.github.io/articles/llm-and-math-phil-202/</link>
      <pubDate>Mon, 08 Sep 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/llm-and-math-phil-202/</guid>
      <description>&lt;p&gt;DESCRIPTION: Idiots, idiots everywhere.jpg&lt;/p&gt;
&lt;p&gt;I am getting old and my cognitive abilities are slowly declining, and I will have no pension or social security, so I need a &amp;ldquo;Turing Award&amp;rdquo; or something. (only partially kidding).  And, yes, I &amp;ldquo;hacked&amp;rdquo; these &amp;ldquo;longevity&amp;rdquo; memes and &amp;ldquo;protocols&amp;rdquo;, but seems like fighting an increase in entropy and the second law of thermodynamics is not that efficient as some meme-guys claim on YouTube ).&lt;/p&gt;
&lt;p&gt;So, lets settle one fundamental meme-question once and for all, so we can let it all go and focus on &amp;ldquo;bio-hacking&amp;rdquo; and what not.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Humanties in 30 seconds</title>
      <link>https://lngnmn2.github.io/articles/humanties-in-30-seconds/</link>
      <pubDate>Mon, 25 Aug 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/humanties-in-30-seconds/</guid>
      <description>&lt;p&gt;So-called &lt;em&gt;Humanties&lt;/em&gt; (as the way of  producing a sectarian socially constructed pretentious abstract verbiage) are done for. At least none of them deserve that high upper-middle-class social status anymore.&lt;/p&gt;
&lt;p&gt;Yes, you have to be &lt;em&gt;actually smart&lt;/em&gt; to ask the &amp;ldquo;right questions&amp;rdquo; (be a prompt &lt;em&gt;engineers&lt;/em&gt; LMAO!), but still. Watch how it spews out an outstanding &amp;ldquo;paper&amp;rdquo; in 30 seconds.&lt;/p&gt;
&lt;p&gt;I really don&amp;rsquo;t know what I have studied (wasted my life) for. Yes, yes, these are not &lt;em&gt;final&lt;/em&gt; answers, and it missed subtleties, and more accurate, insightful formulations, but who needs them anymore?&lt;/p&gt;</description>
    </item>
    <item>
      <title>LLMs-generated Rust code</title>
      <link>https://lngnmn2.github.io/articles/llms-generated-rust/</link>
      <pubDate>Wed, 25 Jun 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/llms-generated-rust/</guid>
      <description>The ultimate evidence of the principal inability for a probability-based generating algorithm to come up with something that passes the type checker.</description>
    </item>
    <item>
      <title>Just a Packaged Slop</title>
      <link>https://lngnmn2.github.io/articles/just-a-packaged-slop/</link>
      <pubDate>Wed, 30 Apr 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/just-a-packaged-slop/</guid>
      <description>&lt;p&gt;DESCRIPTION: Removing the veil of Maya to see things as they really are&lt;/p&gt;
&lt;p&gt;What to do when you have discovered that something is wrong with the world? Nothing, this happens all the time.&lt;/p&gt;
&lt;p&gt;Everything is wrong with C++, but everyone uses it, everything is wrong with packaged food, especially the toxic crap Nestle produced, and everyone is buying it. Nothing can be done.&lt;/p&gt;
&lt;p&gt;Here is what is wrong with your &amp;ldquo;AI&amp;rdquo; and &amp;ldquo;LLMs&amp;rdquo;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Large Ladyboy Models</title>
      <link>https://lngnmn2.github.io/articles/large-ladyboy-models/</link>
      <pubDate>Sun, 09 Mar 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/large-ladyboy-models/</guid>
      <description>&lt;p&gt;Classy Andrej is making shilling videos from Thailand (he leaked his location in the video ) targeting normies (the previous set of videos has been partially filmed in Japan. Andrej is living a truly digital nomad&amp;rsquo;s life).&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=EWvNQjAaOHw&#34;&gt;https://www.youtube.com/watch?v=EWvNQjAaOHw&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Why would he shill? Well, he and guys like him made a lot of promises, not to us (who tf cares), but to the money guys, that this particular technology will completely transform the world, and that &lt;em&gt;they&lt;/em&gt; are the very top guys in the field, so money shall be given to them (to the affiliated companies and entities).&lt;/p&gt;</description>
    </item>
    <item>
      <title>Coding with LLMs</title>
      <link>https://lngnmn2.github.io/articles/llm-coding/</link>
      <pubDate>Mon, 24 Feb 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/llm-coding/</guid>
      <description>&lt;p&gt;DESCRIPTION: Idiots, idiots everywhere.&lt;/p&gt;
&lt;p&gt;Now I can accurately summarize what coding using LLMs &lt;em&gt;actually /is&lt;/em&gt; in just a few sentences.&lt;/p&gt;
&lt;p&gt;Recall how people usually describe a code maintenance job: &lt;em&gt;we have this code to run, while the original developers are gone and leave us no design documentation&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;This hypothetical situation is exactly what you get when an LLM finished spewing out the slop: you now have some code, very cheap, even for free, but it is &lt;em&gt;not yours&lt;/em&gt;, the underlying understanding (of the whys) &lt;em&gt;is not in your head&lt;/em&gt;, and the original developer is already gone. Disappeared.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Grok3</title>
      <link>https://lngnmn2.github.io/articles/grok3/</link>
      <pubDate>Tue, 18 Feb 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/grok3/</guid>
      <description>Smoke and memes.</description>
    </item>
    <item>
      <title>AI Slop</title>
      <link>https://lngnmn2.github.io/articles/ai-slop/</link>
      <pubDate>Sun, 16 Feb 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/ai-slop/</guid>
      <description>&lt;p&gt;&lt;strong&gt;slop&lt;/strong&gt; &lt;em&gt;noun&lt;/em&gt;&lt;/p&gt;
&lt;h4 id=&#34;cambridge-dictionary&#34;&gt;Cambridge dictionary&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;food that is more liquid than it should be and is therefore unpleasant&lt;/li&gt;
&lt;li&gt;liquid or wet food waste, especially when it is fed to animals&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;oxford-learner-s-dictionary&#34;&gt;Oxford Learner&amp;rsquo;s Dictionary&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;â€‹waste food, sometimes fed to animals&lt;/li&gt;
&lt;li&gt;liquid or partly liquid waste, for example urine or dirty water from baths&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;There is also a very related term &amp;ldquo;&lt;em&gt;goyslop&lt;/em&gt;&amp;rdquo; from internet sewers (losers are always looking for someone to blame and hate [instead of themselves]).&lt;/p&gt;</description>
    </item>
    <item>
      <title>Deepseek In Action</title>
      <link>https://lngnmn2.github.io/articles/deepseek-in-action/</link>
      <pubDate>Sat, 15 Feb 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/deepseek-in-action/</guid>
      <description>Look, ma, no reasoning.</description>
    </item>
    <item>
      <title>Reasoning LLMs</title>
      <link>https://lngnmn2.github.io/articles/reasoning-llms/</link>
      <pubDate>Tue, 11 Feb 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/reasoning-llms/</guid>
      <description>&lt;p&gt;AUTHOR: &amp;lt;lngnmn2@yahoo.com&amp;gt;&lt;/p&gt;
&lt;p&gt;When I was a kid &lt;del&gt;they told me not to stare at the sun&lt;/del&gt; I had this vision, that the brain structures are sort of like trees, while the &amp;ldquo;branches&amp;rdquo; are just like patches thorough our yard after fresh snow.&lt;/p&gt;
&lt;p&gt;Some of them remain thin, just someone walked across it absentmindedly, some gets broadened by a heavy re-use. Who would plow through a fresh snow while one could take follow the path that is already here.&lt;/p&gt;</description>
    </item>
    <item>
      <title>OpenAI vs. Deepseek</title>
      <link>https://lngnmn2.github.io/articles/openai-vs-deepseek/</link>
      <pubDate>Thu, 30 Jan 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/openai-vs-deepseek/</guid>
      <description>When shit reached the fan.</description>
    </item>
    <item>
      <title>Deepseek R1</title>
      <link>https://lngnmn2.github.io/articles/deepseek-r1/</link>
      <pubDate>Sun, 26 Jan 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/deepseek-r1/</guid>
      <description>&lt;p&gt;DESCRIPTION: Memes and mirrors.&lt;/p&gt;
&lt;p&gt;Nowadays things are moving way too fast. It is not just controlled trial-and-error, it is literally throwing everything at the wall (to see what sticks).&lt;/p&gt;
&lt;p&gt;It started with that meme &amp;ldquo;Attention Is All You Need&amp;rdquo;, when they just came up with an &amp;ldquo;architecture&amp;rdquo; that sticks.&lt;/p&gt;
&lt;p&gt;That &amp;ldquo;attention&amp;rdquo; and &amp;ldquo;multi head attention&amp;rdquo; turned out to be just a few additional layers of a particular kind.&lt;/p&gt;
&lt;p&gt;No one can explain the actual mechanisms of how exactly or even &lt;em&gt;why&lt;/em&gt; the layers are as they are (abstract bullshit aside). While the general idea was to mimic some specialized brain centers (the key to understand how it works), the actual code was merely &amp;ldquo;buffers&amp;rdquo;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Haskell and a LLM</title>
      <link>https://lngnmn2.github.io/articles/haskell-llm/</link>
      <pubDate>Sun, 26 Jan 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/haskell-llm/</guid>
      <description>&lt;p&gt;This is the difference between a LLM and an expert. An LLM spews out a &amp;ldquo;propaganda&amp;rdquo; from the web.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-markdown&#34; data-lang=&#34;markdown&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;### what are the unique properties of a Haskell program
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;1.&lt;/span&gt; &lt;span style=&#34;font-weight:bold&#34;&gt;**Statically Typed**&lt;/span&gt;: Haskell has a strong, static type system that ensures type safety at compile time.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;2.&lt;/span&gt; &lt;span style=&#34;font-weight:bold&#34;&gt;**Purely Functional**&lt;/span&gt;: Haskell programs are expressions, and functions have no side effects. This leads to code that&amp;#39;s easy to reason about, test, and debug.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;3.&lt;/span&gt; &lt;span style=&#34;font-weight:bold&#34;&gt;**Lazy Evaluation**&lt;/span&gt;: Haskell uses lazy evaluation, meaning it only evaluates expressions when their results are needed. This can lead to more efficient programs and allows for elegant solutions like infinite data structures.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;4.&lt;/span&gt; &lt;span style=&#34;font-weight:bold&#34;&gt;**Higher-Order Functions**&lt;/span&gt;: Functions in Haskell are first-class citizens, meaning they can be passed as arguments, returned as results, and stored in data structures.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;5.&lt;/span&gt; &lt;span style=&#34;font-weight:bold&#34;&gt;**Type Classes**&lt;/span&gt;: Haskell&amp;#39;s type classes (similar to interfaces in other languages) enable ad-hoc polymorphism, allowing related types to be treated uniformly.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;6.&lt;/span&gt; &lt;span style=&#34;font-weight:bold&#34;&gt;**Module System**&lt;/span&gt;: Haskell has a rich module system that supports abstract data types, hiding implementation details, and organizing code into reusable components.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;7.&lt;/span&gt; &lt;span style=&#34;font-weight:bold&#34;&gt;**Concurrency and Parallelism**&lt;/span&gt;: Haskell provides lightweight threads and a high-level concurrency abstraction called Software Transactional Memory (STM), along with support for parallel programming using the Glasgow Haskell Compiler (GHC).
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;8.&lt;/span&gt; &lt;span style=&#34;font-weight:bold&#34;&gt;**Rich Ecosystem**&lt;/span&gt;: Haskell has a vibrant community and a large ecosystem of libraries (via Hackage) for various domains, making it practical for real-world applications.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;###
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Here is what an expert answer could be:&lt;/p&gt;</description>
    </item>
    <item>
      <title>LLM Bullshit-3</title>
      <link>https://lngnmn2.github.io/articles/llmbs-3/</link>
      <pubDate>Mon, 02 Oct 2023 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/llmbs-3/</guid>
      <description>&lt;p&gt;It is more or less obvious why AI and LLM bubble is so huge - imagine just charging money for every &lt;code&gt;https&lt;/code&gt; request to a &lt;code&gt;RESTful&lt;/code&gt; API, without, literally, being responsible about the quality of the responce (it is not out fault if a LLM returned bullshit to you, or, which is much worse &amp;ndash; a highly sophisiticated, convincing subtle bullshit).&lt;/p&gt;
&lt;p&gt;Again, there is not enough good code to train a model on it. MIT Scheme, Haskell, Ocaml, Scala and Go compilers and standard libraries, and this is basically it. Everything else is an outrageously low-effort amateur crap &amp;ndash; piles upon piles of it, without any attempts to do thinfs &amp;ldquo;just right&amp;rdquo; (as in the classic languages).&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
