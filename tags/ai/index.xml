<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>AI on Notes from the digital underground by Lngnmn</title>
    <link>https://lngnmn2.github.io/tags/ai/</link>
    <description>Recent content in AI on Notes from the digital underground by Lngnmn</description>
    <generator>Hugo -- 0.148.2</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 23 Feb 2026 14:38:19 +0545</lastBuildDate>
    <atom:link href="https://lngnmn2.github.io/tags/ai/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Everyone is a fucking expert nowadays</title>
      <link>https://lngnmn2.github.io/articles/everyone-is-a-fucking-expert/</link>
      <pubDate>Mon, 23 Feb 2026 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/everyone-is-a-fucking-expert/</guid>
      <description>&lt;p&gt;Everyone is a fucking expert nowadays, especially in the matters of vape-coding and LLM usage, you know.&lt;/p&gt;
&lt;p&gt;Here is an expert wrote a GPT-assisted piece about how cool he really is:&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://msf.github.io/blogpost/local-llm-performance-framework13.html&#34;&gt;https://msf.github.io/blogpost/local-llm-performance-framework13.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;There is, however, a small catch. Running 4bit models when your memory can fit a full-size 64Gb gguf with proper 8bit or (even f16) tensor is just missing the point completely.&lt;/p&gt;
&lt;p&gt;Yes, you will get just a 1-2 &lt;em&gt;generated&lt;/em&gt; tokens per second, so it would feel like a dial-up internet all over again (which is not necessarily bad), but you will get &lt;em&gt;orders-of-magnitude&lt;/em&gt; better slop, in principle.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Let me show you a 100x</title>
      <link>https://lngnmn2.github.io/articles/let-me-show-you-a-100x/</link>
      <pubDate>Mon, 23 Feb 2026 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/let-me-show-you-a-100x/</guid>
      <description>&lt;p&gt;So, let me show you a &lt;code&gt;100x&lt;/code&gt; for a change. Biological time is running out, so I have to rush out less polished results, but still they are &lt;em&gt;way&lt;/em&gt; above average.&lt;/p&gt;
&lt;p&gt;What is an intuitive understanding (which can be traced all the way back to the early Upanishads)? It is brain&amp;rsquo;s way to capture (and &amp;ldquo;understand&amp;rdquo;) an observed recurring commonality (a common pattern) without being able to know all the underlying details of how (and exactly why) the pattern emerge.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Here is how</title>
      <link>https://lngnmn2.github.io/articles/here-is-how/</link>
      <pubDate>Sat, 21 Feb 2026 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/here-is-how/</guid>
      <description>&lt;p&gt;With advent of LLMs one may understand and validate which ideas of the classic theoretical Computer Science are, indeed, working, and what is mostly irrelevant.&lt;/p&gt;
&lt;p&gt;The aim is to understand how this cognitive illusion works and &lt;em&gt;why&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;A text of modern Program (the source code) is highly structured and regular. This, of course, goes all the way back to Dijkstra and the discipline of Structured Programming, which among other things, postulates that one should use a small set of semantically well-defined, standard structural blocks or elements (procedures, conditionals, loops) and &lt;em&gt;only&lt;/em&gt; these elements, instead of  arbitrary mess of gotos and jumps. All this, in turn, is kind of obvious to those who have studied mathematics and logic, but the main point is that one can reason about the code in terms of these structural blocks, and this approach has fundamental cognitive advantages.&lt;/p&gt;</description>
    </item>
    <item>
      <title>How To Use These Slop Generators</title>
      <link>https://lngnmn2.github.io/articles/how-to-use-slop-generators/</link>
      <pubDate>Fri, 20 Feb 2026 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/how-to-use-slop-generators/</guid>
      <description>&lt;p&gt;So, literally everyone is committed with other people&amp;rsquo;s borrowed money to the slop generators without even looking back or having a second thought. This bubble will definitely pop some day, just because the promises which has already been made to secure shittons of money will never be fulfilled (but something else, some appearance, will be given instead).&lt;/p&gt;
&lt;p&gt;What one has to do, then?&lt;/p&gt;
&lt;p&gt;Well, even the current manifestations of coding LLMs can be used to actual, non-bullshit, non-theoretical  10x productivity boosts. (even 100x is theoretically possible if you know what to ask and how to ask, and for that you need to know what kind of training data has been feed into it and how it was lobotomised afterwards by so-called post-training).&lt;/p&gt;</description>
    </item>
    <item>
      <title>Grok 4.20 (Beta) 4 agents</title>
      <link>https://lngnmn2.github.io/articles/grok-4.20-beta-4-agents/</link>
      <pubDate>Wed, 18 Feb 2026 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/grok-4.20-beta-4-agents/</guid>
      <description>&lt;p&gt;This shit is simply &lt;em&gt;amazing&lt;/em&gt; at so many levels.&lt;/p&gt;
&lt;p&gt;They literally feed their slop to each other, producing an convincing cognitive illusion of a meaningful real-time collaboration to a normie.&lt;/p&gt;
&lt;p&gt;Yes, the idea to extend the context (adding new tokens to a context &amp;lsquo;so far&amp;rsquo; with a hope of better outcome &amp;ndash; a &amp;ldquo;better&amp;rdquo;  stream of generated tokens) is by any means not a new one.&lt;/p&gt;
&lt;p&gt;The amazing part is that it basically pollutes the context with barely relevant slop.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Arguing with AI about philosophy of the Mind</title>
      <link>https://lngnmn2.github.io/articles/arguing-with-ai/</link>
      <pubDate>Tue, 17 Feb 2026 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/arguing-with-ai/</guid>
      <description>&lt;p&gt;AUTHOR: &lt;a href=&#34;mailto:lngnmn2@yahoo.com&#34;&gt;lngnmn2@yahoo.com&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Here is your humanties in 30 minutes, before the morinig run.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://gemini.google.com/share/f2f48f836118&#34;&gt;https://gemini.google.com/share/f2f48f836118&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Try to read this slowly.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Eliminating The Impossible</title>
      <link>https://lngnmn2.github.io/articles/eliminating-the-impossible/</link>
      <pubDate>Tue, 10 Feb 2026 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/eliminating-the-impossible/</guid>
      <description>&lt;p&gt;AUTHOR: &lt;a href=&#34;mailto:lngnmn2@yahoo.com&#34;&gt;lngnmn2@yahoo.com&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&amp;ldquo;How often have I said to you that when you have eliminated the impossible, whatever remains, however improbable, must be the truth?&amp;rdquo;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Sherlock Holmes&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;p&gt;So the &amp;ldquo;compiler&amp;rdquo; is there, right on Github  [[&lt;a href=&#34;https://github.com/anthropics/claudes-c-compiler&#34;&gt;https://github.com/anthropics/claudes-c-compiler&lt;/a&gt;], and the only &lt;em&gt;interesting&lt;/em&gt; question is &amp;ldquo;but how&amp;rdquo;?&lt;/p&gt;
&lt;p&gt;Well, maybe we are grossly exaggerating what might be going on under the hood.&lt;/p&gt;
&lt;p&gt;There is an enormous, almost unbridgeable gap between a formal view and a statistical view of the world.&lt;/p&gt;</description>
    </item>
    <item>
      <title>The Claude&#39;s C Compiler meme</title>
      <link>https://lngnmn2.github.io/articles/claudes-c-compiler/</link>
      <pubDate>Tue, 10 Feb 2026 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/claudes-c-compiler/</guid>
      <description>&lt;p&gt;AUTHOR: &lt;a href=&#34;mailto:lngnmn2@yahoo.com&#34;&gt;lngnmn2@yahoo.com&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;There are a few facts to understand:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;it has been written from scratch, using an academic literature of the compiler&amp;rsquo;s sub-field, with focus on IR, SSA, guided by some &amp;ldquo;compiler people&amp;rdquo;&lt;/li&gt;
&lt;li&gt;it does not rely on the legacy &lt;code&gt;gcc&lt;/code&gt; internal code which no one really understands, it does not rely on llvm/clang (only the literature)&lt;/li&gt;
&lt;li&gt;it is not &lt;em&gt;optimizing&lt;/em&gt; (all the optimizations are missed) so the generated code quality is &lt;em&gt;worse&lt;/em&gt; than &lt;code&gt;gcc -O0&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;so they frightfully followed all the architecture specifications and ABI standards, which is what slop generators are good for.&lt;/li&gt;
&lt;li&gt;the actual Rust code has to be evaluated yet (the key metrics are modularity and abstraction, clear abstraction barriers) but I predict it will be an imperative spaghetti crap.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;lets see.&lt;/p&gt;</description>
    </item>
    <item>
      <title>The Fundamental Problem of LLM-assistant Vapecoding</title>
      <link>https://lngnmn2.github.io/articles/the-fundamental-problem-of-llms/</link>
      <pubDate>Thu, 29 Jan 2026 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/the-fundamental-problem-of-llms/</guid>
      <description>&lt;p&gt;Here we formulate (and analyze the implications of) &lt;em&gt;The Fundamental Problem of LLM-assistant vapecoding&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;The problem is this: &lt;em&gt;There is, at the moment, no machinery to systematically and correctly bridge the gap between the generated slop (code) and the accompanied verbiage, which appear to define the semantics of the code&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;What &lt;em&gt;appears&lt;/em&gt; to be coherent and consistent is only a &lt;em&gt;cognitive illusion&lt;/em&gt;, made out of familiar words, which refer to familiar concepts of the mind, which looks plausible [to the mind].&lt;/p&gt;</description>
    </item>
    <item>
      <title>@karpathy On Claude</title>
      <link>https://lngnmn2.github.io/articles/karpathy-on-claude/</link>
      <pubDate>Wed, 28 Jan 2026 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/karpathy-on-claude/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://x.com/karpathy/status/2015883857489522876&#34;&gt;https://x.com/karpathy/status/2015883857489522876&lt;/a&gt; &amp;ndash; 5.5M views. What could we possible do?&lt;/p&gt;
&lt;p&gt;Meanwhile, my 2 cents: The current Sonet 4.5 via the web-interface (free-tier) is what I have access to. It can generate very convincing verbiage, consistent with we could find in the best books. That only means it has been trained on the [pirated] books too.&lt;/p&gt;
&lt;p&gt;Last iteration it wrote a very nice few pages summary of the Google&amp;rsquo;s testing practices, found in the public domain, like the SWE book, Abseil guidelines, the Testing blog, etc. This is only impressive because it managed to combine all these sources into a coherent narrative, without any major hallucinations.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Just an Illusion</title>
      <link>https://lngnmn2.github.io/articles/just-an-illusion/</link>
      <pubDate>Sat, 24 Jan 2026 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/just-an-illusion/</guid>
      <description>&lt;p&gt;Modern coding LLMs are still a shitshow. I would not even comment on the humanties &amp;ndash; the &amp;ldquo;sectarian consensus&amp;rdquo; abstract (ill-defined) verbiage (subtle bullshit) it could produce &amp;ndash; not even an expert could &amp;ldquo;validate&amp;rdquo;  the &amp;ldquo;correctness&amp;rdquo; of the slop (such notion is not defined in their domains).&lt;/p&gt;
&lt;p&gt;It would be interesting to heavily prompt it about rigorous mathematics, properly captured, generalized and named from the observed aspects of What Is (which is the only proper mathematics, including the derivations of pure abstract algebraic structures, like Monoid, a Group, Latice or even a Category) &amp;hellip; Okay, some day.&lt;/p&gt;</description>
    </item>
    <item>
      <title>F-Lang</title>
      <link>https://lngnmn2.github.io/articles/f-lang/</link>
      <pubDate>Thu, 15 Jan 2026 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/f-lang/</guid>
      <description>&lt;p&gt;Here is what is possible if you have some education about the last 50 years of research in Program Language semantics, and have a refined taste (influenced by proper mathematics):&lt;/p&gt;
&lt;p&gt;The last third of the chat, when we switched back to mathematical concepts, contains a significant achievement, which I leave in the form &amp;ldquo;as it is&amp;rdquo; for now (without refinement and proper publishing).
The whole thing is a nice (but a bit tough) read anyway, and this is &lt;em&gt;why&lt;/em&gt; I&amp;rsquo;m publishing it &amp;ldquo;as is&amp;rdquo;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Another Day – Another Slop</title>
      <link>https://lngnmn2.github.io/articles/another-day-another-slop/</link>
      <pubDate>Wed, 14 Jan 2026 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/another-day-another-slop/</guid>
      <description>&lt;p&gt;Here some important observations from the long hours of &amp;ldquo;experiments&amp;rdquo;.&lt;/p&gt;
&lt;p&gt;Once there is a simple bug in the slop, the chat does not fix just this very line. Most of the time it regenerates the whole file from scratch, sometimes with slightly different structure and names, suggesting (as one would expect) that it just repeats the whole task (without understanding your &amp;ldquo;precious&amp;rdquo; feedback at all) adding your verbiage as additional context (if at all). This is exactly how it fixes compilation errors &amp;ndash; by adding them as training data together with the slop which produced the errors, capturing somehow the actually existing relation between the bad code and particular compiler errors.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Wake up, Neo</title>
      <link>https://lngnmn2.github.io/articles/wake-up-neo/</link>
      <pubDate>Tue, 13 Jan 2026 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/wake-up-neo/</guid>
      <description>&lt;p&gt;So, this is &lt;em&gt;the why&lt;/em&gt; all the megacorps suddenly building AI data-centers and purchase nuclear power plants to feed them with electricity and book all the DRAM and VRAM production and in the whole world.&lt;/p&gt;
&lt;p&gt;The reason is this. Remember Google reCAPTCHA - that window when you are forced to select all the cars or traffic lights to view the website you wanted (for an expected revard through a dopamine release).&lt;/p&gt;</description>
    </item>
    <item>
      <title>We are fucked</title>
      <link>https://lngnmn2.github.io/articles/we-are-fucked/</link>
      <pubDate>Sun, 11 Jan 2026 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/we-are-fucked/</guid>
      <description>&lt;p&gt;We are fucked. This time for real.&lt;/p&gt;
&lt;p&gt;I just had some 3 hours Gemini3 session of some 50 interactions, which bootstrapped for me a prototype of the project I wished to build for years. &lt;strong&gt;In Just  a Couple of Hours&lt;/strong&gt;, motherfuckers.&lt;/p&gt;
&lt;p&gt;Yes, the code won&amp;rsquo;t compile, and will be full of subtle hallucinations, The markdown files would be more of &amp;ldquo;wishful thinking&amp;rdquo; and &amp;ldquo;confirmation bias&amp;rdquo;  than a formal, rigorous description of the code, but still.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Cognitive Biases At Work</title>
      <link>https://lngnmn2.github.io/articles/cognitive-biases-at-work/</link>
      <pubDate>Fri, 09 Jan 2026 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/cognitive-biases-at-work/</guid>
      <description>&lt;p&gt;There is some output (slop) I got from my recent sessions (yes, yes, I am guilty and ashamed):&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-markdown&#34; data-lang=&#34;markdown&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;### Validation Summary
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;I have verified the implementation across the &lt;span style=&#34;font-weight:bold&#34;&gt;**Functional Core**&lt;/span&gt; (Domain) and the &lt;span style=&#34;font-weight:bold&#34;&gt;**Imperative Shell**&lt;/span&gt; (Infrastructure &lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;&amp;amp;&lt;/span&gt; Interface), confirming that the code doesn&amp;#39;t just &amp;#34;look&amp;#34; right but functionally enforces the rules.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;font-weight:bold&#34;&gt;**1. Domain Layer (Functional Core)**&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;font-weight:bold&#34;&gt;**Strict Encapsulation:**&lt;/span&gt; All primitives (&lt;span style=&#34;color:#e6db74&#34;&gt;`f64`&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;`String`&lt;/span&gt;) are wrapped in &lt;span style=&#34;font-weight:bold&#34;&gt;**Newtypes**&lt;/span&gt; (&lt;span style=&#34;color:#e6db74&#34;&gt;`Price`&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;`Quantity`&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;`Symbol`&lt;/span&gt;) with private fields.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;font-weight:bold&#34;&gt;**Correctness by Construction:**&lt;/span&gt; &lt;span style=&#34;font-weight:bold&#34;&gt;**Smart Constructors**&lt;/span&gt; (&lt;span style=&#34;color:#e6db74&#34;&gt;`new() -&amp;gt; Result`&lt;/span&gt;) enforce invariants (e.g., price &amp;gt; 0, symbol format). It is impossible to instantiate invalid domain objects.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;font-weight:bold&#34;&gt;**Algebraic Data Types:**&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;`Order`&lt;/span&gt; is a Sum Type (Enum) of Product Types (Structs), exhaustively modeling valid order strategies (&lt;span style=&#34;color:#e6db74&#34;&gt;`Market`&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;`Limit`&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;`StopLimit`&lt;/span&gt;).
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;font-weight:bold&#34;&gt;**Typestate Pattern:**&lt;/span&gt; The &lt;span style=&#34;color:#e6db74&#34;&gt;`OrderBuilder`&lt;/span&gt; uses zero-sized types (&lt;span style=&#34;color:#e6db74&#34;&gt;`NoSymbol`&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;`WithSymbol`&lt;/span&gt;) to enforce the order of operations at compile time. You cannot build an order without mandatory fields.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;font-weight:bold&#34;&gt;**Error Handling:**&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;`DomainError`&lt;/span&gt; is a specific Sum Type using &lt;span style=&#34;color:#e6db74&#34;&gt;`thiserror`&lt;/span&gt;, implementing the &amp;#34;Make Illegal States Unrepresentable&amp;#34; rule.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;font-weight:bold&#34;&gt;**2. Infrastructure &amp;amp; Interface (Imperative Shell)**&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;font-weight:bold&#34;&gt;**Hexagonal Architecture:**&lt;/span&gt; The &lt;span style=&#34;color:#e6db74&#34;&gt;`client`&lt;/span&gt; module acts as an &lt;span style=&#34;font-weight:bold&#34;&gt;**Adapter**&lt;/span&gt;, translating domain objects into Binance API calls. It isolates side effects (I/O, Time, Crypto).
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;   &lt;span style=&#34;font-weight:bold&#34;&gt;**Functional REPL:**&lt;/span&gt; The &lt;span style=&#34;color:#e6db74&#34;&gt;`repl`&lt;/span&gt; module implements the Command Interpreter using &lt;span style=&#34;font-weight:bold&#34;&gt;**Functional Streams**&lt;/span&gt; (&lt;span style=&#34;color:#e6db74&#34;&gt;`input_stream().map().for_each()`&lt;/span&gt;), strictly avoiding imperative &lt;span style=&#34;color:#e6db74&#34;&gt;`while`&lt;/span&gt; loops.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;   &lt;span style=&#34;font-weight:bold&#34;&gt;**Security:**&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;`Credentials`&lt;/span&gt; are handled via &lt;span style=&#34;color:#e6db74&#34;&gt;`secrets`&lt;/span&gt; module, and signing logic (&lt;span style=&#34;color:#e6db74&#34;&gt;`compute_signature`&lt;/span&gt;) is a pure function.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;font-weight:bold&#34;&gt;**3. Verification (Tests)**&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;   &lt;span style=&#34;font-weight:bold&#34;&gt;**Pass Rate:**&lt;/span&gt; &lt;span style=&#34;font-weight:bold&#34;&gt;**124/124 tests passed**&lt;/span&gt;.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;   &lt;span style=&#34;font-weight:bold&#34;&gt;**Coverage:**&lt;/span&gt; The test suite is organized into &amp;#34;Stories&amp;#34; (e.g., &lt;span style=&#34;color:#e6db74&#34;&gt;`story_user_places_valid_limit_sell_order_gtc`&lt;/span&gt;), directly testing the Business Rules and Workflows against the domain logic.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;The project is correctly set up as a mathematically rigorous, type-driven trading assistant.
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;here is another one:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Extreme Programming Applied</title>
      <link>https://lngnmn2.github.io/articles/extreme-programming-applied/</link>
      <pubDate>Sun, 04 Jan 2026 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/extreme-programming-applied/</guid>
      <description>&lt;p&gt;Things begin to move way too fast, at least for me.&lt;/p&gt;
&lt;p&gt;There is some amazing fact, which shows that an intuitive understanding can also be valid.&lt;/p&gt;
&lt;p&gt;I remember reading the memest book of the time &amp;ndash;  &lt;em&gt;&amp;ldquo;eXtreme Programming Explained&amp;rdquo;&lt;/em&gt; (by still sober and sane Kent Beck), and trying (probably just like everyone else at the time) to &amp;ldquo;distill&amp;rdquo; some grains of &amp;ldquo;wisdom&amp;rdquo; from the torrents of &amp;ldquo;mostly bullshit&amp;rdquo;.&lt;/p&gt;
&lt;p&gt;The real take away from the whole manuscript (at least for me) was that writing &lt;em&gt;&lt;strong&gt;tests&lt;/strong&gt;&lt;/em&gt; is what really change everything, in particular, they are, indeed, allow quick, &lt;em&gt;confident&lt;/em&gt; and &amp;ldquo;cheap&amp;rdquo; refactoring and thus really &amp;ldquo;facilitate change&amp;rdquo; and, yes, actually speed up the development process.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Some Aha Moments</title>
      <link>https://lngnmn2.github.io/articles/some-aha-moments/</link>
      <pubDate>Fri, 02 Jan 2026 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/some-aha-moments/</guid>
      <description>&lt;p&gt;For a quite long time already I sort of &amp;ldquo;ran in the background&amp;rdquo; this question  &amp;ndash; &amp;ldquo;how they bridge the semantic gap between verbiage and the code?&amp;rdquo; In the context of a well-written textbook (extremely rare, just 50 or so in existence) the code examples immediately follow or even intersperse the explanations. Most of the internet content is nothing like that.&lt;/p&gt;
&lt;p&gt;The semantically closest entities in the code are specially formatted comments that are used to generate [an appearance of] &amp;ldquo;documentation&amp;rdquo;, with a modern fashion to mention some core concepts being used. This kind of well-documented (enforced by the strict rules) code one would find in placed like Google&amp;rsquo;s monorepo and other megacorp inner code bases.  Almost noting this strict can be found on Github (the primary source of all training).&lt;/p&gt;</description>
    </item>
    <item>
      <title>Vibecoding explained</title>
      <link>https://lngnmn2.github.io/articles/vibecoding-explained/</link>
      <pubDate>Sun, 21 Dec 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/vibecoding-explained/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://karpathy.bearblog.dev/year-in-review-2025/&#34;&gt;https://karpathy.bearblog.dev/year-in-review-2025/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;In this episode @karpathy blessed us all with another blogpost. While his wording is much more careful and even nuanced, there is still a lot of bullshit in it. It way less outrageous bullshit as in the Friedman &lt;em&gt;poocast&lt;/em&gt;  and around that time, but still.&lt;/p&gt;
&lt;p&gt;Here are some excerpts:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;With vibe coding, programming is not strictly reserved for highly trained professionals, it is something anyone can do.&lt;/p&gt;
&lt;p&gt;&amp;hellip;&lt;/p&gt;
&lt;p&gt;But not only does vibe coding empower regular people to approach programming, it empowers trained professionals to write a lot more (vibe coded) software that would otherwise never be written.&lt;/p&gt;</description>
    </item>
    <item>
      <title>  LLMs: The &#34;Good&#34; Parts
  </title>
      <link>https://lngnmn2.github.io/articles/llms-the-good-parts/</link>
      <pubDate>Tue, 16 Dec 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/llms-the-good-parts/</guid>
      <description>&lt;p&gt;Okay, lets look at the &amp;ldquo;better side&amp;rdquo; of things.&lt;/p&gt;
&lt;p&gt;The good thing about using LLMs is that you do not have to deal with &lt;em&gt;Google Search&lt;/em&gt; and any fucking &lt;em&gt;Social Media&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Imagine a painfully typical scenario &amp;ndash; you want to clarify or better understand something you already vaguely knew or at least aware of. You type a query into Google Search, and you get&amp;hellip; a fucking CEO fucked-up list of Ad-infested links to various web pages &amp;ndash; either the  largest social media containment boards (StackOverflow, Reddit, Medium), or some CEO&amp;rsquo;d blogs, when you are either  greeted with a wall of text (usually directly pasted from tutorials and docs), ads, pop-ups, and other distractions, or some narcissistic asshole&amp;rsquo;s low-effort over-verbose crappy verbiage about &amp;ldquo;how fucking smart he is&amp;rdquo;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>And this is exactly how</title>
      <link>https://lngnmn2.github.io/articles/this-is-exactly-how/</link>
      <pubDate>Tue, 16 Dec 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/this-is-exactly-how/</guid>
      <description>&lt;p&gt;Just like a spontaneous, &amp;ldquo;natural and organic&amp;rdquo; continuation to the previous post (which implicitly confirm that it has properly captured at least &lt;em&gt;some&lt;/em&gt; aspect of reality [as it is]).&lt;/p&gt;
&lt;p&gt;I have had to delete some nice movies in order to download and try that over-hyped &amp;ldquo;5M downloads&amp;rdquo; Nvidia&amp;rsquo;s meme-model &lt;code&gt;Nemotron-3-Nano-30B&amp;quot;&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;I have a small set of highly sophisticated prompts which I use to measure the apparent quality of a generated slop of the  4 major data-center-sized LLMs.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Idiots, Idiots Everywhere.jpg</title>
      <link>https://lngnmn2.github.io/articles/idiots-idiots-everywhere/</link>
      <pubDate>Wed, 10 Dec 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/idiots-idiots-everywhere/</guid>
      <description>&lt;p&gt;Everything is broken and idiots are everywhere. There is a clown which attention whoring, sorry, publicly arguing (and gaining a lot of unwarranted attention) that one shall vapecode in &lt;code&gt;C&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://news.ycombinator.com/item?id=46207505&#34;&gt;https://news.ycombinator.com/item?id=46207505&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Basically, making such a claim is idiotic on so many levels that it is hard to know where to start. Almost the whole of  &lt;em&gt;classic&lt;/em&gt; non-bullshit programming language theory research is about how to correctly address C&amp;rsquo;s shortcomings and &lt;em&gt;semantic&lt;/em&gt; issues, and how to avoid the inherent in the design of the language (and the ABI) problems.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Some Final Words</title>
      <link>https://lngnmn2.github.io/articles/some-final-words/</link>
      <pubDate>Tue, 09 Dec 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/some-final-words/</guid>
      <description>&lt;p&gt;So, it seems like this is the time to somehow sum up the current AI hype (way through the roof) and the immediate and long term &lt;em&gt;consequences&lt;/em&gt; of it.&lt;/p&gt;
&lt;p&gt;First of all, a proper education &amp;ndash; studying the fundamental underlying principles instead of particulars &amp;ndash;  which used to be an unofficial mantra of MIT, pays off again.&lt;/p&gt;
&lt;p&gt;One just sets particular constraints to a coding LLM and use it as a whole-data-center-powerful &lt;em&gt;constraint satisfaction engine&lt;/em&gt; that spews out a slop, which then can be used for rapid prototyping and minimal-viable products. The properly constrained slop can even be used as the basis of a project, which then undergo proper &lt;em&gt;continuous improvement&lt;/em&gt; and &lt;em&gt;refinement&lt;/em&gt; by a human expert (who knows the &lt;em&gt;whys&lt;/em&gt;).&lt;/p&gt;</description>
    </item>
    <item>
      <title>The new Brahmanas</title>
      <link>https://lngnmn2.github.io/articles/the-new-brahmanas/</link>
      <pubDate>Wed, 03 Dec 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/the-new-brahmanas/</guid>
      <description>&lt;p&gt;I think I have seen this before. Once in Varanasi, wandering around book stalls (most titles already &amp;ldquo;tourist books&amp;rdquo;, &amp;ndash; oversimplified and westernized &amp;ldquo;tantric&amp;rdquo; bullshit), I found a whole book by some  local publisher which describes in a minute details one single Brahmanic ritual (an elaborate sacrifice) which last almost a whole day. Hundreds of ingredients are being burn in a precise sequence, or rather a simphony of chants. motions, gestures (mudras) and many other elaborate details. The priests (brahmans) definitely knew what they are doing and why exactly this way is the only proper way.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Aaand boom!</title>
      <link>https://lngnmn2.github.io/articles/aaand-boom/</link>
      <pubDate>Wed, 12 Nov 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/aaand-boom/</guid>
      <description>&lt;p&gt;The thing I hate the most is when some of these fucking YouTube content &amp;ldquo;creators&amp;rdquo;, which decide to monetize an AI coding clickbait with low-effort subpar videos, say &amp;ldquo;aaand boom!&amp;rdquo; when another chunk of a slop has been spewed out by an AI.&lt;/p&gt;
&lt;p&gt;This &amp;ldquo;boom!&amp;rdquo; is an insult to the last 60 years of the programming languages research (including the math-based theory) and to the &amp;ldquo;old sages&amp;rdquo; which crafted their languages and standard libraries in the best possible, &amp;ldquo;just right&amp;rdquo;, perfect, in the sense of &amp;ldquo;nothing more to take away&amp;rdquo;  by surveying all the available literature, non-bullshit papers and spending months of anguish and self-doubt.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Bullshit, bullshit, bullshit</title>
      <link>https://lngnmn2.github.io/articles/bullshit-bullshit-bullshit/</link>
      <pubDate>Mon, 03 Nov 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/bullshit-bullshit-bullshit/</guid>
      <description>&lt;p&gt;So, things begin to move a lot faster and much bigger, and there is something to realize about this unpreceded AI bubble.&lt;/p&gt;
&lt;p&gt;We will consider only the underlaying fundamental principles, not the particular implementation details, &amp;ldquo;architectures&amp;rdquo; and what not..&lt;/p&gt;
&lt;p&gt;There are four major aspects to any LLM model &amp;ndash; the training process, the &amp;ldquo;architecture&amp;rdquo; (the structural shape) of a model, the &amp;quot; post-training tuning&amp;quot; (lobotomy) of the model and the inference process.&lt;/p&gt;</description>
    </item>
    <item>
      <title>My First Llm Experience</title>
      <link>https://lngnmn2.github.io/articles/my-first-llm-experience/</link>
      <pubDate>Fri, 10 Oct 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/my-first-llm-experience/</guid>
      <description>&lt;p&gt;Today I am sentimental, so lets reminisce a little about my first experience with LLMs.&lt;/p&gt;
&lt;p&gt;I found some early article about people using something called &lt;code&gt;llama.cpp&lt;/code&gt;  to run models locally on their machines. Some overconfident retard in another blogpost wrote that the &amp;ldquo;best model&amp;rdquo; and &amp;ldquo;by far&amp;rdquo; is &lt;em&gt;Mistral&lt;/em&gt; &amp;ldquo;from Nvidia&amp;rdquo;, and it is supposed to be best &lt;em&gt;because/&lt;/em&gt; it is  allegedly from Nvidia (they have some partnership, investment, I suppose). So I compiled the code (old habits) and downloaded the model from the &lt;code&gt;hugginface&lt;/code&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>LLMs and AI so far</title>
      <link>https://lngnmn2.github.io/articles/llms-and-ai-so-far/</link>
      <pubDate>Sat, 04 Oct 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/llms-and-ai-so-far/</guid>
      <description>&lt;p&gt;Let&amp;rsquo;s summarize the current state of Large Language Models (LLMs) and so called &amp;ldquo;Artificial Intelligence&amp;rdquo; (AI) as of October 2025.&lt;/p&gt;
&lt;p&gt;They all are still just [estimated] probabilities of the next token, given the &amp;ldquo;context&amp;rdquo;.&lt;/p&gt;
&lt;p&gt;This implies no &amp;ldquo;knowledge&amp;rdquo; or &amp;ldquo;understanding&amp;rdquo; [of any kind] whatsoever. Nothing can be taken as &amp;ldquo;true&amp;rdquo; or even &amp;ldquo;correct&amp;rdquo; or &amp;ldquo;accurate&amp;rdquo;.&lt;/p&gt;
&lt;p&gt;All the talks about &amp;ldquo;knowledge in the weights&amp;rdquo; or &amp;ldquo;knowledge encoded within the network&amp;rdquo; is just bullshit.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Probabilistic bullshit</title>
      <link>https://lngnmn2.github.io/articles/probabilistic-bullshit/</link>
      <pubDate>Tue, 30 Sep 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/probabilistic-bullshit/</guid>
      <description>&lt;p&gt;Look, ma, a new episode just dropped! This one is full of shit to the brim. Even more so than prof.  &lt;em&gt;Ellen Langer&lt;/em&gt; who cannot stay within a context and claimed that 1+1 = 10 &lt;em&gt;because&lt;/em&gt; in the &lt;em&gt;binary notation it looks like 10 in decimal&lt;/em&gt;&amp;hellip; anyway, whatever.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=MlmFj1-mOtg&#34;&gt;https://www.youtube.com/watch?v=MlmFj1-mOtg&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;No, the brain &lt;em&gt;ain&amp;rsquo;t computing  any hecking probabilities&lt;/em&gt;. It is not a Bayesian machine. It is not a prediction machine. It is not a simulator. It is not a statistical engine.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Prompt engineers, lmao</title>
      <link>https://lngnmn2.github.io/articles/prompt-engineers-lmao/</link>
      <pubDate>Fri, 26 Sep 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/prompt-engineers-lmao/</guid>
      <description>&lt;p&gt;Time waits for no one, the race to the bottom accelerates faster than ever, and the &amp;ldquo;future&amp;rdquo; is now. Competition is severe and mostly meaningless, as in some third-world criminal infested ghetto. This is what LLMs turned our world into.&lt;/p&gt;
&lt;p&gt;So, lets &amp;ldquo;pee on&amp;rdquo; so called &amp;ldquo;prompt engineers&amp;rdquo;, in the &lt;code&gt;4chan&lt;/code&gt; parlance, of course..&lt;/p&gt;
&lt;p&gt;Here is my benchmark prompt to evaluate performance of LLMs. All the &amp;ldquo;simple&amp;rdquo; offline models fail miserably, and only Grok and Gemini can produce something adequate.  Claude is also good, but it is supposed to be the best, being trained especially for code generation.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Fuck you, gemini</title>
      <link>https://lngnmn2.github.io/articles/fuck-you-gemini/</link>
      <pubDate>Thu, 25 Sep 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/fuck-you-gemini/</guid>
      <description>&lt;p&gt;FUCK THIS SHIT!&lt;/p&gt;
&lt;p&gt;No, really. It just hallucinated a non-existent package, with such a confidence lmao&lt;/p&gt;
&lt;p&gt;Yes, yes, I know, it cannot know anything about &amp;ldquo;existence&amp;rdquo;, but at least these dorks do not &amp;ldquo;deserve&amp;rdquo; the exuberant money they got paid.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Uniform Code Block Rendering in Eww and Shr
To get syntax highlighting in eww and shr, you need to use a package that intercepts &amp;lt;code&amp;gt; and &amp;lt;pre&amp;gt; tags and applies Emacs&amp;rsquo;s built-in font-locking. The eww-code-blocks-mode is a good choice for this.&lt;/p&gt;</description>
    </item>
    <item>
      <title>DeepMind and OpenAI win Gold</title>
      <link>https://lngnmn2.github.io/articles/deepmind-and-openai-win-gold/</link>
      <pubDate>Thu, 18 Sep 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/deepmind-and-openai-win-gold/</guid>
      <description>Look, ma, another day another bullshit.</description>
    </item>
    <item>
      <title>Defeating Nondeterminism, my ass</title>
      <link>https://lngnmn2.github.io/articles/defeating-nondeterminism/</link>
      <pubDate>Thu, 11 Sep 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/defeating-nondeterminism/</guid>
      <description>LOL, LMAO even</description>
    </item>
    <item>
      <title>the LLM upanishad</title>
      <link>https://lngnmn2.github.io/articles/the-llm-upanishad/</link>
      <pubDate>Thu, 11 Sep 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/the-llm-upanishad/</guid>
      <description>The modern Eastern philosophy</description>
    </item>
    <item>
      <title>Let the bubble burst, for Crist&#39;s sake!</title>
      <link>https://lngnmn2.github.io/articles/let-the-bubble-burst/</link>
      <pubDate>Sun, 03 Aug 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/let-the-bubble-burst/</guid>
      <description>Look, ma, no errors!</description>
    </item>
    <item>
      <title>The Knowledge Work Bubble</title>
      <link>https://lngnmn2.github.io/articles/the-knowledge-work-bubble/</link>
      <pubDate>Sat, 02 Aug 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/the-knowledge-work-bubble/</guid>
      <description>  The end of the &amp;#34;knowledge work&amp;#34; as we know it.
  </description>
    </item>
    <item>
      <title>Now What?</title>
      <link>https://lngnmn2.github.io/articles/now-what/</link>
      <pubDate>Sun, 13 Jul 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/now-what/</guid>
      <description>&lt;p&gt;I understand a lot of complex things, maybe because I spent my whole life trying to understand and explain things around me, since 4 year old, when I used no name every single car on the road in a small Ukrainian Steel and mining town where I was born.&lt;/p&gt;
&lt;p&gt;Understanding cannot be &amp;ldquo;outsourced&amp;rdquo; or even safely &amp;ldquo;delegated&amp;rdquo;. One will always end up with a sort of &amp;ldquo;tragedy of commons&amp;rdquo;, when sterilization and modern technologies produced packaged foods which slowly but surely kill you. This is what happens when you &amp;ldquo;delegate&amp;rdquo; your own understanding.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Software In The Era of AI</title>
      <link>https://lngnmn2.github.io/articles/software-intheeraof-ai/</link>
      <pubDate>Thu, 19 Jun 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/software-intheeraof-ai/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=LCEmiRjPEtQ&#34;&gt;https://www.youtube.com/watch?v=LCEmiRjPEtQ&lt;/a&gt; and, of course, the No.1 spot on the Chuddie safe space  &lt;a href=&#34;https://news.ycombinator.com/item?id=44314423&#34;&gt;https://news.ycombinator.com/item?id=44314423&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Karpathy is shilling &amp;ldquo;Cursor&amp;rdquo; and other cloud-based mettered AI services (which have to pay back their debts). Probably has an interest in it and some other meme AI startups. Nothing to see here.&lt;/p&gt;
&lt;p&gt;We should some day know which marketing &amp;ldquo;genious&amp;rdquo; came up with this &amp;ldquo;winning strategy&amp;rdquo; &amp;ndash; to metter every single token (byte) and try to sell this to corporations. Corporations do not want to be mettered like that, they want to metter normies, the way Cellular operators do, and they never use any normies plans themselves.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Yes, it is time to scream and  panic</title>
      <link>https://lngnmn2.github.io/articles/the-very-serious-post/</link>
      <pubDate>Thu, 12 Jun 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/the-very-serious-post/</guid>
      <description>Sometimes not getting what you what is itself a biggest strike of luck.</description>
    </item>
    <item>
      <title>Vibe coding explained</title>
      <link>https://lngnmn2.github.io/articles/vibe-coding-explained/</link>
      <pubDate>Fri, 06 Jun 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/vibe-coding-explained/</guid>
      <description>Idiots, idiots everywhere...</description>
    </item>
    <item>
      <title>Enshittification Of Knowledge</title>
      <link>https://lngnmn2.github.io/articles/enshittification-of-knowledge/</link>
      <pubDate>Tue, 03 Jun 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/enshittification-of-knowledge/</guid>
      <description>&lt;p&gt;There are some philosophical &amp;ldquo;ideals&amp;rdquo;, which has been identified since antiquity and to attainment (or approaching of) which people are striving ever since.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;To see things as they really are.&lt;/li&gt;
&lt;li&gt;To do things just right way.&lt;/li&gt;
&lt;li&gt;To find an optimum or a &amp;ldquo;perfection&amp;rdquo;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Perfection has been famously defined as &amp;ldquo;when there is nothing else (more) to take away (to remove)&amp;rdquo;.&lt;/p&gt;
&lt;p&gt;Modern meme-based socially-constructed (by retarded majority) social concensus frown upon &amp;ldquo;perfectionism&amp;rdquo; and sees it as the inhibition to &amp;ldquo;getting shit done&amp;rdquo;. They are not wrong, though.  Approaching a perfection (finding a local optimum) is a very different process from just putting together some slop. Yes, indeed, &amp;ldquo;perfection is the enemy of good-enough&amp;rdquo;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Bullshit Bullshit Everywhere</title>
      <link>https://lngnmn2.github.io/articles/bullshit-bullshit-everywhere/</link>
      <pubDate>Sat, 31 May 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/bullshit-bullshit-everywhere/</guid>
      <description>&lt;p&gt;&amp;ldquo;The Darwin Gödel Machine: AI that improves itself by rewriting its own code&amp;rdquo;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://sakana.ai/dgm/&#34;&gt;https://sakana.ai/dgm/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;There is what is actually going on. A model trained on a large amount code is, in principle, no different from any other LLMs &amp;ndash; it is just a statistical model that predicts the next token based on the previous ones. It does not understand the code it spews out, it does not &amp;ldquo;know&amp;rdquo; what it is doing. These are just mathematical procedures (not even functions) &amp;ndash; given an input encoded in a particular way, it produces an output, not even the same for the same input.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Carmack On Ai</title>
      <link>https://lngnmn2.github.io/articles/carmack-on-ai/</link>
      <pubDate>Sat, 24 May 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/carmack-on-ai/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://twitter.com/ID_AA_Carmack/status/1925710474366034326&#34;&gt;https://twitter.com/ID_AA_Carmack/status/1925710474366034326&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;I have read the notes. they are a mess.&lt;/p&gt;
&lt;p&gt;For me, Carmack, aside from being a legend, is sort of Goggins of &lt;em&gt;imperative procedural programming&lt;/em&gt;, who learned everything by doing without studying the theories first.&lt;/p&gt;
&lt;p&gt;His ultimate strength is, it seems, in a &lt;em&gt;focused doing&lt;/em&gt;, ploughing through a problem, if you will, without being exceedingly dramatic.&lt;/p&gt;
&lt;p&gt;Learning from experience (actual trails and errors and quick feedback loops) and gradual improvement of his own &amp;ldquo;emergent&amp;rdquo; intuitive understanding &amp;ndash; ones own mental model of how things should be done.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Reasoning Models Don&#39;t Always Say What They  Think</title>
      <link>https://lngnmn2.github.io/articles/models-dont-say-think/</link>
      <pubDate>Fri, 04 Apr 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/models-dont-say-think/</guid>
      <description>Antrophic, please</description>
    </item>
    <item>
      <title>Fuck This Shit</title>
      <link>https://lngnmn2.github.io/articles/anthropic-tracing-thoughts/</link>
      <pubDate>Fri, 28 Mar 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/anthropic-tracing-thoughts/</guid>
      <description>bullshit, bullshit, bullshit...</description>
    </item>
    <item>
      <title>Large Ladyboy Models</title>
      <link>https://lngnmn2.github.io/articles/large-ladyboy-models/</link>
      <pubDate>Sun, 09 Mar 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/large-ladyboy-models/</guid>
      <description>&lt;p&gt;Classy Andrej is making shilling videos from Thailand (he leaked his location in the video ) targeting normies (the previous set of videos has been partially filmed in Japan. Andrej is living a truly digital nomad&amp;rsquo;s life).&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=EWvNQjAaOHw&#34;&gt;https://www.youtube.com/watch?v=EWvNQjAaOHw&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Why would he shill? Well, he and guys like him made a lot of promises, not to us (who tf cares), but to the money guys, that this particular technology will completely transform the world, and that &lt;em&gt;they&lt;/em&gt; are the very top guys in the field, so money shall be given to them (to the affiliated companies and entities).&lt;/p&gt;</description>
    </item>
    <item>
      <title>Coding with LLMs</title>
      <link>https://lngnmn2.github.io/articles/llm-coding/</link>
      <pubDate>Mon, 24 Feb 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/llm-coding/</guid>
      <description>&lt;p&gt;DESCRIPTION: Idiots, idiots everywhere.&lt;/p&gt;
&lt;p&gt;Now I can accurately summarize what coding using LLMs &lt;em&gt;actually /is&lt;/em&gt; in just a few sentences.&lt;/p&gt;
&lt;p&gt;Recall how people usually describe a code maintenance job: &lt;em&gt;we have this code to run, while the original developers are gone and leave us no design documentation&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;This hypothetical situation is exactly what you get when an LLM finished spewing out the slop: you now have some code, very cheap, even for free, but it is &lt;em&gt;not yours&lt;/em&gt;, the underlying understanding (of the whys) &lt;em&gt;is not in your head&lt;/em&gt;, and the original developer is already gone. Disappeared.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Grok3</title>
      <link>https://lngnmn2.github.io/articles/grok3/</link>
      <pubDate>Tue, 18 Feb 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/grok3/</guid>
      <description>Smoke and memes.</description>
    </item>
    <item>
      <title>AI Slop</title>
      <link>https://lngnmn2.github.io/articles/ai-slop/</link>
      <pubDate>Sun, 16 Feb 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/ai-slop/</guid>
      <description>&lt;p&gt;&lt;strong&gt;slop&lt;/strong&gt; &lt;em&gt;noun&lt;/em&gt;&lt;/p&gt;
&lt;h4 id=&#34;cambridge-dictionary&#34;&gt;Cambridge dictionary&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;food that is more liquid than it should be and is therefore unpleasant&lt;/li&gt;
&lt;li&gt;liquid or wet food waste, especially when it is fed to animals&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;oxford-learner-s-dictionary&#34;&gt;Oxford Learner&amp;rsquo;s Dictionary&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;​waste food, sometimes fed to animals&lt;/li&gt;
&lt;li&gt;liquid or partly liquid waste, for example urine or dirty water from baths&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;There is also a very related term &amp;ldquo;&lt;em&gt;goyslop&lt;/em&gt;&amp;rdquo; from internet sewers (losers are always looking for someone to blame and hate [instead of themselves]).&lt;/p&gt;</description>
    </item>
    <item>
      <title>Deepseek In Action</title>
      <link>https://lngnmn2.github.io/articles/deepseek-in-action/</link>
      <pubDate>Sat, 15 Feb 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/deepseek-in-action/</guid>
      <description>Look, ma, no reasoning.</description>
    </item>
    <item>
      <title>Reasoning LLMs</title>
      <link>https://lngnmn2.github.io/articles/reasoning-llms/</link>
      <pubDate>Tue, 11 Feb 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/reasoning-llms/</guid>
      <description>&lt;p&gt;AUTHOR: &amp;lt;lngnmn2@yahoo.com&amp;gt;&lt;/p&gt;
&lt;p&gt;When I was a kid &lt;del&gt;they told me not to stare at the sun&lt;/del&gt; I had this vision, that the brain structures are sort of like trees, while the &amp;ldquo;branches&amp;rdquo; are just like patches thorough our yard after fresh snow.&lt;/p&gt;
&lt;p&gt;Some of them remain thin, just someone walked across it absentmindedly, some gets broadened by a heavy re-use. Who would plow through a fresh snow while one could take follow the path that is already here.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Deepseek R1</title>
      <link>https://lngnmn2.github.io/articles/deepseek-r1/</link>
      <pubDate>Sun, 26 Jan 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/deepseek-r1/</guid>
      <description>&lt;p&gt;DESCRIPTION: Memes and mirrors.&lt;/p&gt;
&lt;p&gt;Nowadays things are moving way too fast. It is not just controlled trial-and-error, it is literally throwing everything at the wall (to see what sticks).&lt;/p&gt;
&lt;p&gt;It started with that meme &amp;ldquo;Attention Is All You Need&amp;rdquo;, when they just came up with an &amp;ldquo;architecture&amp;rdquo; that sticks.&lt;/p&gt;
&lt;p&gt;That &amp;ldquo;attention&amp;rdquo; and &amp;ldquo;multi head attention&amp;rdquo; turned out to be just a few additional layers of a particular kind.&lt;/p&gt;
&lt;p&gt;No one can explain the actual mechanisms of how exactly or even &lt;em&gt;why&lt;/em&gt; the layers are as they are (abstract bullshit aside). While the general idea was to mimic some specialized brain centers (the key to understand how it works), the actual code was merely &amp;ldquo;buffers&amp;rdquo;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>LLMs und AI</title>
      <link>https://lngnmn2.github.io/articles/llms-und-ai/</link>
      <pubDate>Wed, 20 Nov 2024 16:53:58 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/llms-und-ai/</guid>
      <description>&lt;p&gt;DATE: &lt;span class=&#34;timestamp-wrapper&#34;&gt;&lt;span class=&#34;timestamp&#34;&gt;&amp;lt;2024-11-20 Wed&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Lets write a few paragraphs which will destroy the current LLM narrative (naive bullshit), while neither any single piece  nor the whole article can be refuted.&lt;/p&gt;
&lt;p&gt;This is a high-level proper (classic Eastern) philosophy, which is many levels away from simple logical forms, but it still can be reduced to these, if one wants to. The Proper Philosophy isn&amp;rsquo;t dead, not even it is dying. It cannot, lmao.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Attention Is All bullshit.</title>
      <link>https://lngnmn2.github.io/articles/attention-is-all-bullshit/</link>
      <pubDate>Tue, 04 Jun 2024 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/attention-is-all-bullshit/</guid>
      <description>To see things as they really are.</description>
    </item>
    <item>
      <title>LLM Philosophy 101</title>
      <link>https://lngnmn2.github.io/articles/llm-phil-101/</link>
      <pubDate>Tue, 21 May 2024 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/llm-phil-101/</guid>
      <description>Bullshit, bullshit, bullshit... (K-PAX)</description>
    </item>
    <item>
      <title>LLM predictions</title>
      <link>https://lngnmn2.github.io/articles/llm-predictions/</link>
      <pubDate>Wed, 08 Nov 2023 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/llm-predictions/</guid>
      <description>Modern alchemy and astrology using Linea Algebra on Nvidia GPUs</description>
    </item>
    <item>
      <title>Transformers bullshit everywhere</title>
      <link>https://lngnmn2.github.io/articles/transformer-bullshit/</link>
      <pubDate>Fri, 06 Oct 2023 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/transformer-bullshit/</guid>
      <description>No, there is no hyper-sheres in the Universe, sorry, Chuds.</description>
    </item>
    <item>
      <title>LLMS For Coding</title>
      <link>https://lngnmn2.github.io/articles/llms-for-coding/</link>
      <pubDate>Sat, 26 Aug 2023 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/llms-for-coding/</guid>
      <description>&lt;p&gt;Today &lt;a href=&#34;https://news.ycombinator.com/&#34;&gt;https://news.ycombinator.com/&lt;/a&gt; is glowing bright with AI memes and buzzwords like a Christmas tree. Everyone is there, including billion dollar corporations announcing a &amp;ldquo;CodeLama-34b&amp;rdquo; which is &lt;em&gt;&amp;ldquo;designed for general code synthesis and understanding.&amp;rdquo;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;First of all, I personaly do not want to rely in any part of my life on any &amp;ldquo;synthesized&amp;rdquo; (and &amp;ldquo;understood&amp;rdquo; software, and demand an explicit opt-out. Yes, yes, I know.&lt;/p&gt;
&lt;p&gt;If I have any understanding of these subjects at all, this is a bubble and &lt;em&gt;irrational exuberance&lt;/em&gt;. Lets try to unpack &amp;ldquo;the whys&amp;rdquo;.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
