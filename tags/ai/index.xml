<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>AI on Notes from the digital underground by Lngnmn</title>
    <link>https://lngnmn2.github.io/tags/ai/</link>
    <description>Recent content in AI on Notes from the digital underground by Lngnmn</description>
    <generator>Hugo -- 0.147.7</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 11 Sep 2025 09:58:30 +0545</lastBuildDate>
    <atom:link href="https://lngnmn2.github.io/tags/ai/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>the LLM upanishad</title>
      <link>https://lngnmn2.github.io/articles/the-llm-upanishad/</link>
      <pubDate>Thu, 11 Sep 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/the-llm-upanishad/</guid>
      <description>The modern Eastern philosophy</description>
    </item>
    <item>
      <title>Let the bubble burst, for Crist&#39;s sake!</title>
      <link>https://lngnmn2.github.io/articles/let-the-bubble-burst/</link>
      <pubDate>Sun, 03 Aug 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/let-the-bubble-burst/</guid>
      <description>Look, ma, no errors!</description>
    </item>
    <item>
      <title>The Knowledge Work Bubble</title>
      <link>https://lngnmn2.github.io/articles/the-knowledge-work-bubble/</link>
      <pubDate>Sat, 02 Aug 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/the-knowledge-work-bubble/</guid>
      <description>  The end of the &amp;#34;knowledge work&amp;#34; as we know it.
  </description>
    </item>
    <item>
      <title>Now What?</title>
      <link>https://lngnmn2.github.io/articles/now-what/</link>
      <pubDate>Sun, 13 Jul 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/now-what/</guid>
      <description>&lt;p&gt;I understand a lot of complex things, maybe because I spent my whole life trying to understand and explain things around me, since 4 year old, when I used no name every single car on the road in a small Ukrainian Steel and mining town where I was born.&lt;/p&gt;
&lt;p&gt;Understanding cannot be &amp;ldquo;outsourced&amp;rdquo; or even safely &amp;ldquo;delegated&amp;rdquo;. One will always end up with a sort of &amp;ldquo;tragedy of commons&amp;rdquo;, when sterilization and modern technologies produced packaged foods which slowly but surely kill you. This is what happens when you &amp;ldquo;delegate&amp;rdquo; your own understanding.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Software In The Era of AI</title>
      <link>https://lngnmn2.github.io/articles/software-intheeraof-ai/</link>
      <pubDate>Thu, 19 Jun 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/software-intheeraof-ai/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=LCEmiRjPEtQ&#34;&gt;https://www.youtube.com/watch?v=LCEmiRjPEtQ&lt;/a&gt; and, of course, the No.1 spot on the Chuddie safe space  &lt;a href=&#34;https://news.ycombinator.com/item?id=44314423&#34;&gt;https://news.ycombinator.com/item?id=44314423&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Karpathy is shilling &amp;ldquo;Cursor&amp;rdquo; and other cloud-based mettered AI services (which have to pay back their debts). Probably has an interest in it and some other meme AI startups. Nothing to see here.&lt;/p&gt;
&lt;p&gt;We should some day know which marketing &amp;ldquo;genious&amp;rdquo; came up with this &amp;ldquo;winning strategy&amp;rdquo; &amp;ndash; to metter every single token (byte) and try to sell this to corporations. Corporations do not want to be mettered like that, they want to metter normies, the way Cellular operators do, and they never use any normies plans themselves.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Yes, it is time to scream and  panic</title>
      <link>https://lngnmn2.github.io/articles/the-very-serious-post/</link>
      <pubDate>Thu, 12 Jun 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/the-very-serious-post/</guid>
      <description>Sometimes not getting what you what is itself a biggest strike of luck.</description>
    </item>
    <item>
      <title>Vibe coding explained</title>
      <link>https://lngnmn2.github.io/articles/vibe-coding-explained/</link>
      <pubDate>Fri, 06 Jun 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/vibe-coding-explained/</guid>
      <description>Idiots, idiots everywhere...</description>
    </item>
    <item>
      <title>Enshittification Of Knowledge</title>
      <link>https://lngnmn2.github.io/articles/enshittification-of-knowledge/</link>
      <pubDate>Tue, 03 Jun 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/enshittification-of-knowledge/</guid>
      <description>&lt;p&gt;There are some philosophical &amp;ldquo;ideals&amp;rdquo;, which has been identified since antiquity and to attainment (or approaching of) which people are striving ever since.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;To see things as they really are.&lt;/li&gt;
&lt;li&gt;To do things just right way.&lt;/li&gt;
&lt;li&gt;To find an optimum or a &amp;ldquo;perfection&amp;rdquo;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Perfection has been famously defined as &amp;ldquo;when there is nothing else (more) to take away (to remove)&amp;rdquo;.&lt;/p&gt;
&lt;p&gt;Modern meme-based socially-constructed (by retarded majority) social concensus frown upon &amp;ldquo;perfectionism&amp;rdquo; and sees it as the inhibition to &amp;ldquo;getting shit done&amp;rdquo;. They are not wrong, though.  Approaching a perfection (finding a local optimum) is a very different process from just putting together some slop. Yes, indeed, &amp;ldquo;perfection is the enemy of good-enough&amp;rdquo;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Bullshit Bullshit Everywhere</title>
      <link>https://lngnmn2.github.io/articles/bullshit-bullshit-everywhere/</link>
      <pubDate>Sat, 31 May 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/bullshit-bullshit-everywhere/</guid>
      <description>&lt;p&gt;&amp;ldquo;The Darwin Gödel Machine: AI that improves itself by rewriting its own code&amp;rdquo;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://sakana.ai/dgm/&#34;&gt;https://sakana.ai/dgm/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;There is what is actually going on. A model trained on a large amount code is, in principle, no different from any other LLMs &amp;ndash; it is just a statistical model that predicts the next token based on the previous ones. It does not understand the code it spews out, it does not &amp;ldquo;know&amp;rdquo; what it is doing. These are just mathematical procedures (not even functions) &amp;ndash; given an input encoded in a particular way, it produces an output, not even the same for the same input.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Carmack On Ai</title>
      <link>https://lngnmn2.github.io/articles/carmack-on-ai/</link>
      <pubDate>Sat, 24 May 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/carmack-on-ai/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://twitter.com/ID_AA_Carmack/status/1925710474366034326&#34;&gt;https://twitter.com/ID_AA_Carmack/status/1925710474366034326&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;I have read the notes. they are a mess.&lt;/p&gt;
&lt;p&gt;For me, Carmack, aside from being a legend, is sort of Goggins of &lt;em&gt;imperative procedural programming&lt;/em&gt;, who learned everything by doing without studying the theories first.&lt;/p&gt;
&lt;p&gt;His ultimate strength is, it seems, in a &lt;em&gt;focused doing&lt;/em&gt;, ploughing through a problem, if you will, without being exceedingly dramatic.&lt;/p&gt;
&lt;p&gt;Learning from experience (actual trails and errors and quick feedback loops) and gradual improvement of his own &amp;ldquo;emergent&amp;rdquo; intuitive understanding &amp;ndash; ones own mental model of how things should be done.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Reasoning Models Don&#39;t Always Say What They  Think</title>
      <link>https://lngnmn2.github.io/articles/models-dont-say-think/</link>
      <pubDate>Fri, 04 Apr 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/models-dont-say-think/</guid>
      <description>Antrophic, please</description>
    </item>
    <item>
      <title>Fuck This Shit</title>
      <link>https://lngnmn2.github.io/articles/anthropic-tracing-thoughts/</link>
      <pubDate>Fri, 28 Mar 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/anthropic-tracing-thoughts/</guid>
      <description>bullshit, bullshit, bullshit...</description>
    </item>
    <item>
      <title>Large Ladyboy Models</title>
      <link>https://lngnmn2.github.io/articles/large-ladyboy-models/</link>
      <pubDate>Sun, 09 Mar 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/large-ladyboy-models/</guid>
      <description>&lt;p&gt;Classy Andrej is making shilling videos from Thailand (he leaked his location in the video ) targeting normies (the previous set of videos has been partially filmed in Japan. Andrej is living a truly digital nomad&amp;rsquo;s life).&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=EWvNQjAaOHw&#34;&gt;https://www.youtube.com/watch?v=EWvNQjAaOHw&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Why would he shill? Well, he and guys like him made a lot of promises, not to us (who tf cares), but to the money guys, that this particular technology will completely transform the world, and that &lt;em&gt;they&lt;/em&gt; are the very top guys in the field, so money shall be given to them (to the affiliated companies and entities).&lt;/p&gt;</description>
    </item>
    <item>
      <title>Coding with LLMs</title>
      <link>https://lngnmn2.github.io/articles/llm-coding/</link>
      <pubDate>Mon, 24 Feb 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/llm-coding/</guid>
      <description>&lt;p&gt;DESCRIPTION: Idiots, idiots everywhere.&lt;/p&gt;
&lt;p&gt;Now I can accurately summarize what coding using LLMs &lt;em&gt;actually /is&lt;/em&gt; in just a few sentences.&lt;/p&gt;
&lt;p&gt;Recall how people usually describe a code maintenance job: &lt;em&gt;we have this code to run, while the original developers are gone and leave us no design documentation&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;This hypothetical situation is exactly what you get when an LLM finished spewing out the slop: you now have some code, very cheap, even for free, but it is &lt;em&gt;not yours&lt;/em&gt;, the underlying understanding (of the whys) &lt;em&gt;is not in your head&lt;/em&gt;, and the original developer is already gone. Disappeared.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Grok3</title>
      <link>https://lngnmn2.github.io/articles/grok3/</link>
      <pubDate>Tue, 18 Feb 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/grok3/</guid>
      <description>Smoke and memes.</description>
    </item>
    <item>
      <title>AI Slop</title>
      <link>https://lngnmn2.github.io/articles/ai-slop/</link>
      <pubDate>Sun, 16 Feb 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/ai-slop/</guid>
      <description>&lt;p&gt;&lt;strong&gt;slop&lt;/strong&gt; &lt;em&gt;noun&lt;/em&gt;&lt;/p&gt;
&lt;h4 id=&#34;cambridge-dictionary&#34;&gt;Cambridge dictionary&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;food that is more liquid than it should be and is therefore unpleasant&lt;/li&gt;
&lt;li&gt;liquid or wet food waste, especially when it is fed to animals&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;oxford-learner-s-dictionary&#34;&gt;Oxford Learner&amp;rsquo;s Dictionary&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;​waste food, sometimes fed to animals&lt;/li&gt;
&lt;li&gt;liquid or partly liquid waste, for example urine or dirty water from baths&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;There is also a very related term &amp;ldquo;&lt;em&gt;goyslop&lt;/em&gt;&amp;rdquo; from internet sewers (losers are always looking for someone to blame and hate [instead of themselves]).&lt;/p&gt;</description>
    </item>
    <item>
      <title>Deepseek In Action</title>
      <link>https://lngnmn2.github.io/articles/deepseek-in-action/</link>
      <pubDate>Sat, 15 Feb 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/deepseek-in-action/</guid>
      <description>Look, ma, no reasoning.</description>
    </item>
    <item>
      <title>Reasoning LLMs</title>
      <link>https://lngnmn2.github.io/articles/reasoning-llms/</link>
      <pubDate>Tue, 11 Feb 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/reasoning-llms/</guid>
      <description>&lt;p&gt;AUTHOR: &amp;lt;lngnmn2@yahoo.com&amp;gt;&lt;/p&gt;
&lt;p&gt;When I was a kid &lt;del&gt;they told me not to stare at the sun&lt;/del&gt; I had this vision, that the brain structures are sort of like trees, while the &amp;ldquo;branches&amp;rdquo; are just like patches thorough our yard after fresh snow.&lt;/p&gt;
&lt;p&gt;Some of them remain thin, just someone walked across it absentmindedly, some gets broadened by a heavy re-use. Who would plow through a fresh snow while one could take follow the path that is already here.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Deepseek R1</title>
      <link>https://lngnmn2.github.io/articles/deepseek-r1/</link>
      <pubDate>Sun, 26 Jan 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/deepseek-r1/</guid>
      <description>&lt;p&gt;DESCRIPTION: Memes and mirrors.&lt;/p&gt;
&lt;p&gt;Nowadays things are moving way too fast. It is not just controlled trial-and-error, it is literally throwing everything at the wall (to see what sticks).&lt;/p&gt;
&lt;p&gt;It started with that meme &amp;ldquo;Attention Is All You Need&amp;rdquo;, when they just came up with an &amp;ldquo;architecture&amp;rdquo; that sticks.&lt;/p&gt;
&lt;p&gt;That &amp;ldquo;attention&amp;rdquo; and &amp;ldquo;multi head attention&amp;rdquo; turned out to be just a few additional layers of a particular kind.&lt;/p&gt;
&lt;p&gt;No one can explain the actual mechanisms of how exactly or even &lt;em&gt;why&lt;/em&gt; the layers are as they are (abstract bullshit aside). While the general idea was to mimic some specialized brain centers (the key to understand how it works), the actual code was merely &amp;ldquo;buffers&amp;rdquo;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>LLMs und AI</title>
      <link>https://lngnmn2.github.io/articles/llms-und-ai/</link>
      <pubDate>Wed, 20 Nov 2024 16:53:58 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/llms-und-ai/</guid>
      <description>&lt;p&gt;DATE: &lt;span class=&#34;timestamp-wrapper&#34;&gt;&lt;span class=&#34;timestamp&#34;&gt;&amp;lt;2024-11-20 Wed&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Lets write a few paragraphs which will destroy the current LLM narrative (naive bullshit), while neither any single piece  nor the whole article can be refuted.&lt;/p&gt;
&lt;p&gt;This is a high-level proper (classic Eastern) philosophy, which is many levels away from simple logical forms, but it still can be reduced to these, if one wants to. The Proper Philosophy isn&amp;rsquo;t dead, not even it is dying. It cannot, lmao.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Attention Is All bullshit.</title>
      <link>https://lngnmn2.github.io/articles/attention-is-all-bullshit/</link>
      <pubDate>Tue, 04 Jun 2024 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/attention-is-all-bullshit/</guid>
      <description>To see things as they really are.</description>
    </item>
    <item>
      <title>LLM Philosophy 101</title>
      <link>https://lngnmn2.github.io/articles/llm-phil-101/</link>
      <pubDate>Tue, 21 May 2024 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/llm-phil-101/</guid>
      <description>Bullshit, bullshit, bullshit... (K-PAX)</description>
    </item>
    <item>
      <title>LLM predictions</title>
      <link>https://lngnmn2.github.io/articles/llm-predictions/</link>
      <pubDate>Wed, 08 Nov 2023 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/llm-predictions/</guid>
      <description>Modern alchemy and astrology using Linea Algebra on Nvidia GPUs</description>
    </item>
    <item>
      <title>Transformers bullshit everywhere</title>
      <link>https://lngnmn2.github.io/articles/transformer-bullshit/</link>
      <pubDate>Fri, 06 Oct 2023 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/transformer-bullshit/</guid>
      <description>No, there is no hyper-sheres in the Universe, sorry, Chuds.</description>
    </item>
    <item>
      <title>LLMS For Coding</title>
      <link>https://lngnmn2.github.io/articles/llms-for-coding/</link>
      <pubDate>Sat, 26 Aug 2023 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/llms-for-coding/</guid>
      <description>&lt;p&gt;Today &lt;a href=&#34;https://news.ycombinator.com/&#34;&gt;https://news.ycombinator.com/&lt;/a&gt; is glowing bright with AI memes and buzzwords like a Christmas tree. Everyone is there, including billion dollar corporations announcing a &amp;ldquo;CodeLama-34b&amp;rdquo; which is &lt;em&gt;&amp;ldquo;designed for general code synthesis and understanding.&amp;rdquo;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;First of all, I personaly do not want to rely in any part of my life on any &amp;ldquo;synthesized&amp;rdquo; (and &amp;ldquo;understood&amp;rdquo; software, and demand an explicit opt-out. Yes, yes, I know.&lt;/p&gt;
&lt;p&gt;If I have any understanding of these subjects at all, this is a bubble and &lt;em&gt;irrational exuberance&lt;/em&gt;. Lets try to unpack &amp;ldquo;the whys&amp;rdquo;.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
