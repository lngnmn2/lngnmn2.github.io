<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>LLM on Notes from the digital underground by Lngnmn</title>
    <link>https://lngnmn2.github.io/tags/llm/</link>
    <description>Recent content in LLM on Notes from the digital underground by Lngnmn</description>
    <generator>Hugo -- 0.148.2</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 13 Jan 2026 15:09:49 +0545</lastBuildDate>
    <atom:link href="https://lngnmn2.github.io/tags/llm/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Wake up, Neo</title>
      <link>https://lngnmn2.github.io/articles/wake-up-neo/</link>
      <pubDate>Tue, 13 Jan 2026 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/wake-up-neo/</guid>
      <description>&lt;p&gt;So, this is &lt;em&gt;the why&lt;/em&gt; all the megacorps suddenly building AI data-centers and purchase nuclear power plants to feed them with electricity and book all the DRAM and VRAM production and in the whole world.&lt;/p&gt;
&lt;p&gt;The reason is this. Remember Google reCAPTCHA - that window when you are forced to select all the cars or traffic lights to view the website you wanted (for an expected revard through a dopamine release).&lt;/p&gt;</description>
    </item>
    <item>
      <title>We are fucked</title>
      <link>https://lngnmn2.github.io/articles/we-are-fucked/</link>
      <pubDate>Sun, 11 Jan 2026 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/we-are-fucked/</guid>
      <description>&lt;p&gt;We are fucked. This time for real.&lt;/p&gt;
&lt;p&gt;I just had some 3 hours Gemini3 session of some 50 interactions, which bootstrapped for me a prototype of the project I wished to build for years. &lt;strong&gt;In Just  a Couple of Hours&lt;/strong&gt;, motherfuckers.&lt;/p&gt;
&lt;p&gt;Yes, the code won&amp;rsquo;t compile, and will be full of subtle hallucinations, The markdown files would be more of &amp;ldquo;wishful thinking&amp;rdquo; and &amp;ldquo;confirmation bias&amp;rdquo;  than a formal, rigorous description of the code, but still.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Cognitive Biases At Work</title>
      <link>https://lngnmn2.github.io/articles/cognitive-biases-at-work/</link>
      <pubDate>Fri, 09 Jan 2026 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/cognitive-biases-at-work/</guid>
      <description>&lt;p&gt;There is some output (slop) I got from my recent sessions (yes, yes, I am guilty and ashamed):&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-markdown&#34; data-lang=&#34;markdown&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;### Validation Summary
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;I have verified the implementation across the &lt;span style=&#34;font-weight:bold&#34;&gt;**Functional Core**&lt;/span&gt; (Domain) and the &lt;span style=&#34;font-weight:bold&#34;&gt;**Imperative Shell**&lt;/span&gt; (Infrastructure &lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;&amp;amp;&lt;/span&gt; Interface), confirming that the code doesn&amp;#39;t just &amp;#34;look&amp;#34; right but functionally enforces the rules.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;font-weight:bold&#34;&gt;**1. Domain Layer (Functional Core)**&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;font-weight:bold&#34;&gt;**Strict Encapsulation:**&lt;/span&gt; All primitives (&lt;span style=&#34;color:#e6db74&#34;&gt;`f64`&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;`String`&lt;/span&gt;) are wrapped in &lt;span style=&#34;font-weight:bold&#34;&gt;**Newtypes**&lt;/span&gt; (&lt;span style=&#34;color:#e6db74&#34;&gt;`Price`&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;`Quantity`&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;`Symbol`&lt;/span&gt;) with private fields.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;font-weight:bold&#34;&gt;**Correctness by Construction:**&lt;/span&gt; &lt;span style=&#34;font-weight:bold&#34;&gt;**Smart Constructors**&lt;/span&gt; (&lt;span style=&#34;color:#e6db74&#34;&gt;`new() -&amp;gt; Result`&lt;/span&gt;) enforce invariants (e.g., price &amp;gt; 0, symbol format). It is impossible to instantiate invalid domain objects.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;font-weight:bold&#34;&gt;**Algebraic Data Types:**&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;`Order`&lt;/span&gt; is a Sum Type (Enum) of Product Types (Structs), exhaustively modeling valid order strategies (&lt;span style=&#34;color:#e6db74&#34;&gt;`Market`&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;`Limit`&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;`StopLimit`&lt;/span&gt;).
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;font-weight:bold&#34;&gt;**Typestate Pattern:**&lt;/span&gt; The &lt;span style=&#34;color:#e6db74&#34;&gt;`OrderBuilder`&lt;/span&gt; uses zero-sized types (&lt;span style=&#34;color:#e6db74&#34;&gt;`NoSymbol`&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;`WithSymbol`&lt;/span&gt;) to enforce the order of operations at compile time. You cannot build an order without mandatory fields.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;font-weight:bold&#34;&gt;**Error Handling:**&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;`DomainError`&lt;/span&gt; is a specific Sum Type using &lt;span style=&#34;color:#e6db74&#34;&gt;`thiserror`&lt;/span&gt;, implementing the &amp;#34;Make Illegal States Unrepresentable&amp;#34; rule.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;font-weight:bold&#34;&gt;**2. Infrastructure &amp;amp; Interface (Imperative Shell)**&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;font-weight:bold&#34;&gt;**Hexagonal Architecture:**&lt;/span&gt; The &lt;span style=&#34;color:#e6db74&#34;&gt;`client`&lt;/span&gt; module acts as an &lt;span style=&#34;font-weight:bold&#34;&gt;**Adapter**&lt;/span&gt;, translating domain objects into Binance API calls. It isolates side effects (I/O, Time, Crypto).
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;   &lt;span style=&#34;font-weight:bold&#34;&gt;**Functional REPL:**&lt;/span&gt; The &lt;span style=&#34;color:#e6db74&#34;&gt;`repl`&lt;/span&gt; module implements the Command Interpreter using &lt;span style=&#34;font-weight:bold&#34;&gt;**Functional Streams**&lt;/span&gt; (&lt;span style=&#34;color:#e6db74&#34;&gt;`input_stream().map().for_each()`&lt;/span&gt;), strictly avoiding imperative &lt;span style=&#34;color:#e6db74&#34;&gt;`while`&lt;/span&gt; loops.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;   &lt;span style=&#34;font-weight:bold&#34;&gt;**Security:**&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;`Credentials`&lt;/span&gt; are handled via &lt;span style=&#34;color:#e6db74&#34;&gt;`secrets`&lt;/span&gt; module, and signing logic (&lt;span style=&#34;color:#e6db74&#34;&gt;`compute_signature`&lt;/span&gt;) is a pure function.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;font-weight:bold&#34;&gt;**3. Verification (Tests)**&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;   &lt;span style=&#34;font-weight:bold&#34;&gt;**Pass Rate:**&lt;/span&gt; &lt;span style=&#34;font-weight:bold&#34;&gt;**124/124 tests passed**&lt;/span&gt;.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;   &lt;span style=&#34;font-weight:bold&#34;&gt;**Coverage:**&lt;/span&gt; The test suite is organized into &amp;#34;Stories&amp;#34; (e.g., &lt;span style=&#34;color:#e6db74&#34;&gt;`story_user_places_valid_limit_sell_order_gtc`&lt;/span&gt;), directly testing the Business Rules and Workflows against the domain logic.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;The project is correctly set up as a mathematically rigorous, type-driven trading assistant.
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;here is another one:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Extreme Programming Applied</title>
      <link>https://lngnmn2.github.io/articles/extreme-programming-applied/</link>
      <pubDate>Sun, 04 Jan 2026 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/extreme-programming-applied/</guid>
      <description>&lt;p&gt;Things begin to move way too fast, at least for me.&lt;/p&gt;
&lt;p&gt;There is some amazing fact, which shows that an intuitive understanding can also be valid.&lt;/p&gt;
&lt;p&gt;I remember reading the memest book of the time &amp;ndash;  &lt;em&gt;&amp;ldquo;eXtreme Programming Explained&amp;rdquo;&lt;/em&gt; (by still sober and sane Kent Beck), and trying (probably just like everyone else at the time) to &amp;ldquo;distill&amp;rdquo; some grains of &amp;ldquo;wisdom&amp;rdquo; from the torrents of &amp;ldquo;mostly bullshit&amp;rdquo;.&lt;/p&gt;
&lt;p&gt;The real take away from the whole manuscript (at least for me) was that writing &lt;em&gt;&lt;strong&gt;tests&lt;/strong&gt;&lt;/em&gt; is what really change everything, in particular, they are, indeed, allow quick, &lt;em&gt;confident&lt;/em&gt; and &amp;ldquo;cheap&amp;rdquo; refactoring and thus really &amp;ldquo;facilitate change&amp;rdquo; and, yes, actually speed up the development process.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Some Aha Moments</title>
      <link>https://lngnmn2.github.io/articles/some-aha-moments/</link>
      <pubDate>Fri, 02 Jan 2026 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/some-aha-moments/</guid>
      <description>&lt;p&gt;For a quite long time already I sort of &amp;ldquo;ran in the background&amp;rdquo; this question  &amp;ndash; &amp;ldquo;how they bridge the semantic gap between verbiage and the code?&amp;rdquo; In the context of a well-written textbook (extremely rare, just 50 or so in existence) the code examples immediately follow or even intersperse the explanations. Most of the internet content is nothing like that.&lt;/p&gt;
&lt;p&gt;The semantically closest entities in the code are specially formatted comments that are used to generate [an appearance of] &amp;ldquo;documentation&amp;rdquo;, with a modern fashion to mention some core concepts being used. This kind of well-documented (enforced by the strict rules) code one would find in placed like Google&amp;rsquo;s monorepo and other megacorp inner code bases.  Almost noting this strict can be found on Github (the primary source of all training).&lt;/p&gt;</description>
    </item>
    <item>
      <title>Vibecoding explained</title>
      <link>https://lngnmn2.github.io/articles/vibecoding-explained/</link>
      <pubDate>Sun, 21 Dec 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/vibecoding-explained/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://karpathy.bearblog.dev/year-in-review-2025/&#34;&gt;https://karpathy.bearblog.dev/year-in-review-2025/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;In this episode @karpathy blessed us all with another blogpost. While his wording is much more careful and even nuanced, there is still a lot of bullshit in it. It way less outrageous bullshit as in the Friedman &lt;em&gt;poocast&lt;/em&gt;  and around that time, but still.&lt;/p&gt;
&lt;p&gt;Here are some excerpts:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;With vibe coding, programming is not strictly reserved for highly trained professionals, it is something anyone can do.&lt;/p&gt;
&lt;p&gt;&amp;hellip;&lt;/p&gt;
&lt;p&gt;But not only does vibe coding empower regular people to approach programming, it empowers trained professionals to write a lot more (vibe coded) software that would otherwise never be written.&lt;/p&gt;</description>
    </item>
    <item>
      <title>  LLMs: The &#34;Good&#34; Parts
  </title>
      <link>https://lngnmn2.github.io/articles/llms-the-good-parts/</link>
      <pubDate>Tue, 16 Dec 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/llms-the-good-parts/</guid>
      <description>&lt;p&gt;Okay, lets look at the &amp;ldquo;better side&amp;rdquo; of things.&lt;/p&gt;
&lt;p&gt;The good thing about using LLMs is that you do not have to deal with &lt;em&gt;Google Search&lt;/em&gt; and any fucking &lt;em&gt;Social Media&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Imagine a painfully typical scenario &amp;ndash; you want to clarify or better understand something you already vaguely knew or at least aware of. You type a query into Google Search, and you get&amp;hellip; a fucking CEO fucked-up list of Ad-infested links to various web pages &amp;ndash; either the  largest social media containment boards (StackOverflow, Reddit, Medium), or some CEO&amp;rsquo;d blogs, when you are either  greeted with a wall of text (usually directly pasted from tutorials and docs), ads, pop-ups, and other distractions, or some narcissistic asshole&amp;rsquo;s low-effort over-verbose crappy verbiage about &amp;ldquo;how fucking smart he is&amp;rdquo;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>And this is exactly how</title>
      <link>https://lngnmn2.github.io/articles/this-is-exactly-how/</link>
      <pubDate>Tue, 16 Dec 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/this-is-exactly-how/</guid>
      <description>&lt;p&gt;Just like a spontaneous, &amp;ldquo;natural and organic&amp;rdquo; continuation to the previous post (which implicitly confirm that it has properly captured at least &lt;em&gt;some&lt;/em&gt; aspect of reality [as it is]).&lt;/p&gt;
&lt;p&gt;I have had to delete some nice movies in order to download and try that over-hyped &amp;ldquo;5M downloads&amp;rdquo; Nvidia&amp;rsquo;s meme-model &lt;code&gt;Nemotron-3-Nano-30B&amp;quot;&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;I have a small set of highly sophisticated prompts which I use to measure the apparent quality of a generated slop of the  4 major data-center-sized LLMs.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Idiots, Idiots Everywhere.jpg</title>
      <link>https://lngnmn2.github.io/articles/idiots-idiots-everywhere/</link>
      <pubDate>Wed, 10 Dec 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/idiots-idiots-everywhere/</guid>
      <description>&lt;p&gt;Everything is broken and idiots are everywhere. There is a clown which attention whoring, sorry, publicly arguing (and gaining a lot of unwarranted attention) that one shall vapecode in &lt;code&gt;C&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://news.ycombinator.com/item?id=46207505&#34;&gt;https://news.ycombinator.com/item?id=46207505&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Basically, making such a claim is idiotic on so many levels that it is hard to know where to start. Almost the whole of  &lt;em&gt;classic&lt;/em&gt; non-bullshit programming language theory research is about how to correctly address C&amp;rsquo;s shortcomings and &lt;em&gt;semantic&lt;/em&gt; issues, and how to avoid the inherent in the design of the language (and the ABI) problems.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Some Final Words</title>
      <link>https://lngnmn2.github.io/articles/some-final-words/</link>
      <pubDate>Tue, 09 Dec 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/some-final-words/</guid>
      <description>&lt;p&gt;So, it seems like this is the time to somehow sum up the current AI hype (way through the roof) and the immediate and long term &lt;em&gt;consequences&lt;/em&gt; of it.&lt;/p&gt;
&lt;p&gt;First of all, a proper education &amp;ndash; studying the fundamental underlying principles instead of particulars &amp;ndash;  which used to be an unofficial mantra of MIT, pays off again.&lt;/p&gt;
&lt;p&gt;One just sets particular constraints to a coding LLM and use it as a whole-data-center-powerful &lt;em&gt;constraint satisfaction engine&lt;/em&gt; that spews out a slop, which then can be used for rapid prototyping and minimal-viable products. The properly constrained slop can even be used as the basis of a project, which then undergo proper &lt;em&gt;continuous improvement&lt;/em&gt; and &lt;em&gt;refinement&lt;/em&gt; by a human expert (who knows the &lt;em&gt;whys&lt;/em&gt;).&lt;/p&gt;</description>
    </item>
    <item>
      <title>The new Brahmanas</title>
      <link>https://lngnmn2.github.io/articles/the-new-brahmanas/</link>
      <pubDate>Wed, 03 Dec 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/the-new-brahmanas/</guid>
      <description>&lt;p&gt;I think I have seen this before. Once in Varanasi, wandering around book stalls (most titles already &amp;ldquo;tourist books&amp;rdquo;, &amp;ndash; oversimplified and westernized &amp;ldquo;tantric&amp;rdquo; bullshit), I found a whole book by some  local publisher which describes in a minute details one single Brahmanic ritual (an elaborate sacrifice) which last almost a whole day. Hundreds of ingredients are being burn in a precise sequence, or rather a simphony of chants. motions, gestures (mudras) and many other elaborate details. The priests (brahmans) definitely knew what they are doing and why exactly this way is the only proper way.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Aaand boom!</title>
      <link>https://lngnmn2.github.io/articles/aaand-boom/</link>
      <pubDate>Wed, 12 Nov 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/aaand-boom/</guid>
      <description>&lt;p&gt;The thing I hate the most is when some of these fucking YouTube content &amp;ldquo;creators&amp;rdquo;, which decide to monetize an AI coding clickbait with low-effort subpar videos, say &amp;ldquo;aaand boom!&amp;rdquo; when another chunk of a slop has been spewed out by an AI.&lt;/p&gt;
&lt;p&gt;This &amp;ldquo;boom!&amp;rdquo; is an insult to the last 60 years of the programming languages research (including the math-based theory) and to the &amp;ldquo;old sages&amp;rdquo; which crafted their languages and standard libraries in the best possible, &amp;ldquo;just right&amp;rdquo;, perfect, in the sense of &amp;ldquo;nothing more to take away&amp;rdquo;  by surveying all the available literature, non-bullshit papers and spending months of anguish and self-doubt.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Bullshit, bullshit, bullshit</title>
      <link>https://lngnmn2.github.io/articles/bullshit-bullshit-bullshit/</link>
      <pubDate>Mon, 03 Nov 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/bullshit-bullshit-bullshit/</guid>
      <description>&lt;p&gt;So, things begin to move a lot faster and much bigger, and there is something to realize about this unpreceded AI bubble.&lt;/p&gt;
&lt;p&gt;We will consider only the underlaying fundamental principles, not the particular implementation details, &amp;ldquo;architectures&amp;rdquo; and what not..&lt;/p&gt;
&lt;p&gt;There are four major aspects to any LLM model &amp;ndash; the training process, the &amp;ldquo;architecture&amp;rdquo; (the structural shape) of a model, the &amp;quot; post-training tuning&amp;quot; (lobotomy) of the model and the inference process.&lt;/p&gt;</description>
    </item>
    <item>
      <title>My First Llm Experience</title>
      <link>https://lngnmn2.github.io/articles/my-first-llm-experience/</link>
      <pubDate>Fri, 10 Oct 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/my-first-llm-experience/</guid>
      <description>&lt;p&gt;Today I am sentimental, so lets reminisce a little about my first experience with LLMs.&lt;/p&gt;
&lt;p&gt;I found some early article about people using something called &lt;code&gt;llama.cpp&lt;/code&gt;  to run models locally on their machines. Some overconfident retard in another blogpost wrote that the &amp;ldquo;best model&amp;rdquo; and &amp;ldquo;by far&amp;rdquo; is &lt;em&gt;Mistral&lt;/em&gt; &amp;ldquo;from Nvidia&amp;rdquo;, and it is supposed to be best &lt;em&gt;because/&lt;/em&gt; it is  allegedly from Nvidia (they have some partnership, investment, I suppose). So I compiled the code (old habits) and downloaded the model from the &lt;code&gt;hugginface&lt;/code&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>LLMs and AI so far</title>
      <link>https://lngnmn2.github.io/articles/llms-and-ai-so-far/</link>
      <pubDate>Sat, 04 Oct 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/llms-and-ai-so-far/</guid>
      <description>&lt;p&gt;Let&amp;rsquo;s summarize the current state of Large Language Models (LLMs) and so called &amp;ldquo;Artificial Intelligence&amp;rdquo; (AI) as of October 2025.&lt;/p&gt;
&lt;p&gt;They all are still just [estimated] probabilities of the next token, given the &amp;ldquo;context&amp;rdquo;.&lt;/p&gt;
&lt;p&gt;This implies no &amp;ldquo;knowledge&amp;rdquo; or &amp;ldquo;understanding&amp;rdquo; [of any kind] whatsoever. Nothing can be taken as &amp;ldquo;true&amp;rdquo; or even &amp;ldquo;correct&amp;rdquo; or &amp;ldquo;accurate&amp;rdquo;.&lt;/p&gt;
&lt;p&gt;All the talks about &amp;ldquo;knowledge in the weights&amp;rdquo; or &amp;ldquo;knowledge encoded within the network&amp;rdquo; is just bullshit.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Probabilistic bullshit</title>
      <link>https://lngnmn2.github.io/articles/probabilistic-bullshit/</link>
      <pubDate>Tue, 30 Sep 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/probabilistic-bullshit/</guid>
      <description>&lt;p&gt;Look, ma, a new episode just dropped! This one is full of shit to the brim. Even more so than prof.  &lt;em&gt;Ellen Langer&lt;/em&gt; who cannot stay within a context and claimed that 1+1 = 10 &lt;em&gt;because&lt;/em&gt; in the &lt;em&gt;binary notation it looks like 10 in decimal&lt;/em&gt;&amp;hellip; anyway, whatever.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=MlmFj1-mOtg&#34;&gt;https://www.youtube.com/watch?v=MlmFj1-mOtg&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;No, the brain &lt;em&gt;ain&amp;rsquo;t computing  any hecking probabilities&lt;/em&gt;. It is not a Bayesian machine. It is not a prediction machine. It is not a simulator. It is not a statistical engine.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Prompt engineers, lmao</title>
      <link>https://lngnmn2.github.io/articles/prompt-engineers-lmao/</link>
      <pubDate>Fri, 26 Sep 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/prompt-engineers-lmao/</guid>
      <description>&lt;p&gt;Time waits for no one, the race to the bottom accelerates faster than ever, and the &amp;ldquo;future&amp;rdquo; is now. Competition is severe and mostly meaningless, as in some third-world criminal infested ghetto. This is what LLMs turned our world into.&lt;/p&gt;
&lt;p&gt;So, lets &amp;ldquo;pee on&amp;rdquo; so called &amp;ldquo;prompt engineers&amp;rdquo;, in the &lt;code&gt;4chan&lt;/code&gt; parlance, of course..&lt;/p&gt;
&lt;p&gt;Here is my benchmark prompt to evaluate performance of LLMs. All the &amp;ldquo;simple&amp;rdquo; offline models fail miserably, and only Grok and Gemini can produce something adequate.  Claude is also good, but it is supposed to be the best, being trained especially for code generation.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Fuck you, gemini</title>
      <link>https://lngnmn2.github.io/articles/fuck-you-gemini/</link>
      <pubDate>Thu, 25 Sep 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/fuck-you-gemini/</guid>
      <description>&lt;p&gt;FUCK THIS SHIT!&lt;/p&gt;
&lt;p&gt;No, really. It just hallucinated a non-existent package, with such a confidence lmao&lt;/p&gt;
&lt;p&gt;Yes, yes, I know, it cannot know anything about &amp;ldquo;existence&amp;rdquo;, but at least these dorks do not &amp;ldquo;deserve&amp;rdquo; the exuberant money they got paid.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Uniform Code Block Rendering in Eww and Shr
To get syntax highlighting in eww and shr, you need to use a package that intercepts &amp;lt;code&amp;gt; and &amp;lt;pre&amp;gt; tags and applies Emacs&amp;rsquo;s built-in font-locking. The eww-code-blocks-mode is a good choice for this.&lt;/p&gt;</description>
    </item>
    <item>
      <title>DeepMind and OpenAI win Gold</title>
      <link>https://lngnmn2.github.io/articles/deepmind-and-openai-win-gold/</link>
      <pubDate>Thu, 18 Sep 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/deepmind-and-openai-win-gold/</guid>
      <description>Look, ma, another day another bullshit.</description>
    </item>
    <item>
      <title>Let me show you something</title>
      <link>https://lngnmn2.github.io/articles/let-me-show-you-something/</link>
      <pubDate>Tue, 16 Sep 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/let-me-show-you-something/</guid>
      <description>To see things as they [realy] are</description>
    </item>
    <item>
      <title>Defeating Nondeterminism, my ass</title>
      <link>https://lngnmn2.github.io/articles/defeating-nondeterminism/</link>
      <pubDate>Thu, 11 Sep 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/defeating-nondeterminism/</guid>
      <description>LOL, LMAO even</description>
    </item>
    <item>
      <title>the LLM upanishad</title>
      <link>https://lngnmn2.github.io/articles/the-llm-upanishad/</link>
      <pubDate>Thu, 11 Sep 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/the-llm-upanishad/</guid>
      <description>The modern Eastern philosophy</description>
    </item>
    <item>
      <title>LLM (and Math) Philosophy 202</title>
      <link>https://lngnmn2.github.io/articles/llm-and-math-phil-202/</link>
      <pubDate>Mon, 08 Sep 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/llm-and-math-phil-202/</guid>
      <description>&lt;p&gt;DESCRIPTION: Idiots, idiots everywhere.jpg&lt;/p&gt;
&lt;p&gt;I am getting old and my cognitive abilities are slowly declining, and I will have no pension or social security, so I need a &amp;ldquo;Turing Award&amp;rdquo; or something. (only partially kidding).  And, yes, I &amp;ldquo;hacked&amp;rdquo; these &amp;ldquo;longevity&amp;rdquo; memes and &amp;ldquo;protocols&amp;rdquo;, but seems like fighting an increase in entropy and the second law of thermodynamics is not that efficient as some meme-guys claim on YouTube ).&lt;/p&gt;
&lt;p&gt;So, lets settle one fundamental meme-question once and for all, so we can let it all go and focus on &amp;ldquo;bio-hacking&amp;rdquo; and what not.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Humanties in 30 seconds</title>
      <link>https://lngnmn2.github.io/articles/humanties-in-30-seconds/</link>
      <pubDate>Mon, 25 Aug 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/humanties-in-30-seconds/</guid>
      <description>&lt;p&gt;So-called &lt;em&gt;Humanties&lt;/em&gt; (as the way of  producing a sectarian socially constructed pretentious abstract verbiage) are done for. At least none of them deserve that high upper-middle-class social status anymore.&lt;/p&gt;
&lt;p&gt;Yes, you have to be &lt;em&gt;actually smart&lt;/em&gt; to ask the &amp;ldquo;right questions&amp;rdquo; (be a prompt &lt;em&gt;engineers&lt;/em&gt; LMAO!), but still. Watch how it spews out an outstanding &amp;ldquo;paper&amp;rdquo; in 30 seconds.&lt;/p&gt;
&lt;p&gt;I really don&amp;rsquo;t know what I have studied (wasted my life) for. Yes, yes, these are not &lt;em&gt;final&lt;/em&gt; answers, and it missed subtleties, and more accurate, insightful formulations, but who needs them anymore?&lt;/p&gt;</description>
    </item>
    <item>
      <title>It Feels Like A Cheating Because It Is</title>
      <link>https://lngnmn2.github.io/articles/it-feels-like-cheating-because-it-is/</link>
      <pubDate>Mon, 11 Aug 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/it-feels-like-cheating-because-it-is/</guid>
      <description>&lt;p&gt;The purpose of examination in a college or university setting is to empirically verify that a student has &lt;em&gt;his own genuine understanding&lt;/em&gt; and could actually apply it. It is that simple.&lt;/p&gt;
&lt;p&gt;This is why some courses even allow to bring a textbook to an exam, because if one does not [already] understand the principles and techniques, the textbook is of no use.&lt;/p&gt;
&lt;p&gt;However, bringing pocket calculators, smartphones is considered a cheating, precisely because by using these devises one could &lt;em&gt;appear&lt;/em&gt; as possessing  one&amp;rsquo;s own understanding.&lt;/p&gt;</description>
    </item>
    <item>
      <title>openai-gpt-oss-20b</title>
      <link>https://lngnmn2.github.io/articles/openai-gpt-oss-20b/</link>
      <pubDate>Wed, 06 Aug 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/openai-gpt-oss-20b/</guid>
      <description>&lt;p&gt;OpenAI has recently benedicted us with a 20 billion parameter &amp;ldquo;open source&amp;rdquo; model, which is a significant step up from the previous 7 billion parameter model. This model is designed to be more efficient and effective in understanding and generating human-like text, or rather to &lt;em&gt;appear&lt;/em&gt; to do so.&lt;/p&gt;
&lt;p&gt;It is a total crap, by the way, at least compared to the online free-tier GROK (which is also very basic and limited). It is, obviously, &amp;ldquo;competing&amp;rdquo; with the DeepSeek&amp;rsquo;s &amp;ldquo;open source&amp;rdquo; offerings, and have a very similar &amp;ldquo;feel&amp;rdquo;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Let the bubble burst, for Crist&#39;s sake!</title>
      <link>https://lngnmn2.github.io/articles/let-the-bubble-burst/</link>
      <pubDate>Sun, 03 Aug 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/let-the-bubble-burst/</guid>
      <description>Look, ma, no errors!</description>
    </item>
    <item>
      <title>The Knowledge Work Bubble</title>
      <link>https://lngnmn2.github.io/articles/the-knowledge-work-bubble/</link>
      <pubDate>Sat, 02 Aug 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/the-knowledge-work-bubble/</guid>
      <description>  The end of the &amp;#34;knowledge work&amp;#34; as we know it.
  </description>
    </item>
    <item>
      <title>Look ma, 100x engineers</title>
      <link>https://lngnmn2.github.io/articles/100x-engineering/</link>
      <pubDate>Wed, 23 Jul 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/100x-engineering/</guid>
      <description>Another day -- another bullshit</description>
    </item>
    <item>
      <title>Gold medal-level performance at IMO.</title>
      <link>https://lngnmn2.github.io/articles/openai-gold-medal/</link>
      <pubDate>Sun, 20 Jul 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/openai-gold-medal/</guid>
      <description>Memes, memes everywhere.</description>
    </item>
    <item>
      <title>Grok4 launch video</title>
      <link>https://lngnmn2.github.io/articles/grok4-launch-video/</link>
      <pubDate>Thu, 10 Jul 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/grok4-launch-video/</guid>
      <description>&lt;p&gt;So I watched some. The launch video I mean. Closed the frame when they began that &amp;ldquo;voice&amp;rdquo; thing.&lt;/p&gt;
&lt;p&gt;The PhD. level across all subjects is just a meme. I can easily be shown by asking the question that require a beyond memorizing textbooks reasoning.&lt;/p&gt;
&lt;p&gt;I don&amp;rsquo;t want to &amp;ldquo;register&amp;rdquo; for &amp;ldquo;Grok4&amp;rdquo;, but here are some example problems which will break the &amp;ldquo;PhD level&amp;rdquo; meme.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;A recursive functions in, say, Ocaml, or  Scala, without explicitly mentioning the accumulator pattern as the required way to avoid stack overflows on languages which does not do TCO at the compile time. This is  very basic stuff, which all &amp;ldquo;PhDs&amp;rdquo; have to know. The inner &lt;em&gt;lambda&lt;/em&gt; with an extra argument, and the  &amp;ldquo;trampoline&amp;rdquo;  is such a classic pattern that some compliers do it automatically. Again, &lt;em&gt;without mentioning it&lt;/em&gt; the model will fail by writing non TCO code .&lt;/p&gt;</description>
    </item>
    <item>
      <title>Illusion Of Intelligence</title>
      <link>https://lngnmn2.github.io/articles/illusion-of-intelligence/</link>
      <pubDate>Sat, 05 Jul 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/illusion-of-intelligence/</guid>
      <description>&lt;p&gt;There is a very simple trick to  break the illusion and to see through &amp;ldquo;the veil of Maya&amp;rdquo;.&lt;/p&gt;
&lt;p&gt;Locally-run models, like &lt;em&gt;Deepseek-R1-14b-0528&lt;/em&gt; (at full &lt;code&gt;fp16&lt;/code&gt; quantization),  which is the best I could have,  produce vastly different &amp;ldquo;answers&amp;rdquo; for exactly the same prompt not just between two runs, but if one uses a different math library stack (like recompiling with forcing Intel MKL).&lt;/p&gt;
&lt;p&gt;Every  time  we run a prompt a reasonably good model  spits out something which &amp;ldquo;looks very reasonable&amp;rdquo;, (unless your are an actual expert in the field), because it captures  &amp;ldquo;common sense&amp;rdquo;, expressed in the training data.&lt;/p&gt;</description>
    </item>
    <item>
      <title>The Age Of Copy-Pasting</title>
      <link>https://lngnmn2.github.io/articles/the-age-of-copy-pasting/</link>
      <pubDate>Fri, 04 Jul 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/the-age-of-copy-pasting/</guid>
      <description>&lt;p&gt;Just a few years ago we had that running joke &amp;ldquo;pasting code from stackoverflow&amp;rdquo;, which describes a coder, who just find and copy-paste the code &amp;ndash; the &amp;ldquo;right&amp;rdquo; answers &amp;ndash; without any understanding whatsoever.&lt;/p&gt;
&lt;p&gt;It is well-understood at the level of cognitive neuroscience, that skipping the part of &amp;ldquo;doing it yourself&amp;rdquo; (and so never getting these necessary &lt;em&gt;10,000&lt;/em&gt; hours of a &lt;em&gt;deliberate practice&lt;/em&gt;) basically makes us dumber (lots of  supporting MIT studies, google them) and ultimately wastes out time, the only irreplaceable and the most valuable resource we ever had.&lt;/p&gt;</description>
    </item>
    <item>
      <title>LLMs-generated Rust code</title>
      <link>https://lngnmn2.github.io/articles/llms-generated-rust/</link>
      <pubDate>Wed, 25 Jun 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/llms-generated-rust/</guid>
      <description>The ultimate evidence of the principal inability for a probability-based generating algorithm to come up with something that passes the type checker.</description>
    </item>
    <item>
      <title>Software In The Era of AI</title>
      <link>https://lngnmn2.github.io/articles/software-intheeraof-ai/</link>
      <pubDate>Thu, 19 Jun 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/software-intheeraof-ai/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=LCEmiRjPEtQ&#34;&gt;https://www.youtube.com/watch?v=LCEmiRjPEtQ&lt;/a&gt; and, of course, the No.1 spot on the Chuddie safe space  &lt;a href=&#34;https://news.ycombinator.com/item?id=44314423&#34;&gt;https://news.ycombinator.com/item?id=44314423&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Karpathy is shilling &amp;ldquo;Cursor&amp;rdquo; and other cloud-based mettered AI services (which have to pay back their debts). Probably has an interest in it and some other meme AI startups. Nothing to see here.&lt;/p&gt;
&lt;p&gt;We should some day know which marketing &amp;ldquo;genious&amp;rdquo; came up with this &amp;ldquo;winning strategy&amp;rdquo; &amp;ndash; to metter every single token (byte) and try to sell this to corporations. Corporations do not want to be mettered like that, they want to metter normies, the way Cellular operators do, and they never use any normies plans themselves.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Yes, it is time to scream and  panic</title>
      <link>https://lngnmn2.github.io/articles/the-very-serious-post/</link>
      <pubDate>Thu, 12 Jun 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/the-very-serious-post/</guid>
      <description>Sometimes not getting what you what is itself a biggest strike of luck.</description>
    </item>
    <item>
      <title>Just a Packaged Slop</title>
      <link>https://lngnmn2.github.io/articles/just-a-packaged-slop/</link>
      <pubDate>Wed, 30 Apr 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/just-a-packaged-slop/</guid>
      <description>&lt;p&gt;DESCRIPTION: Removing the veil of Maya to see things as they really are&lt;/p&gt;
&lt;p&gt;What to do when you have discovered that something is wrong with the world? Nothing, this happens all the time.&lt;/p&gt;
&lt;p&gt;Everything is wrong with C++, but everyone uses it, everything is wrong with packaged food, especially the toxic crap Nestle produced, and everyone is buying it. Nothing can be done.&lt;/p&gt;
&lt;p&gt;Here is what is wrong with your &amp;ldquo;AI&amp;rdquo; and &amp;ldquo;LLMs&amp;rdquo;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Large Ladyboy Models</title>
      <link>https://lngnmn2.github.io/articles/large-ladyboy-models/</link>
      <pubDate>Sun, 09 Mar 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/large-ladyboy-models/</guid>
      <description>&lt;p&gt;Classy Andrej is making shilling videos from Thailand (he leaked his location in the video ) targeting normies (the previous set of videos has been partially filmed in Japan. Andrej is living a truly digital nomad&amp;rsquo;s life).&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=EWvNQjAaOHw&#34;&gt;https://www.youtube.com/watch?v=EWvNQjAaOHw&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Why would he shill? Well, he and guys like him made a lot of promises, not to us (who tf cares), but to the money guys, that this particular technology will completely transform the world, and that &lt;em&gt;they&lt;/em&gt; are the very top guys in the field, so money shall be given to them (to the affiliated companies and entities).&lt;/p&gt;</description>
    </item>
    <item>
      <title>Coding with LLMs</title>
      <link>https://lngnmn2.github.io/articles/llm-coding/</link>
      <pubDate>Mon, 24 Feb 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/llm-coding/</guid>
      <description>&lt;p&gt;DESCRIPTION: Idiots, idiots everywhere.&lt;/p&gt;
&lt;p&gt;Now I can accurately summarize what coding using LLMs &lt;em&gt;actually /is&lt;/em&gt; in just a few sentences.&lt;/p&gt;
&lt;p&gt;Recall how people usually describe a code maintenance job: &lt;em&gt;we have this code to run, while the original developers are gone and leave us no design documentation&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;This hypothetical situation is exactly what you get when an LLM finished spewing out the slop: you now have some code, very cheap, even for free, but it is &lt;em&gt;not yours&lt;/em&gt;, the underlying understanding (of the whys) &lt;em&gt;is not in your head&lt;/em&gt;, and the original developer is already gone. Disappeared.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Grok3</title>
      <link>https://lngnmn2.github.io/articles/grok3/</link>
      <pubDate>Tue, 18 Feb 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/grok3/</guid>
      <description>Smoke and memes.</description>
    </item>
    <item>
      <title>AI Slop</title>
      <link>https://lngnmn2.github.io/articles/ai-slop/</link>
      <pubDate>Sun, 16 Feb 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/ai-slop/</guid>
      <description>&lt;p&gt;&lt;strong&gt;slop&lt;/strong&gt; &lt;em&gt;noun&lt;/em&gt;&lt;/p&gt;
&lt;h4 id=&#34;cambridge-dictionary&#34;&gt;Cambridge dictionary&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;food that is more liquid than it should be and is therefore unpleasant&lt;/li&gt;
&lt;li&gt;liquid or wet food waste, especially when it is fed to animals&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;oxford-learner-s-dictionary&#34;&gt;Oxford Learner&amp;rsquo;s Dictionary&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;â€‹waste food, sometimes fed to animals&lt;/li&gt;
&lt;li&gt;liquid or partly liquid waste, for example urine or dirty water from baths&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;There is also a very related term &amp;ldquo;&lt;em&gt;goyslop&lt;/em&gt;&amp;rdquo; from internet sewers (losers are always looking for someone to blame and hate [instead of themselves]).&lt;/p&gt;</description>
    </item>
    <item>
      <title>Deepseek In Action</title>
      <link>https://lngnmn2.github.io/articles/deepseek-in-action/</link>
      <pubDate>Sat, 15 Feb 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/deepseek-in-action/</guid>
      <description>Look, ma, no reasoning.</description>
    </item>
    <item>
      <title>Reasoning LLMs</title>
      <link>https://lngnmn2.github.io/articles/reasoning-llms/</link>
      <pubDate>Tue, 11 Feb 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/reasoning-llms/</guid>
      <description>&lt;p&gt;AUTHOR: &amp;lt;lngnmn2@yahoo.com&amp;gt;&lt;/p&gt;
&lt;p&gt;When I was a kid &lt;del&gt;they told me not to stare at the sun&lt;/del&gt; I had this vision, that the brain structures are sort of like trees, while the &amp;ldquo;branches&amp;rdquo; are just like patches thorough our yard after fresh snow.&lt;/p&gt;
&lt;p&gt;Some of them remain thin, just someone walked across it absentmindedly, some gets broadened by a heavy re-use. Who would plow through a fresh snow while one could take follow the path that is already here.&lt;/p&gt;</description>
    </item>
    <item>
      <title>OpenAI vs. Deepseek</title>
      <link>https://lngnmn2.github.io/articles/openai-vs-deepseek/</link>
      <pubDate>Thu, 30 Jan 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/openai-vs-deepseek/</guid>
      <description>When shit reached the fan.</description>
    </item>
    <item>
      <title>Deepseek R1</title>
      <link>https://lngnmn2.github.io/articles/deepseek-r1/</link>
      <pubDate>Sun, 26 Jan 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/deepseek-r1/</guid>
      <description>&lt;p&gt;DESCRIPTION: Memes and mirrors.&lt;/p&gt;
&lt;p&gt;Nowadays things are moving way too fast. It is not just controlled trial-and-error, it is literally throwing everything at the wall (to see what sticks).&lt;/p&gt;
&lt;p&gt;It started with that meme &amp;ldquo;Attention Is All You Need&amp;rdquo;, when they just came up with an &amp;ldquo;architecture&amp;rdquo; that sticks.&lt;/p&gt;
&lt;p&gt;That &amp;ldquo;attention&amp;rdquo; and &amp;ldquo;multi head attention&amp;rdquo; turned out to be just a few additional layers of a particular kind.&lt;/p&gt;
&lt;p&gt;No one can explain the actual mechanisms of how exactly or even &lt;em&gt;why&lt;/em&gt; the layers are as they are (abstract bullshit aside). While the general idea was to mimic some specialized brain centers (the key to understand how it works), the actual code was merely &amp;ldquo;buffers&amp;rdquo;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Haskell and a LLM</title>
      <link>https://lngnmn2.github.io/articles/haskell-llm/</link>
      <pubDate>Sun, 26 Jan 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/haskell-llm/</guid>
      <description>&lt;p&gt;This is the difference between a LLM and an expert. An LLM spews out a &amp;ldquo;propaganda&amp;rdquo; from the web.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-markdown&#34; data-lang=&#34;markdown&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;### what are the unique properties of a Haskell program
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;1.&lt;/span&gt; &lt;span style=&#34;font-weight:bold&#34;&gt;**Statically Typed**&lt;/span&gt;: Haskell has a strong, static type system that ensures type safety at compile time.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;2.&lt;/span&gt; &lt;span style=&#34;font-weight:bold&#34;&gt;**Purely Functional**&lt;/span&gt;: Haskell programs are expressions, and functions have no side effects. This leads to code that&amp;#39;s easy to reason about, test, and debug.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;3.&lt;/span&gt; &lt;span style=&#34;font-weight:bold&#34;&gt;**Lazy Evaluation**&lt;/span&gt;: Haskell uses lazy evaluation, meaning it only evaluates expressions when their results are needed. This can lead to more efficient programs and allows for elegant solutions like infinite data structures.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;4.&lt;/span&gt; &lt;span style=&#34;font-weight:bold&#34;&gt;**Higher-Order Functions**&lt;/span&gt;: Functions in Haskell are first-class citizens, meaning they can be passed as arguments, returned as results, and stored in data structures.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;5.&lt;/span&gt; &lt;span style=&#34;font-weight:bold&#34;&gt;**Type Classes**&lt;/span&gt;: Haskell&amp;#39;s type classes (similar to interfaces in other languages) enable ad-hoc polymorphism, allowing related types to be treated uniformly.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;6.&lt;/span&gt; &lt;span style=&#34;font-weight:bold&#34;&gt;**Module System**&lt;/span&gt;: Haskell has a rich module system that supports abstract data types, hiding implementation details, and organizing code into reusable components.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;7.&lt;/span&gt; &lt;span style=&#34;font-weight:bold&#34;&gt;**Concurrency and Parallelism**&lt;/span&gt;: Haskell provides lightweight threads and a high-level concurrency abstraction called Software Transactional Memory (STM), along with support for parallel programming using the Glasgow Haskell Compiler (GHC).
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;8.&lt;/span&gt; &lt;span style=&#34;font-weight:bold&#34;&gt;**Rich Ecosystem**&lt;/span&gt;: Haskell has a vibrant community and a large ecosystem of libraries (via Hackage) for various domains, making it practical for real-world applications.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;###
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Here is what an expert answer could be:&lt;/p&gt;</description>
    </item>
    <item>
      <title>L. Tao on LLMs</title>
      <link>https://lngnmn2.github.io/articles/tao-on-llms/</link>
      <pubDate>Thu, 13 Jun 2024 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/tao-on-llms/</guid>
      <description>LLMa is an IQ test and a midwit filter.</description>
    </item>
    <item>
      <title>Selfawareness</title>
      <link>https://lngnmn2.github.io/articles/selfawareness/</link>
      <pubDate>Mon, 20 Nov 2023 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/selfawareness/</guid>
      <description>Abstract bullshitting is not enough.</description>
    </item>
    <item>
      <title>LLM predictions</title>
      <link>https://lngnmn2.github.io/articles/llm-predictions/</link>
      <pubDate>Wed, 08 Nov 2023 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/llm-predictions/</guid>
      <description>Modern alchemy and astrology using Linea Algebra on Nvidia GPUs</description>
    </item>
    <item>
      <title>LLMS For Coding</title>
      <link>https://lngnmn2.github.io/articles/llms-for-coding/</link>
      <pubDate>Sat, 26 Aug 2023 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/llms-for-coding/</guid>
      <description>&lt;p&gt;Today &lt;a href=&#34;https://news.ycombinator.com/&#34;&gt;https://news.ycombinator.com/&lt;/a&gt; is glowing bright with AI memes and buzzwords like a Christmas tree. Everyone is there, including billion dollar corporations announcing a &amp;ldquo;CodeLama-34b&amp;rdquo; which is &lt;em&gt;&amp;ldquo;designed for general code synthesis and understanding.&amp;rdquo;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;First of all, I personaly do not want to rely in any part of my life on any &amp;ldquo;synthesized&amp;rdquo; (and &amp;ldquo;understood&amp;rdquo; software, and demand an explicit opt-out. Yes, yes, I know.&lt;/p&gt;
&lt;p&gt;If I have any understanding of these subjects at all, this is a bubble and &lt;em&gt;irrational exuberance&lt;/em&gt;. Lets try to unpack &amp;ldquo;the whys&amp;rdquo;.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
