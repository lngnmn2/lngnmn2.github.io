<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>LLM on Notes from the digital underground by Lngnmn</title>
    <link>https://lngnmn2.github.io/tags/llm/</link>
    <description>Recent content in LLM on Notes from the digital underground by Lngnmn</description>
    <generator>Hugo -- 0.131.0</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 24 Feb 2025 19:57:45 +0545</lastBuildDate>
    <atom:link href="https://lngnmn2.github.io/tags/llm/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Coding with LLMs</title>
      <link>https://lngnmn2.github.io/articles/llm-coding/</link>
      <pubDate>Mon, 24 Feb 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/llm-coding/</guid>
      <description>DESCRIPTION: Idiots, idiots everywhere.
Now I can accurately summarize what coding using LLMs actually /is in just a few sentences.
Recall how people usually describe a code maintenance job: we have this code to run, while the original developers are gone and leave us no design documentation.
This hypothetical situation is exactly what you get when an LLM finished spewing out the slop: you now have some code, very cheap, even for free, but it is not yours, the underlying understanding (of the whys) is not in your head, and the original developer is already gone.</description>
    </item>
    <item>
      <title>Grok3</title>
      <link>https://lngnmn2.github.io/articles/grok3/</link>
      <pubDate>Tue, 18 Feb 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/grok3/</guid>
      <description>Smoke and memes.</description>
    </item>
    <item>
      <title>AI Slop</title>
      <link>https://lngnmn2.github.io/articles/ai-slop/</link>
      <pubDate>Sun, 16 Feb 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/ai-slop/</guid>
      <description>slop noun
Cambridge dictionary food that is more liquid than it should be and is therefore unpleasant liquid or wet food waste, especially when it is fed to animals Oxford Learner&amp;rsquo;s Dictionary â€‹waste food, sometimes fed to animals liquid or partly liquid waste, for example urine or dirty water from baths There is also a very related term &amp;ldquo;goyslop&amp;rdquo; from internet sewers (losers are always looking for someone to blame and hate [instead of themselves]).</description>
    </item>
    <item>
      <title>Deepseek In Action</title>
      <link>https://lngnmn2.github.io/articles/deepseek-in-action/</link>
      <pubDate>Sat, 15 Feb 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/deepseek-in-action/</guid>
      <description>Look, ma, no reasoning.</description>
    </item>
    <item>
      <title>Reasoning LLMs</title>
      <link>https://lngnmn2.github.io/articles/reasoning-llms/</link>
      <pubDate>Tue, 11 Feb 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/reasoning-llms/</guid>
      <description>AUTHOR: &amp;lt;lngnmn2@yahoo.com&amp;gt;
When I was a kid they told me not to stare at the sun I had this vision, that the brain structures are sort of like trees, while the &amp;ldquo;branches&amp;rdquo; are just like patches thorough our yard after fresh snow.
Some of them remain thin, just someone walked across it absentmindedly, some gets broadened by a heavy re-use. Who would plow through a fresh snow while one could take follow the path that is already here.</description>
    </item>
    <item>
      <title>OpenAI vs. Deepseek</title>
      <link>https://lngnmn2.github.io/articles/openai-vs-deepseek/</link>
      <pubDate>Thu, 30 Jan 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/openai-vs-deepseek/</guid>
      <description>When shit reached the fan.</description>
    </item>
    <item>
      <title>Deepseek R1</title>
      <link>https://lngnmn2.github.io/articles/deepseek-r1/</link>
      <pubDate>Sun, 26 Jan 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/deepseek-r1/</guid>
      <description>DESCRIPTION: Memes and mirrors.
Nowadays things are moving way too fast. It is not just controlled trial-and-error, it is literally throwing everything at the wall (to see what sticks).
It started with that meme &amp;ldquo;Attention Is All You Need&amp;rdquo;, when they just came up with an &amp;ldquo;architecture&amp;rdquo; that sticks.
That &amp;ldquo;attention&amp;rdquo; and &amp;ldquo;multi head attention&amp;rdquo; turned out to be just a few additional layers of a particular kind.
No one can explain the actual mechanisms of how exactly or even why the layers are as they are (abstract bullshit aside).</description>
    </item>
    <item>
      <title>Haskell and a LLM</title>
      <link>https://lngnmn2.github.io/articles/haskell-llm/</link>
      <pubDate>Sun, 26 Jan 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/haskell-llm/</guid>
      <description>This is the difference between a LLM and an expert. An LLM spews out a &amp;ldquo;propaganda&amp;rdquo; from the web.
### what are the unique properties of a Haskell program 1. **Statically Typed**: Haskell has a strong, static type system that ensures type safety at compile time. 2. **Purely Functional**: Haskell programs are expressions, and functions have no side effects. This leads to code that&amp;#39;s easy to reason about, test, and debug.</description>
    </item>
    <item>
      <title>L. Tao on LLMs</title>
      <link>https://lngnmn2.github.io/articles/tao-on-llms/</link>
      <pubDate>Thu, 13 Jun 2024 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/tao-on-llms/</guid>
      <description>LLMa is an IQ test and a midwit filter.</description>
    </item>
    <item>
      <title>Selfawareness</title>
      <link>https://lngnmn2.github.io/articles/selfawareness/</link>
      <pubDate>Mon, 20 Nov 2023 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/selfawareness/</guid>
      <description>Abstract bullshitting is not enough.</description>
    </item>
    <item>
      <title>LLM predictions</title>
      <link>https://lngnmn2.github.io/articles/llm-predictions/</link>
      <pubDate>Wed, 08 Nov 2023 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/llm-predictions/</guid>
      <description>Modern alchemy and astrology using Linea Algebra on Nvidia GPUs</description>
    </item>
    <item>
      <title>LLMS For Coding</title>
      <link>https://lngnmn2.github.io/articles/llms-for-coding/</link>
      <pubDate>Sat, 26 Aug 2023 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/llms-for-coding/</guid>
      <description>Today https://news.ycombinator.com/ is glowing bright with AI memes and buzzwords like a Christmas tree. Everyone is there, including billion dollar corporations announcing a &amp;ldquo;CodeLama-34b&amp;rdquo; which is &amp;ldquo;designed for general code synthesis and understanding.&amp;rdquo;
First of all, I personaly do not want to rely in any part of my life on any &amp;ldquo;synthesized&amp;rdquo; (and &amp;ldquo;understood&amp;rdquo; software, and demand an explicit opt-out. Yes, yes, I know.
If I have any understanding of these subjects at all, this is a bubble and irrational exuberance.</description>
    </item>
  </channel>
</rss>
