<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Bullshit on Notes from the digital underground by Lngnmn</title>
    <link>https://lngnmn2.github.io/tags/bullshit/</link>
    <description>Recent content in Bullshit on Notes from the digital underground by Lngnmn</description>
    <generator>Hugo -- 0.148.2</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 09 Jan 2026 09:39:08 +0545</lastBuildDate>
    <atom:link href="https://lngnmn2.github.io/tags/bullshit/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Cognitive Biases At Work</title>
      <link>https://lngnmn2.github.io/articles/cognitive-biases-at-work/</link>
      <pubDate>Thu, 08 Jan 2026 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/cognitive-biases-at-work/</guid>
      <description>&lt;p&gt;There is some output (slop) I got from my recent sessions (yes, yes, I am guilty and ashamed):&lt;/p&gt;
&lt;p&gt;#+BEGIN_SRC markdown
### Validation Summary
I have verified the implementation across the &lt;strong&gt;&lt;strong&gt;Functional Core&lt;/strong&gt;&lt;/strong&gt; (Domain) and the &lt;strong&gt;&lt;strong&gt;Imperative Shell&lt;/strong&gt;&lt;/strong&gt; (Infrastructure &amp;amp; Interface), confirming that the code doesn&amp;rsquo;t just &amp;ldquo;look&amp;rdquo; right but functionally enforces the rules.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;1. Domain Layer (Functional Core)&lt;/strong&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&#34;strict-encapsulation-all-primitives--f64-string--are-wrapped-in-newtypes--price-quantity-symbol--with-private-fields-dot&#34;&gt;&lt;strong&gt;&lt;strong&gt;Strict Encapsulation:&lt;/strong&gt;&lt;/strong&gt; All primitives (`f64`, `String`) are wrapped in &lt;strong&gt;&lt;strong&gt;Newtypes&lt;/strong&gt;&lt;/strong&gt; (`Price`, `Quantity`, `Symbol`) with private fields.&lt;/h2&gt;
&lt;h2 id=&#34;correctness-by-construction-smart-constructors--new--result--enforce-invariants--e-dot-g-dot-price-0-symbol-format--dot-it-is-impossible-to-instantiate-invalid-domain-objects-dot&#34;&gt;&lt;strong&gt;&lt;strong&gt;Correctness by Construction:&lt;/strong&gt;&lt;/strong&gt; &lt;strong&gt;&lt;strong&gt;Smart Constructors&lt;/strong&gt;&lt;/strong&gt; (`new() -&amp;gt; Result`) enforce invariants (e.g., price &amp;gt; 0, symbol format). It is impossible to instantiate invalid domain objects.&lt;/h2&gt;
&lt;h2 id=&#34;algebraic-data-types-order-is-a-sum-type--enum--of-product-types--structs--exhaustively-modeling-valid-order-strategies--market-limit-stoplimit--dot&#34;&gt;&lt;strong&gt;&lt;strong&gt;Algebraic Data Types:&lt;/strong&gt;&lt;/strong&gt; `Order` is a Sum Type (Enum) of Product Types (Structs), exhaustively modeling valid order strategies (`Market`, `Limit`, `StopLimit`).&lt;/h2&gt;
&lt;h2 id=&#34;typestate-pattern-the-orderbuilder-uses-zero-sized-types--nosymbol-withsymbol--to-enforce-the-order-of-operations-at-compile-time-dot-you-cannot-build-an-order-without-mandatory-fields-dot&#34;&gt;&lt;strong&gt;&lt;strong&gt;Typestate Pattern:&lt;/strong&gt;&lt;/strong&gt; The `OrderBuilder` uses zero-sized types (`NoSymbol`, `WithSymbol`) to enforce the order of operations at compile time. You cannot build an order without mandatory fields.&lt;/h2&gt;
&lt;h2 id=&#34;error-handling-domainerror-is-a-specific-sum-type-using-thiserror-implementing-the-make-illegal-states-unrepresentable-rule-dot&#34;&gt;&lt;strong&gt;&lt;strong&gt;Error Handling:&lt;/strong&gt;&lt;/strong&gt; `DomainError` is a specific Sum Type using `thiserror`, implementing the &amp;ldquo;Make Illegal States Unrepresentable&amp;rdquo; rule.&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;2. Infrastructure &amp;amp; Interface (Imperative Shell)&lt;/strong&gt;&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Some Aha Moments</title>
      <link>https://lngnmn2.github.io/articles/some-aha-moments/</link>
      <pubDate>Fri, 02 Jan 2026 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/some-aha-moments/</guid>
      <description>&lt;p&gt;For a quite long time already I sort of &amp;ldquo;ran in the background&amp;rdquo; this question  &amp;ndash; &amp;ldquo;how they bridge the semantic gap between verbiage and the code?&amp;rdquo; In the context of a well-written textbook (extremely rare, just 50 or so in existence) the code examples immediately follow or even intersperse the explanations. Most of the internet content is nothing like that.&lt;/p&gt;
&lt;p&gt;The semantically closest entities in the code are specially formatted comments that are used to generate [an appearance of] &amp;ldquo;documentation&amp;rdquo;, with a modern fashion to mention some core concepts being used. This kind of well-documented (enforced by the strict rules) code one would find in placed like Google&amp;rsquo;s monorepo and other megacorp inner code bases.  Almost noting this strict can be found on Github (the primary source of all training).&lt;/p&gt;</description>
    </item>
    <item>
      <title>Vibecoding explained</title>
      <link>https://lngnmn2.github.io/articles/vibecoding-explained/</link>
      <pubDate>Sun, 21 Dec 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/vibecoding-explained/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://karpathy.bearblog.dev/year-in-review-2025/&#34;&gt;https://karpathy.bearblog.dev/year-in-review-2025/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;In this episode @karpathy blessed us all with another blogpost. While his wording is much more careful and even nuanced, there is still a lot of bullshit in it. It way less outrageous bullshit as in the Friedman &lt;em&gt;poocast&lt;/em&gt;  and around that time, but still.&lt;/p&gt;
&lt;p&gt;Here are some excerpts:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;With vibe coding, programming is not strictly reserved for highly trained professionals, it is something anyone can do.&lt;/p&gt;
&lt;p&gt;&amp;hellip;&lt;/p&gt;
&lt;p&gt;But not only does vibe coding empower regular people to approach programming, it empowers trained professionals to write a lot more (vibe coded) software that would otherwise never be written.&lt;/p&gt;</description>
    </item>
    <item>
      <title>  LLMs: The &#34;Good&#34; Parts
  </title>
      <link>https://lngnmn2.github.io/articles/llms-the-good-parts/</link>
      <pubDate>Tue, 16 Dec 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/llms-the-good-parts/</guid>
      <description>&lt;p&gt;Okay, lets look at the &amp;ldquo;better side&amp;rdquo; of things.&lt;/p&gt;
&lt;p&gt;The good thing about using LLMs is that you do not have to deal with &lt;em&gt;Google Search&lt;/em&gt; and any fucking &lt;em&gt;Social Media&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Imagine a painfully typical scenario &amp;ndash; you want to clarify or better understand something you already vaguely knew or at least aware of. You type a query into Google Search, and you get&amp;hellip; a fucking CEO fucked-up list of Ad-infested links to various web pages &amp;ndash; either the  largest social media containment boards (StackOverflow, Reddit, Medium), or some CEO&amp;rsquo;d blogs, when you are either  greeted with a wall of text (usually directly pasted from tutorials and docs), ads, pop-ups, and other distractions, or some narcissistic asshole&amp;rsquo;s low-effort over-verbose crappy verbiage about &amp;ldquo;how fucking smart he is&amp;rdquo;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>And this is exactly how</title>
      <link>https://lngnmn2.github.io/articles/this-is-exactly-how/</link>
      <pubDate>Tue, 16 Dec 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/this-is-exactly-how/</guid>
      <description>&lt;p&gt;Just like a spontaneous, &amp;ldquo;natural and organic&amp;rdquo; continuation to the previous post (which implicitly confirm that it has properly captured at least &lt;em&gt;some&lt;/em&gt; aspect of reality [as it is]).&lt;/p&gt;
&lt;p&gt;I have had to delete some nice movies in order to download and try that over-hyped &amp;ldquo;5M downloads&amp;rdquo; Nvidia&amp;rsquo;s meme-model &lt;code&gt;Nemotron-3-Nano-30B&amp;quot;&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;I have a small set of highly sophisticated prompts which I use to measure the apparent quality of a generated slop of the  4 major data-center-sized LLMs.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Idiots, Idiots Everywhere.jpg</title>
      <link>https://lngnmn2.github.io/articles/idiots-idiots-everywhere/</link>
      <pubDate>Wed, 10 Dec 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/idiots-idiots-everywhere/</guid>
      <description>&lt;p&gt;Everything is broken and idiots are everywhere. There is a clown which attention whoring, sorry, publicly arguing (and gaining a lot of unwarranted attention) that one shall vapecode in &lt;code&gt;C&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://news.ycombinator.com/item?id=46207505&#34;&gt;https://news.ycombinator.com/item?id=46207505&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Basically, making such a claim is idiotic on so many levels that it is hard to know where to start. Almost the whole of  &lt;em&gt;classic&lt;/em&gt; non-bullshit programming language theory research is about how to correctly address C&amp;rsquo;s shortcomings and &lt;em&gt;semantic&lt;/em&gt; issues, and how to avoid the inherent in the design of the language (and the ABI) problems.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Some Final Words</title>
      <link>https://lngnmn2.github.io/articles/some-final-words/</link>
      <pubDate>Tue, 09 Dec 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/some-final-words/</guid>
      <description>&lt;p&gt;So, it seems like this is the time to somehow sum up the current AI hype (way through the roof) and the immediate and long term &lt;em&gt;consequences&lt;/em&gt; of it.&lt;/p&gt;
&lt;p&gt;First of all, a proper education &amp;ndash; studying the fundamental underlying principles instead of particulars &amp;ndash;  which used to be an unofficial mantra of MIT, pays off again.&lt;/p&gt;
&lt;p&gt;One just sets particular constraints to a coding LLM and use it as a whole-data-center-powerful &lt;em&gt;constraint satisfaction engine&lt;/em&gt; that spews out a slop, which then can be used for rapid prototyping and minimal-viable products. The properly constrained slop can even be used as the basis of a project, which then undergo proper &lt;em&gt;continuous improvement&lt;/em&gt; and &lt;em&gt;refinement&lt;/em&gt; by a human expert (who knows the &lt;em&gt;whys&lt;/em&gt;).&lt;/p&gt;</description>
    </item>
    <item>
      <title>The new Brahmanas</title>
      <link>https://lngnmn2.github.io/articles/the-new-brahmanas/</link>
      <pubDate>Wed, 03 Dec 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/the-new-brahmanas/</guid>
      <description>&lt;p&gt;I think I have seen this before. Once in Varanasi, wandering around book stalls (most titles already &amp;ldquo;tourist books&amp;rdquo;, &amp;ndash; oversimplified and westernized &amp;ldquo;tantric&amp;rdquo; bullshit), I found a whole book by some  local publisher which describes in a minute details one single Brahmanic ritual (an elaborate sacrifice) which last almost a whole day. Hundreds of ingredients are being burn in a precise sequence, or rather a simphony of chants. motions, gestures (mudras) and many other elaborate details. The priests (brahmans) definitely knew what they are doing and why exactly this way is the only proper way.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Bullshit, bullshit, bullshit</title>
      <link>https://lngnmn2.github.io/articles/bullshit-bullshit-bullshit/</link>
      <pubDate>Mon, 03 Nov 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/bullshit-bullshit-bullshit/</guid>
      <description>&lt;p&gt;So, things begin to move a lot faster and much bigger, and there is something to realize about this unpreceded AI bubble.&lt;/p&gt;
&lt;p&gt;We will consider only the underlaying fundamental principles, not the particular implementation details, &amp;ldquo;architectures&amp;rdquo; and what not..&lt;/p&gt;
&lt;p&gt;There are four major aspects to any LLM model &amp;ndash; the training process, the &amp;ldquo;architecture&amp;rdquo; (the structural shape) of a model, the &amp;quot; post-training tuning&amp;quot; (lobotomy) of the model and the inference process.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Emergence Of A New Cult</title>
      <link>https://lngnmn2.github.io/articles/emergence-of-new-cult/</link>
      <pubDate>Sat, 24 May 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/emergence-of-new-cult/</guid>
      <description>The Tantra of vibe coding</description>
    </item>
  </channel>
</rss>
