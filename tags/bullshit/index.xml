<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Bullshit on Notes from the digital underground by Lngnmn</title>
    <link>https://lngnmn2.github.io/tags/bullshit/</link>
    <description>Recent content in Bullshit on Notes from the digital underground by Lngnmn</description>
    <generator>Hugo -- 0.148.2</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 21 Dec 2025 12:02:31 +0545</lastBuildDate>
    <atom:link href="https://lngnmn2.github.io/tags/bullshit/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Vibecoding explained</title>
      <link>https://lngnmn2.github.io/articles/vibecoding-explained/</link>
      <pubDate>Sun, 21 Dec 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/vibecoding-explained/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://karpathy.bearblog.dev/year-in-review-2025/&#34;&gt;https://karpathy.bearblog.dev/year-in-review-2025/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;In this episode @karpathy blessed us all with another blogpost. While his wording is much more careful and even nuanced, there is still a lot of bullshit in it. It way less outrageous bullshit as in the Friedman &lt;em&gt;poocast&lt;/em&gt;  and around that time, but still.&lt;/p&gt;
&lt;p&gt;Here are some excerpts:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;With vibe coding, programming is not strictly reserved for highly trained professionals, it is something anyone can do.&lt;/p&gt;
&lt;p&gt;&amp;hellip;&lt;/p&gt;
&lt;p&gt;But not only does vibe coding empower regular people to approach programming, it empowers trained professionals to write a lot more (vibe coded) software that would otherwise never be written.&lt;/p&gt;</description>
    </item>
    <item>
      <title>  LLMs: The &#34;Good&#34; Parts
  </title>
      <link>https://lngnmn2.github.io/articles/llms-the-good-parts/</link>
      <pubDate>Tue, 16 Dec 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/llms-the-good-parts/</guid>
      <description>&lt;p&gt;Okay, lets look at the &amp;ldquo;better side&amp;rdquo; of things.&lt;/p&gt;
&lt;p&gt;The good thing about using LLMs is that you do not have to deal with &lt;em&gt;Google Search&lt;/em&gt; and any fucking &lt;em&gt;Social Media&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Imagine a painfully typical scenario &amp;ndash; you want to clarify or better understand something you already vaguely knew or at least aware of. You type a query into Google Search, and you get&amp;hellip; a fucking CEO fucked-up list of Ad-infested links to various web pages &amp;ndash; either the  largest social media containment boards (StackOverflow, Reddit, Medium), or some CEO&amp;rsquo;d blogs, when you are either  greeted with a wall of text (usually directly pasted from tutorials and docs), ads, pop-ups, and other distractions, or some narcissistic asshole&amp;rsquo;s low-effort over-verbose crappy verbiage about &amp;ldquo;how fucking smart he is&amp;rdquo;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>And this is exactly how</title>
      <link>https://lngnmn2.github.io/articles/this-is-exactly-how/</link>
      <pubDate>Tue, 16 Dec 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/this-is-exactly-how/</guid>
      <description>&lt;p&gt;Just like a spontaneous, &amp;ldquo;natural and organic&amp;rdquo; continuation to the previous post (which implicitly confirm that it has properly captured at least &lt;em&gt;some&lt;/em&gt; aspect of reality [as it is]).&lt;/p&gt;
&lt;p&gt;I have had to delete some nice movies in order to download and try that over-hyped &amp;ldquo;5M downloads&amp;rdquo; Nvidia&amp;rsquo;s meme-model &lt;code&gt;Nemotron-3-Nano-30B&amp;quot;&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;I have a small set of highly sophisticated prompts which I use to measure the apparent quality of a generated slop of the  4 major data-center-sized LLMs.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Idiots, Idiots Everywhere.jpg</title>
      <link>https://lngnmn2.github.io/articles/idiots-idiots-everywhere/</link>
      <pubDate>Wed, 10 Dec 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/idiots-idiots-everywhere/</guid>
      <description>&lt;p&gt;Everything is broken and idiots are everywhere. There is a clown which attention whoring, sorry, publicly arguing (and gaining a lot of unwarranted attention) that one shall vapecode in &lt;code&gt;C&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://news.ycombinator.com/item?id=46207505&#34;&gt;https://news.ycombinator.com/item?id=46207505&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Basically, making such a claim is idiotic on so many levels that it is hard to know where to start. Almost the whole of  &lt;em&gt;classic&lt;/em&gt; non-bullshit programming language theory research is about how to correctly address C&amp;rsquo;s shortcomings and &lt;em&gt;semantic&lt;/em&gt; issues, and how to avoid the inherent in the design of the language (and the ABI) problems.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Some Final Words</title>
      <link>https://lngnmn2.github.io/articles/some-final-words/</link>
      <pubDate>Tue, 09 Dec 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/some-final-words/</guid>
      <description>&lt;p&gt;So, it seems like this is the time to somehow sum up the current AI hype (way through the roof) and the immediate and long term &lt;em&gt;consequences&lt;/em&gt; of it.&lt;/p&gt;
&lt;p&gt;First of all, a proper education &amp;ndash; studying the fundamental underlying principles instead of particulars &amp;ndash;  which used to be an unofficial mantra of MIT, pays off again.&lt;/p&gt;
&lt;p&gt;One just sets particular constraints to a coding LLM and use it as a whole-data-center-powerful &lt;em&gt;constraint satisfaction engine&lt;/em&gt; that spews out a slop, which then can be used for rapid prototyping and minimal-viable products. The properly constrained slop can even be used as the basis of a project, which then undergo proper &lt;em&gt;continuous improvement&lt;/em&gt; and &lt;em&gt;refinement&lt;/em&gt; by a human expert (who knows the &lt;em&gt;whys&lt;/em&gt;).&lt;/p&gt;</description>
    </item>
    <item>
      <title>The new Brahmanas</title>
      <link>https://lngnmn2.github.io/articles/the-new-brahmanas/</link>
      <pubDate>Wed, 03 Dec 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/the-new-brahmanas/</guid>
      <description>&lt;p&gt;I think I have seen this before. Once in Varanasi, wandering around book stalls (most titles already &amp;ldquo;tourist books&amp;rdquo;, &amp;ndash; oversimplified and westernized &amp;ldquo;tantric&amp;rdquo; bullshit), I found a whole book by some  local publisher which describes in a minute details one single Brahmanic ritual (an elaborate sacrifice) which last almost a whole day. Hundreds of ingredients are being burn in a precise sequence, or rather a simphony of chants. motions, gestures (mudras) and many other elaborate details. The priests (brahmans) definitely knew what they are doing and why exactly this way is the only proper way.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Bullshit, bullshit, bullshit</title>
      <link>https://lngnmn2.github.io/articles/bullshit-bullshit-bullshit/</link>
      <pubDate>Mon, 03 Nov 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/bullshit-bullshit-bullshit/</guid>
      <description>&lt;p&gt;So, things begin to move a lot faster and much bigger, and there is something to realize about this unpreceded AI bubble.&lt;/p&gt;
&lt;p&gt;We will consider only the underlaying fundamental principles, not the particular implementation details, &amp;ldquo;architectures&amp;rdquo; and what not..&lt;/p&gt;
&lt;p&gt;There are four major aspects to any LLM model &amp;ndash; the training process, the &amp;ldquo;architecture&amp;rdquo; (the structural shape) of a model, the &amp;quot; post-training tuning&amp;quot; (lobotomy) of the model and the inference process.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Emergence Of A New Cult</title>
      <link>https://lngnmn2.github.io/articles/emergence-of-new-cult/</link>
      <pubDate>Sat, 24 May 2025 00:00:00 +0545</pubDate>
      <guid>https://lngnmn2.github.io/articles/emergence-of-new-cult/</guid>
      <description>The Tantra of vibe coding</description>
    </item>
  </channel>
</rss>
