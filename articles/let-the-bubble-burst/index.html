<!DOCTYPE html>
<html lang="en" dir="auto" data-theme="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Let the bubble burst, for Crist&#39;s sake! | Notes from the digital underground by Lngnmn</title>
<meta name="keywords" content="AI, LLM">
<meta name="description" content="Look, ma, no errors!">
<meta name="author" content="&amp;lt;lngnmn2@yahoo.com&amp;gt;">
<link rel="canonical" href="https://lngnmn2.github.io/articles/let-the-bubble-burst/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.a5781257de4197b8e3d54346acdf1dd55a9ba4cb91dcace192fc1baf228c08b5.css" integrity="sha256-pXgSV95Bl7jj1UNGrN8d1VqbpMuR3KzhkvwbryKMCLU=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://lngnmn2.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://lngnmn2.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://lngnmn2.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://lngnmn2.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://lngnmn2.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://lngnmn2.github.io/articles/let-the-bubble-burst/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
                color-scheme: dark;
            }

            .list {
                background: var(--theme);
            }

            .toc {
                background: var(--entry);
            }
        }

        @media (prefers-color-scheme: light) {
            .list::-webkit-scrollbar-thumb {
                border-color: var(--code-bg);
            }
        }

    </style>
</noscript>
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.querySelector("html").dataset.theme = 'dark';
    } else if (localStorage.getItem("pref-theme") === "light") {
       document.querySelector("html").dataset.theme = 'light';
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.querySelector("html").dataset.theme = 'dark';
    } else {
        document.querySelector("html").dataset.theme = 'light';
    }

</script><link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Source+Code+Pro:wght@300&display=swap" rel="stylesheet">
<link href="https://fonts.googleapis.com/css2?family=Noto+Sans:wght@300&display=swap" rel="stylesheet">
<link href="https://fonts.googleapis.com/css2?family=Noto+Serif:wght@300&display=swap" rel="stylesheet">
<style>
font-family: 'Noto Serif', serif;
font-family: 'Noto Sans', sans-serif;
font-family: 'Source Code Pro', monospace;
</style>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script type="text/javascript" id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script><meta property="og:url" content="https://lngnmn2.github.io/articles/let-the-bubble-burst/">
  <meta property="og:site_name" content="Notes from the digital underground by Lngnmn">
  <meta property="og:title" content="Let the bubble burst, for Crist&#39;s sake!">
  <meta property="og:description" content="Look, ma, no errors!">
  <meta property="og:locale" content="en-us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="articles">
    <meta property="article:published_time" content="2025-08-03T00:00:00+05:45">
    <meta property="article:modified_time" content="2025-08-03T19:03:45+05:45">
    <meta property="article:tag" content="AI">
    <meta property="article:tag" content="LLM">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Let the bubble burst, for Crist&#39;s sake!">
<meta name="twitter:description" content="Look, ma, no errors!">


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Articles",
      "item": "https://lngnmn2.github.io/articles/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Let the bubble burst, for Crist's sake!",
      "item": "https://lngnmn2.github.io/articles/let-the-bubble-burst/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Let the bubble burst, for Crist's sake!",
  "name": "Let the bubble burst, for Crist\u0027s sake!",
  "description": "Look, ma, no errors!",
  "keywords": [
    "AI", "LLM"
  ],
  "articleBody": "I have noticed a resent dramatic change in the behavior of major GPTs online providers – most notably, Gemini is now providing just outline of code, full of stubs and “mocks” of real APIs, and not the full code. This is a significant change from the previous behavior where they would provide a semi-complete (but ridden with errors) code solution. Perhaps, mimicking the behavior of ChatGPT, which has been doing this for a while now – they “optimize” for more what appears to be a “dialogue” (more like a normie-level chat), to create a better illusion of “actually conversing with an artificial intelligence”.\nThis trend is kind of obvious and easy to see and understand – they are targeting normies and optimize for an “average user” who is not a top-tier programmer, and who is not looking for a full code solution (and can accurately evaluate the intrinsic quality of it), but rather for a “conversation” with an AI about the code, just what amateurs would like to do. This is a significant change from the previous behavior where Gemini would provide a semi-complete (but still ridden with errors) well-commented code solution.\nOne more time – the code blocks they spew out today are incomplete, and cannot be compiled or run, and are full of stubs and “mocks” and comments like “here the other functions shall be put” . In this mode the errors are “not even out there”, they literally does not arise, because this is just an “outline” or a “sketch” of the code, a “skeleton” of the solution, instead of a full solution. This “innovation” deepens the illusion for normies but makes code generation useless for real programmers, who are looking for a full code solution, not just a “conversation” about the code.\nLets make our understanding a bit more clear. Among the major “megacorp” AI providers, the ChatGPT was the most normie-focused, “chatty” and provide “infortainment” and even recreation, instead of anything “serious”. It dealt with generalities and banalities – just what Liberal Arts “educated” people and those without any education whatsoever would like and prefer (in order to feel confident, important and “in charge”). Why, we understand this strategy – a basic Psychology 101.\nThe Gemini was the most “serious” and “professional” AI when it comes to programming, for the obvious reasons, (Google has “nothing” but its wast code monorepo, billions of lines of code), which provided the most complete (as probabilisticly possible) code solutions, and was the most useful for real programmers. Now, it seems that Gemini is following the ChatGPT’s path, and is becoming more “chatty” and norime-friendly and thus refusing to provide any “working code” at all.\nSeems like everyone is trying to mimic these “Cursor” workflows, which magically look like a “real” and even [applied] “agile” programming (if you are a normie) due to a series of micro-iterations , executed right from the chat window, which is, indeed, the best and the most convincing illusion so far, at least as seen on TV (shown to millions by @karpathy).\nGrok has an ambition to become a “source of truth” (no more, no less, leaving all the political anti- “left-wing bias” bullshit aside) and to provide the most accurate answers to the questions. The PhD-level meme was created to emphasize the fact that Grok is not a “normie” AI, but rather a “serious”, even “well-educated” AI (LOL, lmao even!)\nThis is what it was just a couple of weeks ago. Since then Gemini has been meme’d into an “IMO gold medal level performance”, following ChatGPT, who coined that meme first.\nNow, there is something to realize. All these claims are simply bullshit to lure paying normies in, which, it seems, does not go as expected and outlined in the business plans. Normies are not interested in “serious” AI, they are not interested in “PhD-level” AI, they are not interested in “gold medal level performance”. They are interested in “chatty” AI, which is what ChatGPT has been providing all along.\nSo, lets call “the top” of the bubble. The actual tech does not live its promises and even pivoting into just paid infortainment services, which will never fly. At least it will not pay back the billions spend.\nThe only real use case – of being a “glorified auto-complete” for crappy, badly designed, stateful imperative verbose OO and webshit APIs – is so error-prone, that they decided to “optimize” for the “conversation” instead of the actual code generation. This is a clear sign that the bubble is bursting, and the AI providers are trying to save face by pretending that they are not failing, but rather “innovating” and “optimizing” for the “average user”.\nToday Gemini gave me an utter, sub-par crap full of comments and “stubs” – an outline of the solution – for almost the same (even more carefully crafted) prompt. ChatGPT for the same prompt gave me an empty “project structure”. Grok did “OK”, just as before (does not compile, of course). This is just the following quick analysis of this fact.\nBut yes, enjoy your “vibecoding”, retards.\n",
  "wordCount" : "846",
  "inLanguage": "en",
  "datePublished": "2025-08-03T00:00:00+05:45",
  "dateModified": "2025-08-03T19:03:45+05:45",
  "author":[{
    "@type": "Person",
    "name": "\u0026lt;lngnmn2@yahoo.com\u0026gt;"
  }],
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://lngnmn2.github.io/articles/let-the-bubble-burst/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Notes from the digital underground by Lngnmn",
    "logo": {
      "@type": "ImageObject",
      "url": "https://lngnmn2.github.io/favicon.ico"
    }
  }
}
</script>
</head>
<body id="top">
    <header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://lngnmn2.github.io/" accesskey="h" title="Notes from the digital underground by Lngnmn (Alt + H)">Notes from the digital underground by Lngnmn</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)" aria-label="Toggle theme">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://lngnmn2.github.io/about/" title="About me.">
                    <span>About me.</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      Let the bubble burst, for Crist&#39;s sake!
    </h1>
    <div class="post-description">
      Look, ma, no errors!
    </div>
    <div class="post-meta"><span title='2025-08-03 00:00:00 +0545 +0545'>August 3, 2025</span>&nbsp;·&nbsp;<span>&amp;lt;lngnmn2@yahoo.com&amp;gt;</span>

</div>
  </header> 
  <div class="post-content"><p>I have noticed a resent dramatic change in the behavior of major GPTs online providers &ndash; most notably, Gemini is  now providing just outline of code, full of stubs and &ldquo;mocks&rdquo; of real APIs,  and not the full code. This is a significant change from the previous behavior where they would provide a semi-complete (but ridden with errors) code solution. Perhaps, mimicking the behavior of ChatGPT, which has been doing this for a while now &ndash; they &ldquo;optimize&rdquo; for more what appears to be a &ldquo;dialogue&rdquo; (more like a normie-level chat), to create a better illusion of &ldquo;actually conversing with an artificial intelligence&rdquo;.</p>
<p>This trend is kind of obvious and easy to see and understand &ndash; they are targeting normies and optimize for an &ldquo;average user&rdquo; who is not a top-tier programmer, and who is not looking for a full code solution (and can accurately evaluate the intrinsic quality of it), but rather for  a &ldquo;conversation&rdquo; with an AI <em>about</em> the code, just what amateurs would like to do. This is a significant change from the previous behavior where Gemini would provide a semi-complete (but still ridden with errors) well-commented code solution.</p>
<p>One more time &ndash; the code blocks they spew out today are incomplete, and cannot be compiled or run, and are full of stubs and &ldquo;mocks&rdquo; and comments like &ldquo;here the other functions shall be put&rdquo; . In this mode the errors are &ldquo;not even out there&rdquo;, they literally does not arise, because this is just an &ldquo;outline&rdquo; or a &ldquo;sketch&rdquo; of the code, a &ldquo;skeleton&rdquo; of the solution, instead of  a full solution. This &ldquo;innovation&rdquo; deepens the illusion for normies but makes code generation useless for real programmers, who are looking for a full code solution, not just a &ldquo;conversation&rdquo; about the code.</p>
<p>Lets make our understanding a bit more clear. Among the major &ldquo;megacorp&rdquo; AI providers, the ChatGPT was the most normie-focused, &ldquo;chatty&rdquo; and provide &ldquo;infortainment&rdquo; and even recreation, instead of anything &ldquo;serious&rdquo;. It dealt with generalities and banalities &ndash; just what Liberal Arts &ldquo;educated&rdquo; people and  those without any education whatsoever would like and prefer (in order to feel confident, important and &ldquo;in charge&rdquo;). Why, we understand this strategy &ndash; a basic Psychology 101.</p>
<p>The Gemini was the most &ldquo;serious&rdquo; and &ldquo;professional&rdquo; AI when it comes  to programming, for the obvious reasons, (Google has &ldquo;nothing&rdquo; but its wast code monorepo, billions of  lines of code), which provided the most complete (as probabilisticly possible) code solutions, and was the most useful for real programmers. Now, it seems that Gemini is following the ChatGPT&rsquo;s path, and is becoming more &ldquo;chatty&rdquo; and norime-friendly and thus refusing to provide any &ldquo;working code&rdquo; at all.</p>
<p>Seems like everyone is trying to mimic these &ldquo;Cursor&rdquo; workflows, which magically look like a &ldquo;real&rdquo; and even  [applied] &ldquo;agile&rdquo; programming (if you are a normie) due to a series of micro-iterations , executed right from the chat window, which is, indeed, the best and the most convincing illusion so far, at least as seen on TV (shown to millions by @karpathy).</p>
<p>Grok has an ambition to become a &ldquo;source of truth&rdquo; (no more, no less, leaving all the political anti- &ldquo;left-wing bias&rdquo; bullshit aside) and to provide the most accurate answers to the questions. The PhD-level meme was created to emphasize the fact that Grok is not a &ldquo;normie&rdquo; AI, but rather a &ldquo;serious&rdquo;, even &ldquo;well-educated&rdquo; AI (LOL, lmao even!)</p>
<p>This is what it was just a couple of weeks ago. Since then Gemini has been meme&rsquo;d into an &ldquo;IMO gold medal level performance&rdquo;, following ChatGPT, who coined that meme first.</p>
<p>Now, there is something to realize. All these claims are simply bullshit to lure paying normies in, which, it seems, does not go as expected and outlined in the business plans. Normies are not interested in &ldquo;serious&rdquo; AI, they are not interested in &ldquo;PhD-level&rdquo; AI, they are not interested in &ldquo;gold medal level performance&rdquo;. They are interested in &ldquo;chatty&rdquo; AI, which is what ChatGPT has been providing all along.</p>
<p>So, lets call &ldquo;the top&rdquo; of the bubble. The actual tech does not live its promises and even pivoting into just paid infortainment services, which will never fly. At least it will not pay back the billions spend.</p>
<p>The only real use case  &ndash; of being a &ldquo;glorified auto-complete&rdquo; for crappy, badly designed, stateful imperative verbose OO and webshit APIs &ndash; is so error-prone, that they decided to &ldquo;optimize&rdquo; for the &ldquo;conversation&rdquo; instead of the actual code generation. This is a clear sign that the bubble is bursting, and the AI providers are trying to save face by pretending that they are not failing, but rather &ldquo;innovating&rdquo; and &ldquo;optimizing&rdquo; for the &ldquo;average user&rdquo;.</p>
<p>Today Gemini gave me an utter, sub-par crap full of comments and &ldquo;stubs&rdquo; &ndash; an outline of the solution &ndash; for almost the same (even more carefully crafted) prompt. ChatGPT for the same prompt gave me an empty &ldquo;project structure&rdquo;. Grok did &ldquo;OK&rdquo;, just as before (does not compile, of course). This is just the following quick  analysis of this fact.</p>
<p>But yes, enjoy your &ldquo;vibecoding&rdquo;, retards.</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://lngnmn2.github.io/tags/ai/">AI</a></li>
      <li><a href="https://lngnmn2.github.io/tags/llm/">LLM</a></li>
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2025 <a href="https://lngnmn2.github.io/">Notes from the digital underground by Lngnmn</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu');
    if (menu) {
        
        const scrollPosition = localStorage.getItem("menu-scroll-position");
        if (scrollPosition) {
            menu.scrollLeft = parseInt(scrollPosition, 10);
        }
        
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        const html = document.querySelector("html");
        if (html.dataset.theme === "dark") {
            html.dataset.theme = 'light';
            localStorage.setItem("pref-theme", 'light');
        } else {
            html.dataset.theme = 'dark';
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
