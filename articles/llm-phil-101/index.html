<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>LLM Philosophy 101 | Notes from the digital underground by Lngnmn</title>
<meta name="keywords" content="AI, deep-learing">
<meta name="description" content="Bullshit, bullshit, bullshit... (K-PAX)">
<meta name="author" content="&amp;lt;lngnmn2@yahoo.com&amp;gt;">
<link rel="canonical" href="https://lngnmn2.github.io/articles/llm-phil-101/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.45e028aa8ce0961349adf411b013ee39406be2c0bc80d4ea3fc04555f7f4611a.css" integrity="sha256-ReAoqozglhNJrfQRsBPuOUBr4sC8gNTqP8BFVff0YRo=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://lngnmn2.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://lngnmn2.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://lngnmn2.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://lngnmn2.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://lngnmn2.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://lngnmn2.github.io/articles/llm-phil-101/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Source+Code+Pro:wght@300&display=swap" rel="stylesheet">
<link href="https://fonts.googleapis.com/css2?family=Noto+Sans:wght@300&display=swap" rel="stylesheet">
<link href="https://fonts.googleapis.com/css2?family=Noto+Serif:wght@300&display=swap" rel="stylesheet">
<style>
font-family: 'Noto Serif', serif;
font-family: 'Noto Sans', sans-serif;
font-family: 'Source Code Pro', monospace;
</style>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script type="text/javascript" id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  

<meta property="og:url" content="https://lngnmn2.github.io/articles/llm-phil-101/">
  <meta property="og:site_name" content="Notes from the digital underground by Lngnmn">
  <meta property="og:title" content="LLM Philosophy 101">
  <meta property="og:description" content="Bullshit, bullshit, bullshit... (K-PAX)">
  <meta property="og:locale" content="en-us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="articles">
    <meta property="article:published_time" content="2024-05-21T00:00:00+05:45">
    <meta property="article:modified_time" content="2024-05-21T18:19:29+05:45">
    <meta property="article:tag" content="AI">
    <meta property="article:tag" content="Deep-Learing">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="LLM Philosophy 101">
<meta name="twitter:description" content="Bullshit, bullshit, bullshit... (K-PAX)">


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Articles",
      "item": "https://lngnmn2.github.io/articles/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "LLM Philosophy 101",
      "item": "https://lngnmn2.github.io/articles/llm-phil-101/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "LLM Philosophy 101",
  "name": "LLM Philosophy 101",
  "description": "Bullshit, bullshit, bullshit... (K-PAX)",
  "keywords": [
    "AI", "deep-learing"
  ],
  "articleBody": "The LLM mania is still going on, with no sign of bursting of the bubble. This will be (already is) way larger than even the DotCom bubble. Grab your popcorn.\nI already wrote this on the old site, and, of course, because I haven’t followed the rules I got “canceled” as they do nowadays with anyone who disagree with their current set of beliefs.\nLets talk it again, even with millions of views behind each Karpathy or Friendman videos.\nWe have to start with Deep Learning – what it actually is (instead of what all the normies think it is and what the talking heads tell us it is).\nWhen we consider what is actually going on we will find out that there is a two-stage process of constructing a mathematical artifact (with a particular representation) and of using (“prompting”) this artifact to output (generate) some information.\nThe vague terminology is what sells and generates a hype (and profits) – just like any organized religion, but it is exactly what destroys the meaning and creates dogmas and debates about them (again, this is how everything actually works as a large social construction).\nFirst of all, we do not “talk” to the large binary blobs, and they never “speak” to us. The additional layers of software generate this experience as a from of a User Experience (UX).\nLets state some facts. These facts are at different levels of abstraction, but however general these statements are not wrong (which makes them statements of a fact).\nWhen we study the actual mathematics involved, we realize that this is a representation learning problem. The training process has been shown to be general enough to learn a representation of any function.\nThis means that given enough correctly labelled data (and correctly applying a back-propagation algorithm) an mathematical artifact will be produced, such that it can be used as a black-box implementation of a procedure which computes given a function.\nThe crucial part is that the mathematical techniques at all levels (both of abstractions and of actual representation and implementation) are correct and even “straightforward”, but there is no “intelligence” in them.\nThe illusion of intelligence (exactly as in a parrot – a talking bird) is inside the heads of the consumers, and literally nowhere else to be found. Just as there no “mind” inside a personal computer.\nLets see where it all gets wrong (which is not a mere opinion or a “research exploration”, but actual facts). There is some non-bullshit philosophy required, but I will keep it simple.\nPeople say that a function is a special kind of a relation. This is too abstract and actually wrong. A function captures a relation, it formally defines a relation so it is at a more “concrete” level.\nA function, in turn could have more than one procedure of how to actually compute (calculate) it – a sequence of finite steps, usually called as an algorithm. An actual implementation of an algorithm in some formalism (a programming or a machine language) is one more level down to Earth (from Platonic heights). Everything is well-understood since Turing.\nThe point so far is this – we already have a whole tradition of how to implement mathematics on machines and we have studied this process at many levels, there are no “miracles” in there – just propertly captured (mathematical) abstractions and their proper implementations with layers upon layers of Abstract Data Types. (and their actual implementations).\nThe first take-home message is this – there is nothing more out there. All the talk about “emergent properties” is an utter bullshit. Just as there is no mind in a PC.\nLets make in more clear. What we call a relation is not an arbitrary ephemeral abstract Platonic idea. It has to be observed and captured with an informal human language and then translated into a formal of mathematics – which captures of what is already known.\nHere we have to invoke the first piece of a popular philosophy – according to the nature (laws) of our Universe contradictions do not exist. They just cannot arise within a single unfolding process. This means that every new “piece of knowledge” must not contradict what is already known (non-billshit mathematics and first-order logic).\nSo, a sort of type-checking for a relation is that it has to be observed and properly captured and it must not contradict what is already known (the math, phisics and biology).\nWhen we have an actual relation we could have a corresponding function and then one or more algorithm or any other representation. Representation is when it gets interesting.\nAbstractly, a function could be thought of as a table, just like the multiplication table in an elementry school. The fundamental property is not that it can be drawn as a table, but that the inputs and outputs are fixed (and can be thought of as pairs or “arrows”).\nThere is another a-ha moment – not everything can be properly captured as a mathematical function. One could say that only \" the stable aspects of the Universe\" (which make Life Itself possible) are.\nHere is a operational definition of non-bullshit – something which can be actually observed and captured and turned into a math (surprise! – proper mathematics is not a bunch of abstract Platonic ideas, and never been). All math so far has been built exactly like this.\nNow here is the main point – almost nothing (except for What actually Is) can be properly captured as a relation and a function. Building representations of what is not a relation or a function (what isn’t Out There) using mathematical techniques is, indeed, no different (in principle) from alchemy or astrology, which is what it is as a social construction or a mass-hysteria at the social level.\nWhile each step– mathematical, algorithms, representations, implementations – can be well-understood and well-defined, the result is just bullshit, because all the correct, proper, known-so-far methodology has been applied to bullshit in a particular social settings – just exactly as alchemy.\nOne more time – pay attention – there is no “intelligence” out there, no actual “emergent properties”, just as there is no angels or gods. This is nothing but an information processing.\nInformation processing, in principle, cannot be a source of truth, just as mere applied math cannot yield an experimental science. An experimental science is another level of abstraction from mere information processing or calculations. Just as mere texts (as sequences of words and symbols) never (by themselves) are sources of truth (most of the times they are just verbalized dogmas).\nNow lets explain it as if to a 5 year olds. Mathematics (and information processing using computers) however pure and flawless, applied to bullshit yields bullshit. The relations has to be out there.\nThe only non-bullshit applications of Deep Learning and other AI techniques has been to measurements (using various instruments) of some aspects of actual reality – biology, mostly.\nWhat cannot be adequately measured and empirically validated cannot be used as a training data to a deep learning model. Well, it obviously can, but it will yield as bullshit. It is this simple and this fundamental.\nHere is another infallible principle (even the law of the Universe) – the non-stable environments, in which the factors keep evolving (new ones emerge, old ones disappear or diminish) cannot be properly captured using mathematics, because your function will give different results, due to the “changes within the environment”.\nThe same principle has been observed when imperative programs crash after some data “changed behind their backs”. Immutability (of so-called “stable intermediate forms”) is a requirement, not an academic fancy. In short – the environment has to be stable-enough (for a Life to emerge and sustain itself).\nThe principle is this – Application of any Deep Learning techniques to bullshit will yield bullshit. Language, (unless it is a very strict mathematical formalism or a scientific discipline) captures bullshit, not even “the whole world at once” (as naive liberal arts majors would tell us).\nNo, all the written texts do not capture reality. It actually captures all the bullshits that a humand mind are capable of.\nLast but probably the most important fact – any AI system which currently is capable of generating any code that compiles and runs never does it from the first principles (reality -\u003e math -\u003e abstract data types -\u003e representation -\u003e implementation), it just generates something that sounds like a human speech (code) – exactly what a parrot does. There is no “understanding” involved.\nJust as it is with a parrot, the actual understanding is at another level, many layers of abstractions away from the soundwaves the bird emits (or the binary numbers a software+model produces). Let this fact sink in.\n",
  "wordCount" : "1458",
  "inLanguage": "en",
  "datePublished": "2024-05-21T00:00:00+05:45",
  "dateModified": "2024-05-21T18:19:29+05:45",
  "author":[{
    "@type": "Person",
    "name": "\u0026lt;lngnmn2@yahoo.com\u0026gt;"
  }],
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://lngnmn2.github.io/articles/llm-phil-101/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Notes from the digital underground by Lngnmn",
    "logo": {
      "@type": "ImageObject",
      "url": "https://lngnmn2.github.io/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://lngnmn2.github.io/" accesskey="h" title="Notes from the digital underground by Lngnmn (Alt + H)">Notes from the digital underground by Lngnmn</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://lngnmn2.github.io/about/" title="About me.">
                    <span>About me.</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      LLM Philosophy 101
    </h1>
    <div class="post-description">
      Bullshit, bullshit, bullshit... (K-PAX)
    </div>
    <div class="post-meta"><span title='2024-05-21 00:00:00 +0545 +0545'>May 21, 2024</span>&nbsp;·&nbsp;&amp;lt;lngnmn2@yahoo.com&amp;gt;

</div>
  </header> 
  <div class="post-content"><p>The LLM mania is still going on, with no sign of bursting of the bubble. This will be (already is) way larger than even the DotCom bubble. Grab  your popcorn.</p>
<p>I already wrote <a href="https://schiptsov.github.io/GPT-bullshit.html">this</a> on the old site, and, of course, because I haven&rsquo;t followed the rules I got &ldquo;canceled&rdquo; as they do nowadays with anyone who disagree with their current set of beliefs.</p>
<p>Lets talk it again, even with millions of views behind each Karpathy or Friendman videos.</p>
<p>We have to start with <em>Deep Learning</em> &ndash; what it actually is (instead of what all the normies think it is and what the talking heads tell us it is).</p>
<p>When we consider what is actually going on we will find out that there is a two-stage process of <em>constructing</em> a mathematical artifact (with a particular representation) and of using (&ldquo;prompting&rdquo;) this artifact to output (generate) some <em>information</em>.</p>
<p>The vague terminology is what sells and generates a hype (and profits) &ndash; just like any organized religion, but it is exactly what destroys the meaning and creates dogmas and debates about them (again, this is how everything <em>actually</em> works as a large social construction).</p>
<p>First of all, we do not &ldquo;talk&rdquo; to the large binary blobs, and they never &ldquo;speak&rdquo; to us. The additional layers of software generate this experience as a from of a User Experience (UX).</p>
<p>Lets state some facts. These facts are at different levels of abstraction, but <em>however general</em> these statements are not wrong (which makes them statements of a fact).</p>
<p>When we study the actual mathematics involved, we realize that this is a <em>representation learning</em> problem. The training process has been shown to be general enough to learn a representation of <em>any function</em>.</p>
<p>This means that given enough <em>correctly labelled</em> data (and correctly applying a back-propagation algorithm) an mathematical artifact will be produced, such that it can be used as a <em>black-box implementation of a procedure which computes</em> given a function.</p>
<p>The crucial part is that the mathematical techniques at all levels (both of abstractions and of actual representation and implementation) are correct and even &ldquo;straightforward&rdquo;, but there is no &ldquo;intelligence&rdquo; in them.</p>
<p>The illusion of intelligence (exactly as in a parrot &ndash; a talking bird) is inside the heads of the consumers, and literally nowhere else to be found. Just as there no &ldquo;mind&rdquo; inside a personal computer.</p>
<p>Lets see where it all gets wrong (which is not a mere opinion or a &ldquo;research exploration&rdquo;, but actual facts). There is some non-bullshit philosophy required, but I will keep it simple.</p>
<p>People say that <em>a function is a special kind of a relation</em>. This is too abstract and actually wrong. A function <em>captures a relation, it formally defines a relation</em> so it is at a more &ldquo;concrete&rdquo; level.</p>
<p>A <em>function</em>, in turn could have more than one <em>procedure</em> of how to actually compute (calculate) it &ndash; a sequence of finite steps, usually called as an <em>algorithm</em>. An actual implementation of an algorithm in some formalism (a programming or a machine language) is one more level down to Earth (from Platonic heights). Everything is well-understood since Turing.</p>
<p>The point so far is this &ndash; we already have a whole tradition of how to implement mathematics on machines and we have studied this process at many levels, there are no &ldquo;miracles&rdquo; in there &ndash; just propertly captured (mathematical) abstractions and their proper implementations with layers upon layers of Abstract Data Types. (and their actual implementations).</p>
<p>The first take-home message is this &ndash; there is <em>nothing more</em> out there. All the talk about &ldquo;emergent properties&rdquo; is an utter bullshit. Just as there is no mind in a PC.</p>
<p>Lets make in more clear. What we call <em>a relation</em> is not an arbitrary ephemeral  abstract Platonic idea. It has to be <em>observed</em> and <em>captured</em> with an informal human language and then translated into a formal of mathematics &ndash; <em>which captures of what is already known</em>.</p>
<p>Here we have to invoke the first piece of a popular philosophy &ndash; <em>according to the nature (laws) of our Universe contradictions do not exist</em>. They just cannot arise within a single unfolding process. This means that every new &ldquo;piece of knowledge&rdquo; must not contradict what is already known (non-billshit mathematics and first-order logic).</p>
<p>So, a sort of <em>type-checking</em> for <em>a relation</em> is that it has to be <em>observed and properly captured</em> and it must not contradict what is already known (the math, phisics and biology).</p>
<p>When we have an actual relation we could have a corresponding function and then one or more algorithm or any other <em>representation</em>. Representation is when it gets interesting.</p>
<p>Abstractly, a function could be thought of as a <em>table</em>, just like the multiplication table in an elementry school. The fundamental property is not that it can be drawn as a table, but that the inputs and outputs are fixed (and can be thought of as pairs or &ldquo;arrows&rdquo;).</p>
<p>There is another a-ha moment &ndash; not everything can be properly captured as a mathematical function. One could say that only &quot; the stable aspects of the Universe&quot; (which make Life Itself possible) are.</p>
<p>Here is a operational definition of <em>non-bullshit</em> &ndash; something which can be actually observed and captured and turned into a math (surprise! &ndash; proper mathematics is not a bunch of  abstract Platonic ideas, and never been). All math so far has been built exactly like this.</p>
<p>Now here is the main point &ndash; almost nothing (except for What actually Is) can be properly captured as a <em>relation</em> and a function. Building representations of what is not a relation or a function (what isn&rsquo;t Out There) using mathematical techniques is, indeed, no different (in principle) from alchemy or astrology, which is what it is as a social construction or a mass-hysteria at the social level.</p>
<p>While each step&ndash; mathematical, algorithms, representations, implementations &ndash; can be well-understood and well-defined, the result is just bullshit, because all the correct, proper, known-so-far methodology has been applied to bullshit in a particular social settings &ndash; just exactly as alchemy.</p>
<p>One more time &ndash; <em>pay attention</em> &ndash; there is no &ldquo;intelligence&rdquo; out there, no actual &ldquo;emergent properties&rdquo;, just as there is no angels or gods. This is nothing but an <em>information processing</em>.</p>
<p>Information processing, in principle, cannot be a source of truth, just as mere applied math cannot yield an experimental science. An experimental science is another level of abstraction  from mere information processing or calculations. Just as mere texts (as sequences of words and symbols) never (by themselves) are sources of truth (most of the times they are just verbalized dogmas).</p>
<p>Now lets explain it as if to a 5 year olds. Mathematics (and information processing using computers) however pure and flawless, <em>applied to bullshit yields bullshit</em>. The relations has to be out there.</p>
<p>The only non-bullshit applications of <em>Deep Learning</em> and other AI techniques has been <em>to measurements</em> (using various instruments) of some aspects of actual reality &ndash; biology, mostly.</p>
<p>What cannot be adequately measured and empirically validated cannot be used as a training data to a deep learning model. Well, it obviously can, but it will yield as bullshit. It is this simple and this fundamental.</p>
<p>Here is another infallible principle (even the law of the Universe) &ndash; the non-stable environments, in which the factors keep evolving (new ones emerge, old ones disappear or diminish) cannot be properly captured using mathematics, because your function will give different results, due to the &ldquo;changes within the environment&rdquo;.</p>
<p>The same principle has been observed when imperative programs crash after some data &ldquo;changed behind their backs&rdquo;. Immutability (of so-called &ldquo;stable intermediate forms&rdquo;) is a requirement, not an academic fancy. In short &ndash; the environment has to be stable-enough (for a Life to emerge and sustain itself).</p>
<p>The principle is this &ndash; Application of any <em>Deep Learning</em> techniques to bullshit will yield bullshit. Language, (unless it is a very strict mathematical formalism or a scientific discipline) captures bullshit, not even &ldquo;the whole world at once&rdquo; (as naive liberal arts majors would tell us).</p>
<p>No, all the written texts do not capture reality. It actually captures all the bullshits that a humand mind are capable of.</p>
<p>Last but probably the most important fact &ndash; any AI system which currently is capable of generating any code that compiles and runs never does it from the first principles (reality -&gt; math -&gt; abstract data types -&gt; representation -&gt; implementation), it just generates something that sounds like a human speech (code) &ndash; exactly what a parrot does. There is no &ldquo;understanding&rdquo; involved.</p>
<p>Just as it is with a parrot, the actual understanding is at another level, many layers of abstractions away from the soundwaves the bird emits (or the binary numbers a software+model produces). Let this fact sink in.</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://lngnmn2.github.io/tags/ai/">AI</a></li>
      <li><a href="https://lngnmn2.github.io/tags/deep-learing/">Deep-Learing</a></li>
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2025 <a href="https://lngnmn2.github.io/">Notes from the digital underground by Lngnmn</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
