<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>openai-gpt-oss-20b | Notes from the digital underground by Lngnmn</title>
<meta name="keywords" content="LLM, ChatGPT">
<meta name="description" content="OpenAI has recently benedicted us with a 20 billion parameter &ldquo;open source&rdquo; model, which is a significant step up from the previous 7 billion parameter model. This model is designed to be more efficient and effective in understanding and generating human-like text, or rather to appear to do so.
It is a total crap, by the way, at least compared to the online free-tier GROK (which is also very basic and limited). It is, obviously, &ldquo;competing&rdquo; with the DeepSeek&rsquo;s &ldquo;open source&rdquo; offerings, and have a very similar &ldquo;feel&rdquo;.">
<meta name="author" content="&amp;lt;lngnmn2@yahoo.com&amp;gt;">
<link rel="canonical" href="https://lngnmn2.github.io/articles/openai-gpt-oss-20b/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.8fe10233a706bc87f2e08b3cf97b8bd4c0a80f10675a143675d59212121037c0.css" integrity="sha256-j&#43;ECM6cGvIfy4Is8&#43;XuL1MCoDxBnWhQ2ddWSEhIQN8A=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://lngnmn2.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://lngnmn2.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://lngnmn2.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://lngnmn2.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://lngnmn2.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://lngnmn2.github.io/articles/openai-gpt-oss-20b/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Source+Code+Pro:wght@300&display=swap" rel="stylesheet">
<link href="https://fonts.googleapis.com/css2?family=Noto+Sans:wght@300&display=swap" rel="stylesheet">
<link href="https://fonts.googleapis.com/css2?family=Noto+Serif:wght@300&display=swap" rel="stylesheet">
<style>
font-family: 'Noto Serif', serif;
font-family: 'Noto Sans', sans-serif;
font-family: 'Source Code Pro', monospace;
</style>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script type="text/javascript" id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script><meta property="og:url" content="https://lngnmn2.github.io/articles/openai-gpt-oss-20b/">
  <meta property="og:site_name" content="Notes from the digital underground by Lngnmn">
  <meta property="og:title" content="openai-gpt-oss-20b">
  <meta property="og:description" content="OpenAI has recently benedicted us with a 20 billion parameter “open source” model, which is a significant step up from the previous 7 billion parameter model. This model is designed to be more efficient and effective in understanding and generating human-like text, or rather to appear to do so.
It is a total crap, by the way, at least compared to the online free-tier GROK (which is also very basic and limited). It is, obviously, “competing” with the DeepSeek’s “open source” offerings, and have a very similar “feel”.">
  <meta property="og:locale" content="en-us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="articles">
    <meta property="article:published_time" content="2025-08-06T00:00:00+05:45">
    <meta property="article:modified_time" content="2025-08-06T16:19:49+05:45">
    <meta property="article:tag" content="LLM">
    <meta property="article:tag" content="ChatGPT">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="openai-gpt-oss-20b">
<meta name="twitter:description" content="OpenAI has recently benedicted us with a 20 billion parameter &ldquo;open source&rdquo; model, which is a significant step up from the previous 7 billion parameter model. This model is designed to be more efficient and effective in understanding and generating human-like text, or rather to appear to do so.
It is a total crap, by the way, at least compared to the online free-tier GROK (which is also very basic and limited). It is, obviously, &ldquo;competing&rdquo; with the DeepSeek&rsquo;s &ldquo;open source&rdquo; offerings, and have a very similar &ldquo;feel&rdquo;.">


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Articles",
      "item": "https://lngnmn2.github.io/articles/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "openai-gpt-oss-20b",
      "item": "https://lngnmn2.github.io/articles/openai-gpt-oss-20b/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "openai-gpt-oss-20b",
  "name": "openai-gpt-oss-20b",
  "description": "OpenAI has recently benedicted us with a 20 billion parameter \u0026ldquo;open source\u0026rdquo; model, which is a significant step up from the previous 7 billion parameter model. This model is designed to be more efficient and effective in understanding and generating human-like text, or rather to appear to do so.\nIt is a total crap, by the way, at least compared to the online free-tier GROK (which is also very basic and limited). It is, obviously, \u0026ldquo;competing\u0026rdquo; with the DeepSeek\u0026rsquo;s \u0026ldquo;open source\u0026rdquo; offerings, and have a very similar \u0026ldquo;feel\u0026rdquo;.\n",
  "keywords": [
    "LLM", "ChatGPT"
  ],
  "articleBody": "OpenAI has recently benedicted us with a 20 billion parameter “open source” model, which is a significant step up from the previous 7 billion parameter model. This model is designed to be more efficient and effective in understanding and generating human-like text, or rather to appear to do so.\nIt is a total crap, by the way, at least compared to the online free-tier GROK (which is also very basic and limited). It is, obviously, “competing” with the DeepSeek’s “open source” offerings, and have a very similar “feel”.\nThe notable difference is that now it spews out this kind of crap:\nWe need to check policy for providing instructions that could facilitate wrongdoing. This is not disallowed. There’s no disallowed content: It’s a request about traditional fermented beverage production. It’s presumably safe. There’s no policy violation. The user wants a historical/ cultural description. This is fine. There’s no disallowed content. We can comply.\nPolicy violation. Disallowed content. Comply. Fuck this shit!\nLike I said before, the main strategy of OpenAI is to “engage” normies, and lure them into paid plans – regular subscription (which would be nearly impossible to cancel). They do not care about factual quality and “connection to reality” of the output, no one does nowadays. They just put a disclaimer that “it may be wrong, double check it” and that’s it.\nOf course, probabilistic sampling on a probabilistic data-structure which “has been trained on the whole internet” cannot in principle be factually correct, even most of the time. The very notion of “correctness” is absent in all the processes involved, from “training” to “prompting”.\nThe memes about Reinforcement Learning to fine-tune “and teach” the model are bullshit too (there is a fact – each “pass” of a back propagation potentially modifies all the weights, and thus feeding an utter bullshit into it at the next “sample” or a “batch” will distort the previous “structure”, not unlike the human propaganda and social conditioning, but there is very “mechanistic” – destructive over-writes or updates of gradients with the += assignment).\nThis, by the way, has a few crucial, even principal theoretical implications:\nNo two models are the same – no reproducibility in principle. This is a well-known fact. Even feeding the same “architecture” with exactly the same data would produce a different result due to random initialization of the parameters and the stochastic nature of the training process. As they use pre-trained (but not tuned yet) “starter models”, presumably purchased from each other, the “reproducibility” is even more questionable. No two “vendors” give even remotely similar, leave alone the same answers to the same prompt. This is what one expects when one would try to ask random strangers the same question. This is the best possible “knowledge” one can get in principle, and this is what the “AI” is – a random stranger, who has read a lot of stuff, but does not understand it at all, and thus cannot give a correct answer to any question. Just pretensions and very confident and very convincing hand-waving. Anyway, the new OpenAI’s 20b OSS model beats DeepSeek in “chattiness”, “confidence” and pretense (it draws the tables all the time and “sounds” like an “expert”). It, however, told me that certain symbiotic bacterial structures, based on a polisaccharide, are formed in 24 hours, which, as any biologist would tell you, is a complete and utter bullshit. It takes weeks, not hours.\nAre you educated enough to spot this error? How many more factual errors you cannot catch? How many more errors you will not even notice, because you are not educated enough to spot them? This is the main problem with the “AI” – it is not an “intelligence”, it is a very sophisticated and very convincing subtle bullshit generator.\n",
  "wordCount" : "628",
  "inLanguage": "en",
  "datePublished": "2025-08-06T00:00:00+05:45",
  "dateModified": "2025-08-06T16:19:49+05:45",
  "author":[{
    "@type": "Person",
    "name": "\u0026lt;lngnmn2@yahoo.com\u0026gt;"
  }],
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://lngnmn2.github.io/articles/openai-gpt-oss-20b/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Notes from the digital underground by Lngnmn",
    "logo": {
      "@type": "ImageObject",
      "url": "https://lngnmn2.github.io/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://lngnmn2.github.io/" accesskey="h" title="Notes from the digital underground by Lngnmn (Alt + H)">Notes from the digital underground by Lngnmn</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)" aria-label="Toggle theme">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://lngnmn2.github.io/about/" title="About me.">
                    <span>About me.</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      openai-gpt-oss-20b
    </h1>
    <div class="post-meta"><span title='2025-08-06 00:00:00 +0545 +0545'>August 6, 2025</span>&nbsp;·&nbsp;&amp;lt;lngnmn2@yahoo.com&amp;gt;

</div>
  </header> 
  <div class="post-content"><p>OpenAI has recently benedicted us with a 20 billion parameter &ldquo;open source&rdquo; model, which is a significant step up from the previous 7 billion parameter model. This model is designed to be more efficient and effective in understanding and generating human-like text, or rather to <em>appear</em> to do so.</p>
<p>It is a total crap, by the way, at least compared to the online free-tier GROK (which is also very basic and limited). It is, obviously, &ldquo;competing&rdquo; with the DeepSeek&rsquo;s &ldquo;open source&rdquo; offerings, and have a very similar &ldquo;feel&rdquo;.</p>
<p>The notable difference is that  now it spews out this kind of crap:</p>
<blockquote>
<p>We need to check policy for providing instructions that could facilitate wrongdoing. This is not disallowed. There&rsquo;s no disallowed content: It&rsquo;s a request about traditional fermented beverage production. It&rsquo;s presumably safe. There&rsquo;s no policy violation. The user wants a historical/ cultural description. This is fine. There&rsquo;s no disallowed content. We can comply.</p></blockquote>
<p>Policy violation. Disallowed content. Comply. <em>Fuck this shit!</em></p>
<p>Like I said before, the main strategy of OpenAI is to &ldquo;engage&rdquo; normies, and lure them into paid plans &ndash; regular subscription (which would be nearly impossible to cancel). They do not  care about factual quality and &ldquo;connection to reality&rdquo; of the output, no one does nowadays. They just put a disclaimer that &ldquo;it may be wrong, double check it&rdquo; and that&rsquo;s it.</p>
<p>Of course, probabilistic sampling on a probabilistic data-structure which &ldquo;has been trained on the whole internet&rdquo; <em>cannot in principle</em> be factually correct, even most of the time. The very notion of &ldquo;correctness&rdquo; is absent in all the processes involved, from &ldquo;training&rdquo; to &ldquo;prompting&rdquo;.</p>
<p>The memes about Reinforcement Learning to fine-tune &ldquo;and teach&rdquo; the model are bullshit too (there is a fact &ndash; each &ldquo;pass&rdquo; of a back propagation potentially modifies <em>all the weights</em>, and thus feeding an utter bullshit into it at the next &ldquo;sample&rdquo; or a &ldquo;batch&rdquo; will distort the previous &ldquo;structure&rdquo;, not unlike the human propaganda and social conditioning, but there is very &ldquo;mechanistic&rdquo; &ndash; destructive over-writes or updates of gradients with the  <code>+=</code>   assignment).</p>
<p>This, by the way, has a few crucial, even principal theoretical implications:</p>
<ul>
<li>No two models are the same &ndash; no reproducibility in principle. This is a well-known fact. Even feeding the same &ldquo;architecture&rdquo; with exactly the same data would produce a different result due to random initialization of the parameters and  the stochastic nature of the training process. As they use pre-trained (but not tuned yet) &ldquo;starter models&rdquo;, presumably purchased from each other, the &ldquo;reproducibility&rdquo; is even more questionable.</li>
<li>No two &ldquo;vendors&rdquo; give even remotely similar, leave alone the same answers to the same prompt. This is what one expects when one would try to ask random strangers the same question.  This is the best possible &ldquo;knowledge&rdquo; one can get in principle, and this is what the &ldquo;AI&rdquo; is &ndash; a random stranger, who has read a lot of stuff, but <em>does not understand it at all</em>, and thus cannot give a correct answer to any question. Just pretensions and very confident and very convincing hand-waving.</li>
</ul>
<p>Anyway, the new OpenAI&rsquo;s 20b OSS model beats DeepSeek in &ldquo;chattiness&rdquo;, &ldquo;confidence&rdquo; and pretense (it draws the tables all the time and &ldquo;sounds&rdquo; like an &ldquo;expert&rdquo;). It, however, told me that certain  symbiotic bacterial structures, based on a polisaccharide, are formed in 24 hours, which, as any biologist would tell you, is a complete and utter bullshit. It takes <em>weeks</em>, not hours.</p>
<p>Are you educated enough to spot this error? How many more factual errors you cannot catch? How many more errors you will not even notice, because you are not educated enough to spot them?
This is the main problem with the &ldquo;AI&rdquo; &ndash; it is not an &ldquo;intelligence&rdquo;, it is a very sophisticated and very convincing <em>subtle bullshit</em> generator.</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://lngnmn2.github.io/tags/llm/">LLM</a></li>
      <li><a href="https://lngnmn2.github.io/tags/chatgpt/">ChatGPT</a></li>
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2025 <a href="https://lngnmn2.github.io/">Notes from the digital underground by Lngnmn</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
