<!DOCTYPE html>
<html lang="en" dir="auto" data-theme="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Defeating Nondeterminism, my ass | Notes from the digital underground by Lngnmn</title>
<meta name="keywords" content="LLM, AI">
<meta name="description" content="LOL, LMAO even">
<meta name="author" content="lngnmn2@yahoo.com">
<link rel="canonical" href="https://lngnmn2.github.io/articles/defeating-nondeterminism/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.a5781257de4197b8e3d54346acdf1dd55a9ba4cb91dcace192fc1baf228c08b5.css" integrity="sha256-pXgSV95Bl7jj1UNGrN8d1VqbpMuR3KzhkvwbryKMCLU=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://lngnmn2.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://lngnmn2.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://lngnmn2.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://lngnmn2.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://lngnmn2.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://lngnmn2.github.io/articles/defeating-nondeterminism/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
                color-scheme: dark;
            }

            .list {
                background: var(--theme);
            }

            .toc {
                background: var(--entry);
            }
        }

        @media (prefers-color-scheme: light) {
            .list::-webkit-scrollbar-thumb {
                border-color: var(--code-bg);
            }
        }

    </style>
</noscript>
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.querySelector("html").dataset.theme = 'dark';
    } else if (localStorage.getItem("pref-theme") === "light") {
       document.querySelector("html").dataset.theme = 'light';
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.querySelector("html").dataset.theme = 'dark';
    } else {
        document.querySelector("html").dataset.theme = 'light';
    }

</script><link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Source+Code+Pro:wght@300&display=swap" rel="stylesheet">
<link href="https://fonts.googleapis.com/css2?family=Noto+Sans:wght@300&display=swap" rel="stylesheet">
<link href="https://fonts.googleapis.com/css2?family=Noto+Serif:wght@300&display=swap" rel="stylesheet">
<style>
font-family: 'Noto Serif', serif;
font-family: 'Noto Sans', sans-serif;
font-family: 'Source Code Pro', monospace;
</style>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script type="text/javascript" id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script><meta property="og:url" content="https://lngnmn2.github.io/articles/defeating-nondeterminism/">
  <meta property="og:site_name" content="Notes from the digital underground by Lngnmn">
  <meta property="og:title" content="Defeating Nondeterminism, my ass">
  <meta property="og:description" content="LOL, LMAO even">
  <meta property="og:locale" content="en-us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="articles">
    <meta property="article:published_time" content="2025-09-11T00:00:00+05:45">
    <meta property="article:modified_time" content="2025-09-11T12:43:07+05:45">
    <meta property="article:tag" content="LLM">
    <meta property="article:tag" content="AI">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Defeating Nondeterminism, my ass">
<meta name="twitter:description" content="LOL, LMAO even">


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Articles",
      "item": "https://lngnmn2.github.io/articles/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Defeating Nondeterminism, my ass",
      "item": "https://lngnmn2.github.io/articles/defeating-nondeterminism/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Defeating Nondeterminism, my ass",
  "name": "Defeating Nondeterminism, my ass",
  "description": "LOL, LMAO even",
  "keywords": [
    "LLM", "AI"
  ],
  "articleBody": "And while passing by…\nYet another “look, look at us, we are soooo smart and clever, give us much more money just because we are so cool” article dropped.\nhttps://thinkingmachines.ai/blog/defeating-nondeterminism-in-llm-inference/\nThe lack of exact precision is not the fundamental issue here. Even if one manages to overcome the “numerical instability issues” and would be able to reproduce always the same structural output from the same linguistic (or otherwise structured) input the “hallucinations” and “subtle bullshitting” won’t go away in principle.\nAs long as sampling from conditional probability distributions, obtained at the level of “tokens” (mere syntax) is the underlying model, no technical trick, larger amount of the training data or an increased precision, even the totally exact math at all levels, will make such model to accurately capture even the simplest aspect of reality. What a probabilistic model “tries to capture” is just at another level of abstraction, semantically very distant from the “training data”.\nAnd no, exact precision is never the issue in Biology. Mother nature relies on crude, gross approximations and on actually capturing somehow the actual, relevant constraints of the environment and on reusing the “stable” recurring patterns in What Is.\nYes, floating point math is inexact. Yes, there are “numerical stability issues”, well-understood since 70s or so, but this is not /“the why” your “AI” is only an appearance of intelligence.\nLet’s however “contribute” some, just for kicks.\nThe “non-determinism you are “trying to defeat” is not jut inherent in the world, it is inherent in the algorithmic approach at all levels, not just floating point math.\nThe weight “initialization” is non-deterministic. There are some “wight answers” from biology – brain has a pre-defined structure of the distinct specialized areas, which is an non-random “initialization” before the actual “training” (fine tuning) begins.\nThe “ordering” in which the tainting occurs (it is inherently sequential after all) does matter a lot (contrary to what some popular bullshitters postulate) and this is another source of non-determinism. One does not have to be Hinton to see that if you “feed in” the carefully written children’s English (pre- and elementary school) textbooks before all the random slop from reddit and 4chan, there will be way less hallucinations , especially when being trained on per-revered written materials.\nThe reason is that earlier “proper” weights would be less prone to distortion by a linguistic noise.\nWhen applied to the code, the common, recurring patterns are “intuitively” captured in the standard library code of classic, concise math-inspired less cluttered and less verbose languages (of the ML family), and ideally, the “coding models” should be trained and operate at the level of “pure ASTs” – some evolved intermediate representation, just like advanced compilers of by really smart people (GHC) do.\nOperating at the level of mere syntax in the context of a source code will always, in principle, yield subtle bullshit here and there.\nLet’s address the “in LLM inference” part.\nSelection of one of many possibilities based on estimated probability is not /“the how” knowledge is obtained. Yes, there is always a less wrong answer (up to some “fixed point”), and it is not “probable”, it “just how it is”.\nIndividual particular outcomes of complex processes are non-deterministic and thus unpredictable, so we think of terms of similarity and of a likelihood of coming out being similar (similar but not the same outcomes), which is the only adequate notion of probability. It is not even the frequencies of observations (mere counting of outcomes), it is due to the inherent non-determinism within the process which produce the individual outcomes.\nIn short, it is prior to counting the outcomes, even the complicated coining with respect to the “previous outcomes”. Ironically, what you will have is a “common belief or conditioning” (not What actually Is), which is an accurate interpretation of “conditional probability” – a measure of belief.\nAs for precision, again, it is not the fundamental requirement. The fundamental requirement regains the same since the times of the Buddha – to see (capture) things as [really] they are. This is what is actually necessary and this is what makes mathematics to be whatever it is.\nAnd no, no amount of computation (or precision) will turn verbiage from reddit “into mathematics”, simply because the process of determining which statement is true or false requires reproducible experiments (the actual, rigorous application of the scientific method) or mechanically verifiable proofs in properly chosen (matching reality) axiomatic system.\nIt is not the loss of associativity what ruins the naive promises of “intelligence”.\nBut yes, your writing is so detailed and pictures are so neat. How much are you entitled to be paid for this?\n",
  "wordCount" : "774",
  "inLanguage": "en",
  "datePublished": "2025-09-11T00:00:00+05:45",
  "dateModified": "2025-09-11T12:43:07+05:45",
  "author":[{
    "@type": "Person",
    "name": "lngnmn2@yahoo.com"
  }],
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://lngnmn2.github.io/articles/defeating-nondeterminism/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Notes from the digital underground by Lngnmn",
    "logo": {
      "@type": "ImageObject",
      "url": "https://lngnmn2.github.io/favicon.ico"
    }
  }
}
</script>
</head>
<body id="top">
    <header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://lngnmn2.github.io/" accesskey="h" title="Notes from the digital underground by Lngnmn (Alt + H)">Notes from the digital underground by Lngnmn</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)" aria-label="Toggle theme">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://lngnmn2.github.io/about/" title="About me.">
                    <span>About me.</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      Defeating Nondeterminism, my ass
    </h1>
    <div class="post-description">
      LOL, LMAO even
    </div>
    <div class="post-meta"><span title='2025-09-11 00:00:00 +0545 +0545'>September 11, 2025</span>&nbsp;·&nbsp;<span>lngnmn2@yahoo.com</span>

</div>
  </header> 
  <div class="post-content"><p>And while passing by&hellip;</p>
<p>Yet another &ldquo;look, look at us, we are soooo smart and clever, give us much more money just because we are so cool&rdquo; article dropped.</p>
<p><a href="https://thinkingmachines.ai/blog/defeating-nondeterminism-in-llm-inference/">https://thinkingmachines.ai/blog/defeating-nondeterminism-in-llm-inference/</a></p>
<p>The lack of exact precision is not the fundamental issue here. Even if one manages to overcome the &ldquo;numerical instability issues&rdquo; and would be able to reproduce always the same structural output from the same linguistic (or otherwise structured) input the &ldquo;hallucinations&rdquo; and &ldquo;subtle bullshitting&rdquo; won&rsquo;t go away in principle.</p>
<p>As long as sampling from conditional probability distributions, obtained at the level of &ldquo;tokens&rdquo; (mere syntax) is the underlying model, no technical trick, larger amount of the training data or  an increased precision, even the totally exact math at all levels, will make such model to accurately capture even the simplest aspect of reality. What a probabilistic model &ldquo;tries to capture&rdquo; is just at another level of abstraction, semantically very distant from the &ldquo;training data&rdquo;.</p>
<p>And no, exact precision is never the issue in Biology. Mother nature relies on crude, gross approximations and on <em>actually capturing somehow</em> the actual, relevant constraints of the environment and on reusing the &ldquo;stable&rdquo; recurring patterns in What Is.</p>
<p>Yes, floating point math is inexact. Yes, there are &ldquo;numerical stability issues&rdquo;, well-understood since 70s or so, but this is <em>not /&ldquo;the why&rdquo;</em> your &ldquo;AI&rdquo; is only an <em>appearance of</em> intelligence.</p>
<p>Let&rsquo;s however &ldquo;contribute&rdquo; some, just for kicks.</p>
<p>The &ldquo;non-determinism you are &ldquo;trying to defeat&rdquo; is not jut inherent in the world, it is inherent in the algorithmic approach at all levels, not just floating point math.</p>
<p>The weight &ldquo;initialization&rdquo; is non-deterministic. There are some &ldquo;wight answers&rdquo; from biology &ndash; brain has a pre-defined structure of the distinct specialized areas, which is an non-random &ldquo;initialization&rdquo; before the actual &ldquo;training&rdquo; (fine tuning) begins.</p>
<p>The &ldquo;ordering&rdquo; in which the tainting occurs (it is inherently sequential after all) does matter a lot (contrary to what some popular bullshitters postulate) and this is another source of non-determinism. One does not have to be Hinton to see that if you &ldquo;feed in&rdquo; the carefully written children&rsquo;s English (pre- and elementary school) textbooks <em>before</em> all the random slop from reddit and 4chan, there will be way less hallucinations , especially when being trained on per-revered written materials.</p>
<p>The reason is that earlier &ldquo;proper&rdquo; weights would be less prone to distortion by a linguistic noise.</p>
<p>When applied to the code, the common, recurring patterns are &ldquo;intuitively&rdquo; captured in the standard library code of classic, concise math-inspired less  cluttered and less verbose languages (of the ML family), and ideally, the &ldquo;coding models&rdquo; should be trained and operate at the level of &ldquo;pure ASTs&rdquo; &ndash; some evolved intermediate representation, just like advanced compilers of by really smart people (GHC) do.</p>
<p>Operating at the level of mere syntax in the context of a source code will <em>always</em>, in principle, yield subtle bullshit here and there.</p>
<p>Let&rsquo;s address the &ldquo;in LLM inference&rdquo; part.</p>
<p>Selection of one of many possibilities based on estimated probability is <em>not /&ldquo;the how&rdquo;</em> knowledge is obtained. Yes, there is always a less wrong answer (up to some &ldquo;fixed point&rdquo;), and it is not &ldquo;probable&rdquo;, it &ldquo;just how it is&rdquo;.</p>
<p>Individual particular outcomes of complex processes are non-deterministic and thus unpredictable, so we think of terms of similarity and of a likelihood of coming out being similar (similar but not the same outcomes), which is the only adequate notion of probability. It is not even the frequencies of observations (mere counting of outcomes), it is due to the inherent non-determinism within the process which produce the individual outcomes.</p>
<p>In short, it is prior to counting the outcomes, even the complicated coining with respect to the &ldquo;previous outcomes&rdquo;. Ironically, what you will have is a &ldquo;common belief or conditioning&rdquo; (not What actually Is), which is an accurate interpretation of &ldquo;conditional probability&rdquo; &ndash; a measure of belief.</p>
<p>As for precision, again, it is not the fundamental requirement. The fundamental requirement regains the same since the times of the Buddha &ndash; <em>to see (capture) things as [really] they are</em>. This is what is actually necessary and this is what makes mathematics to be whatever it is.</p>
<p>And no, no amount of computation (or precision) will turn verbiage from reddit &ldquo;into mathematics&rdquo;, simply because the process of determining which statement is true or false requires reproducible experiments (the actual, rigorous application of the scientific method) or mechanically verifiable proofs in properly chosen (matching reality) axiomatic system.</p>
<p>It is not the loss of associativity what ruins the naive promises of &ldquo;intelligence&rdquo;.</p>
<p>But yes, your writing is so detailed and pictures are so neat. How much are you <em>entitled</em> to be paid for this?</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://lngnmn2.github.io/tags/llm/">LLM</a></li>
      <li><a href="https://lngnmn2.github.io/tags/ai/">AI</a></li>
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2026 <a href="https://lngnmn2.github.io/">Notes from the digital underground by Lngnmn</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu');
    if (menu) {
        
        const scrollPosition = localStorage.getItem("menu-scroll-position");
        if (scrollPosition) {
            menu.scrollLeft = parseInt(scrollPosition, 10);
        }
        
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        const html = document.querySelector("html");
        if (html.dataset.theme === "dark") {
            html.dataset.theme = 'light';
            localStorage.setItem("pref-theme", 'light');
        } else {
            html.dataset.theme = 'dark';
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
