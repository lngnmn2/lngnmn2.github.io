<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>No, it doesn&#39;t. | Notes from the digital underground by Lngnmn</title>
<meta name="keywords" content="esoteric">
<meta name="description" content="There is a typical quote from some random Chud on the internet:
The location within the [high-dimensional hyper-] space represents the semantic meaning of the content, according to the embedding model’s weird, mostly incomprehensible understanding of the world.
This is bullshit at so many levels, and in a such &ldquo;lecturing&rdquo; tone.
First of all, there is no &ldquo;understanding&rdquo; whatsoever and it is not &ldquo;of the world&rdquo;.
&ldquo;The world&rdquo; is at a fundamentally different level of abstraction from what has been used as &ldquo;inputs&rdquo; to a language model.">
<meta name="author" content="&amp;lt;lngnmn2@yahoo.com&amp;gt;">
<link rel="canonical" href="https://lngnmn2.github.io/articles/no-it-doesnt/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.b609c58d5c11bb90b1a54e04005d74ad1ddf22165eb79f5533967e57df9c3b50.css" integrity="sha256-tgnFjVwRu5CxpU4EAF10rR3fIhZet59VM5Z&#43;V9&#43;cO1A=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://lngnmn2.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://lngnmn2.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://lngnmn2.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://lngnmn2.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://lngnmn2.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://lngnmn2.github.io/articles/no-it-doesnt/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Source+Code+Pro:wght@300&display=swap" rel="stylesheet">
<link href="https://fonts.googleapis.com/css2?family=Noto+Sans:wght@300&display=swap" rel="stylesheet">
<link href="https://fonts.googleapis.com/css2?family=Noto+Serif:wght@300&display=swap" rel="stylesheet">
<style>
font-family: 'Noto Serif', serif;
font-family: 'Noto Sans', sans-serif;
font-family: 'Source Code Pro', monospace;
</style>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script type="text/javascript" id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  

<meta property="og:title" content="No, it doesn&#39;t." />
<meta property="og:description" content="There is a typical quote from some random Chud on the internet:
The location within the [high-dimensional hyper-] space represents the semantic meaning of the content, according to the embedding model’s weird, mostly incomprehensible understanding of the world.
This is bullshit at so many levels, and in a such &ldquo;lecturing&rdquo; tone.
First of all, there is no &ldquo;understanding&rdquo; whatsoever and it is not &ldquo;of the world&rdquo;.
&ldquo;The world&rdquo; is at a fundamentally different level of abstraction from what has been used as &ldquo;inputs&rdquo; to a language model." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://lngnmn2.github.io/articles/no-it-doesnt/" /><meta property="article:section" content="articles" />
<meta property="article:published_time" content="2023-10-24T00:00:00+05:45" />
<meta property="article:modified_time" content="2023-10-24T10:58:15+05:45" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="No, it doesn&#39;t."/>
<meta name="twitter:description" content="There is a typical quote from some random Chud on the internet:
The location within the [high-dimensional hyper-] space represents the semantic meaning of the content, according to the embedding model’s weird, mostly incomprehensible understanding of the world.
This is bullshit at so many levels, and in a such &ldquo;lecturing&rdquo; tone.
First of all, there is no &ldquo;understanding&rdquo; whatsoever and it is not &ldquo;of the world&rdquo;.
&ldquo;The world&rdquo; is at a fundamentally different level of abstraction from what has been used as &ldquo;inputs&rdquo; to a language model."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Articles",
      "item": "https://lngnmn2.github.io/articles/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "No, it doesn't.",
      "item": "https://lngnmn2.github.io/articles/no-it-doesnt/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "No, it doesn't.",
  "name": "No, it doesn\u0027t.",
  "description": "There is a typical quote from some random Chud on the internet:\nThe location within the [high-dimensional hyper-] space represents the semantic meaning of the content, according to the embedding model’s weird, mostly incomprehensible understanding of the world.\nThis is bullshit at so many levels, and in a such \u0026ldquo;lecturing\u0026rdquo; tone.\nFirst of all, there is no \u0026ldquo;understanding\u0026rdquo; whatsoever and it is not \u0026ldquo;of the world\u0026rdquo;.\n\u0026ldquo;The world\u0026rdquo; is at a fundamentally different level of abstraction from what has been used as \u0026ldquo;inputs\u0026rdquo; to a language model.",
  "keywords": [
    "esoteric"
  ],
  "articleBody": "There is a typical quote from some random Chud on the internet:\nThe location within the [high-dimensional hyper-] space represents the semantic meaning of the content, according to the embedding model’s weird, mostly incomprehensible understanding of the world.\nThis is bullshit at so many levels, and in a such “lecturing” tone.\nFirst of all, there is no “understanding” whatsoever and it is not “of the world”.\n“The world” is at a fundamentally different level of abstraction from what has been used as “inputs” to a language model.\nWhat that represents is not the how the world is, but some information encoded in a particular way, from a huge garbage pile, a verbiage landfill, so to speak.\nLet’s see what is actually going on at a higher level.\nThere is some “world”, in which there are human beings, which have evolved an ability to use sequences of sounds to communicate with one another about some particular aspects of it.\nThe basis of any human language is “things”, their “attributes” and the words used to describe and characterize “processes”.\nThere is something evolved since the beginning of time which is called “predicate logic” and then a “first order logic”, which define or at least show what a precise and correct use of a language shall be.\nNotice that any human language is in principle sequential, and to partially overcome this limitations a set of rules has been invented, to indicate relations among individual words.\nI intentionally do not use the term “semantic relations” hare, because it is from joggling with ill-defined terminology and in the wrong (unapplicable) contexts bullshit arise.\nSo, in every language there is the same abstract structure, which intended to mimic the actual structure of the world - there are “things” (“objects”) and their “attributes”.\nSo, the structure of the world is being collapsed into some linear structure with some implicit relations, which are represented in a linear structure according to the set of grammar rules for a particular language.\nTraditionally, linguists are using trees to represent the “full structure” of a sentence.\nIt has been well-understood that just these abstract tree-like structures are not enough to reconstruct the intended meaning of a communication and the shared context is required for a communication to be meaningful.\nThe Chuds think that the contexts could be “learned” from (by observing) the sequences of words, while the results show that the shared context comes first.\nWhat then is actually going on there?\nWell, structural transformations of information (at the level of a language without a well-defined context).\nIt is exactly similar to what a search engine does - it indexes (conceptually - rearranges) the words of a language and builds a complex data structure (informally called a “global index”). This index then is used to find “similar” or “related” pages (texts).\nDoes a search engine or it “global index” has any understanding of the world? Hardly. Would we call a “global index” a (form of) intelligence? Probably not, if you are not a Chud.\nNow what about that “semantic meaning”?\nDoes “semantic meaning” arise or emerge when one re-arranges sequential (ok, tree-like) pieces of data into a high-dimensional structure? Probably not.\nThe “meaning” exists only at the level of the world for which words of a language are mere crude “labels”.\nNow the most fundamental question: Does the resulting multi-dimensional structure actually captures or reproduces and then represents the actual structure of the world? No, it does not.\nIt cannot, in principle, not just because “the map is not the territory” (especially a totally abstract map of an arbitrary structure), but because the “relations” are being broken at each level of abstraction.\nHere is how. One takes a lot of text and feeds it onto a “structural transformation” process (a procedure) which spits out an high-dimensional hyper index of abstract pieces (not even sounds).\nThe notion of distances is very intuitive and “natural” but unwarranted and misleading, because it has been applied to the wrong level of abstraction.\nAll the results are no different from a search-engine output based on a frequencies statistics and mostly about nouns, which are closest to the actual reality (the world).\nNouns are “sorted” or “indexed” and the index somehow “mimics” the world.\nAt the level of mere words it does not. The individual “maps” within out brains is what create a “coherent picture” and recreate the meaning from the output, slightly different for each person, due to the differences in their inner “maps”.\nThe “meaning” is not in the information itself, it is inside our heads, which continuously update and maintain an inner representations (“maps”) of our environment (“world”).\nSo, what exactly all the Chuds are doing?\nThey play games with their own brains, by creating highly distorted, completely disconnected form reality set of clues to the brain, and watch how it reconstructs reality back form given abstract bullshit.\nThis is what they do. They give to brain an abstract bullshit (that went trough a shredder first and then arranged into a hyper-plane, or what they prefer to call it, by “learning” (counting) the frequencies of the individual pieces, and use this as the “correct” map of the world) to interpret.\nNow pay attention. All the semantic meaning and understanding is NOT within the models, but withing interpretations our brains gave to what we “see” (the outputs of the models).\nThe abstract notion of a “distance” between pieces is only “meaningful” because the world has its structure, and there are, indeed, causality relations between “things” and “objects” (sub-processes).\nIn short, all these complex “structural transformations” of information (only) have no more meaning that Hegelian “philosophy” or astrology.\nCalculations, just as arrangements of abstract concepts, can be completely meaningless, like multiplying birds by trees or calculating “distances” between words taken from a huge garbage dump.\nThe fact that none of these transformations are applicable to mathematical texts is my informal “proof by contradiction”.\nNo “new meanings” can be “generated” by merely shuffling the shredded pieces of a verbiage. It has to be “Out There Prior To That” and has to be captured in the texts which are used to train a model.\nIn short, bullshit, bullshit everywhere. And nothing more “semantically meaningful” that a frequency based statistics, used to “mimic” the actual world for the brain of an external observer, so it can barely interpret all this Chud’s nonsense.\n",
  "wordCount" : "1062",
  "inLanguage": "en",
  "datePublished": "2023-10-24T00:00:00+05:45",
  "dateModified": "2023-10-24T10:58:15+05:45",
  "author":[{
    "@type": "Person",
    "name": "\u0026lt;lngnmn2@yahoo.com\u0026gt;"
  }],
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://lngnmn2.github.io/articles/no-it-doesnt/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Notes from the digital underground by Lngnmn",
    "logo": {
      "@type": "ImageObject",
      "url": "https://lngnmn2.github.io/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://lngnmn2.github.io/" accesskey="h" title="Notes from the digital underground by Lngnmn (Alt + H)">Notes from the digital underground by Lngnmn</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://lngnmn2.github.io/about/" title="About me.">
                    <span>About me.</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      No, it doesn&#39;t.
    </h1>
    <div class="post-meta"><span title='2023-10-24 00:00:00 +0545 +0545'>October 24, 2023</span>&nbsp;·&nbsp;&amp;lt;lngnmn2@yahoo.com&amp;gt;

</div>
  </header> 
  <div class="post-content"><p>There is a typical quote from some random Chud on the internet:</p>
<blockquote>
<p>The location within the [high-dimensional hyper-] space represents the
semantic meaning of the content, according to the embedding model’s
weird, mostly incomprehensible understanding of the world.</p>
</blockquote>
<p>This is bullshit at so many levels, and in a such &ldquo;lecturing&rdquo; tone.</p>
<p>First of all, there is no &ldquo;understanding&rdquo; whatsoever and it is not &ldquo;of
the world&rdquo;.</p>
<p>&ldquo;The world&rdquo; is at a fundamentally different level of abstraction from
what has been used as &ldquo;inputs&rdquo; to a language model.</p>
<p>What that <em>represents</em> is not the how the world is, but some
information encoded in a particular way, from a huge garbage pile, a
verbiage landfill, so to speak.</p>
<p>Let&rsquo;s see what is <em>actually</em> going on at a higher level.</p>
<p>There is some &ldquo;world&rdquo;, in which there are human beings, which have
evolved an ability to use sequences of sounds to communicate with one another
about some particular aspects of it.</p>
<p>The basis of <em>any</em> human language is &ldquo;things&rdquo;, their &ldquo;attributes&rdquo; and the
words used to describe and characterize &ldquo;processes&rdquo;.</p>
<p>There is something evolved since the beginning of time which is called
&ldquo;predicate logic&rdquo; and then a &ldquo;first order logic&rdquo;, which define or at
least <em>show</em> what a <em>precise and correct</em> use of a language shall be.</p>
<p>Notice that any human language is in principle <em>sequential</em>, and to
partially overcome this limitations a set of rules has been invented,
to indicate <em>relations</em> among individual words.</p>
<p>I intentionally do not use the term &ldquo;semantic relations&rdquo; hare, because
it is from joggling with ill-defined terminology and in the wrong
(unapplicable) contexts bullshit arise.</p>
<p>So, in every language there is the same abstract structure, which
intended to mimic the actual structure of the world - there are
&ldquo;things&rdquo; (&ldquo;objects&rdquo;) and their &ldquo;attributes&rdquo;.</p>
<p>So, the structure of the world is being collapsed into some linear
structure with some implicit <em>relations</em>, which are represented in a
linear structure according to the set of grammar rules for a particular
language.</p>
<p>Traditionally, linguists are using <em>trees</em> to represent the &ldquo;full
structure&rdquo; of a sentence.</p>
<p>It has been well-understood that just these abstract tree-like
structures are <em>not enough</em> to reconstruct the intended meaning of a
communication and the shared <em>context</em> is required for a communication to
be meaningful.</p>
<p>The Chuds think that the <em>contexts</em> could be &ldquo;learned&rdquo; from (by observing)
the sequences of words, while the results show that the shared context
<em>comes first</em>.</p>
<p>What then is actually going on there?</p>
<p>Well, structural transformations of information (at the level of a
language without a well-defined context).</p>
<p>It is exactly similar to what a search engine does - it indexes
(conceptually - rearranges) the words of a language and builds a complex
data structure (informally called a &ldquo;global index&rdquo;). This index then is
used to find &ldquo;similar&rdquo; or &ldquo;related&rdquo; pages (texts).</p>
<p>Does a search engine or it &ldquo;global index&rdquo; has any understanding of the
world? Hardly. Would we call a &ldquo;global index&rdquo; a (form of) intelligence?
Probably not, if you are not a Chud.</p>
<p>Now what about that &ldquo;semantic meaning&rdquo;?</p>
<p>Does &ldquo;semantic meaning&rdquo; <em>arise</em> or <em>emerge</em> when one re-arranges sequential
(ok, tree-like) pieces of data into a high-dimensional structure?
Probably not.</p>
<p>The &ldquo;meaning&rdquo; exists only at the level of the world for which words of a
language are mere crude &ldquo;labels&rdquo;.</p>
<p>Now the most fundamental question: Does the resulting multi-dimensional
structure actually <em>captures</em> or <em>reproduces</em> and then represents the actual
structure of the world? No, it does not.</p>
<p>It cannot, in principle, not just because &ldquo;the map is not the territory&rdquo;
(especially a totally abstract map of an arbitrary structure), but
because the &ldquo;relations&rdquo; are being broken at each level of abstraction.</p>
<p>Here is how. One takes a lot of text and feeds it onto a &ldquo;structural
transformation&rdquo; process (a procedure) which spits out an
high-dimensional hyper index of abstract pieces (not even sounds).</p>
<p>The notion of <em>distances</em> is very intuitive and &ldquo;natural&rdquo; but unwarranted
and misleading, because it has been applied to the wrong level of
abstraction.</p>
<p>All the results are no different from a search-engine output based on
a frequencies statistics and mostly about nouns, which are closest to
the actual reality (the world).</p>
<p>Nouns are &ldquo;sorted&rdquo; or &ldquo;indexed&rdquo; and the index somehow &ldquo;mimics&rdquo; the
world.</p>
<p>At the level of mere words it does not. The individual &ldquo;maps&rdquo; within out
brains is what create a &ldquo;coherent picture&rdquo; and <em>recreate</em> the meaning from
the output, slightly different for each person, due to the differences
in their inner &ldquo;maps&rdquo;.</p>
<p>The &ldquo;meaning&rdquo; is not in the information itself, it is inside our
heads, which continuously update and maintain an inner representations
(&ldquo;maps&rdquo;) of our environment (&ldquo;world&rdquo;).</p>
<p>So, what <em>exactly</em> all the Chuds are doing?</p>
<p>They play games with their own brains, by creating highly distorted,
completely disconnected form reality set of clues to the brain, and
watch how it <em>reconstructs reality back form given abstract bullshit</em>.</p>
<p>This is what they do. They give to brain an abstract bullshit (that went
trough a shredder first and then arranged into a hyper-plane, or what
they prefer to call it, by &ldquo;learning&rdquo; (counting) the frequencies of the
individual pieces, and use <em>this</em> as the &ldquo;correct&rdquo; <em>map</em> of the world) to
interpret.</p>
<p>Now pay attention. All the semantic meaning and understanding is <em>NOT</em>
within the models, but withing interpretations our brains gave to what
we &ldquo;see&rdquo; (the outputs of the models).</p>
<p>The abstract notion of a &ldquo;distance&rdquo; between pieces is only &ldquo;meaningful&rdquo;
because the world has its structure, and there are, indeed, causality
relations between &ldquo;things&rdquo; and &ldquo;objects&rdquo; (sub-processes).</p>
<p>In short, all these complex &ldquo;structural transformations&rdquo; of information
(only) have no more meaning that Hegelian &ldquo;philosophy&rdquo; or astrology.</p>
<p>Calculations, just as arrangements of abstract concepts, can be
completely meaningless, like multiplying birds by trees or calculating
&ldquo;distances&rdquo; between words taken from a huge garbage dump.</p>
<p>The fact that none of these transformations are applicable to
mathematical texts is my informal &ldquo;proof by contradiction&rdquo;.</p>
<p>No &ldquo;new meanings&rdquo; can be &ldquo;generated&rdquo; by merely shuffling the shredded
pieces of a verbiage. It has to be &ldquo;Out There Prior To That&rdquo; and has to
be captured in the texts which are used to train a model.</p>
<p>In short, <em>bullshit, bullshit everywhere</em>. And nothing more &ldquo;semantically
meaningful&rdquo; that a frequency based statistics, used to &ldquo;mimic&rdquo; the
actual world <em>for the brain of an external observer</em>, so it can barely
interpret all this Chud&rsquo;s nonsense.</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://lngnmn2.github.io/tags/esoteric/">Esoteric</a></li>
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2024 <a href="https://lngnmn2.github.io/">Notes from the digital underground by Lngnmn</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
