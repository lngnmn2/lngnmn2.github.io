<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>LLMs and AI so far | Notes from the digital underground by Lngnmn</title>
<meta name="keywords" content="AI, LLM">
<meta name="description" content="Let&rsquo;s summarize the current state of Large Language Models (LLMs) and so called &ldquo;Artificial Intelligence&rdquo; (AI) as of October 2025.
They all are still just [estimated] probabilities of the next token, given the &ldquo;context&rdquo;.
This implies no &ldquo;knowledge&rdquo; or &ldquo;understanding&rdquo; [of any kind] whatsoever. Nothing can be taken as &ldquo;true&rdquo; or even &ldquo;correct&rdquo; or &ldquo;accurate&rdquo;.
All the talks about &ldquo;knowledge in the weights&rdquo; or &ldquo;knowledge encoded within the network&rdquo; is just bullshit.">
<meta name="author" content="lngnmn2@yahoo.com">
<link rel="canonical" href="https://lngnmn2.github.io/articles/llms-and-ai-so-far/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.d0049500090a8b5b522a30f4bc70f815df41595125d25503dff47281216974cb.css" integrity="sha256-0ASVAAkKi1tSKjD0vHD4Fd9BWVEl0lUD3/RygSFpdMs=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://lngnmn2.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://lngnmn2.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://lngnmn2.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://lngnmn2.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://lngnmn2.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://lngnmn2.github.io/articles/llms-and-ai-so-far/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Source+Code+Pro:wght@300&display=swap" rel="stylesheet">
<link href="https://fonts.googleapis.com/css2?family=Noto+Sans:wght@300&display=swap" rel="stylesheet">
<link href="https://fonts.googleapis.com/css2?family=Noto+Serif:wght@300&display=swap" rel="stylesheet">
<style>
font-family: 'Noto Serif', serif;
font-family: 'Noto Sans', sans-serif;
font-family: 'Source Code Pro', monospace;
</style>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script type="text/javascript" id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script><meta property="og:url" content="https://lngnmn2.github.io/articles/llms-and-ai-so-far/">
  <meta property="og:site_name" content="Notes from the digital underground by Lngnmn">
  <meta property="og:title" content="LLMs and AI so far">
  <meta property="og:description" content="Let’s summarize the current state of Large Language Models (LLMs) and so called “Artificial Intelligence” (AI) as of October 2025.
They all are still just [estimated] probabilities of the next token, given the “context”.
This implies no “knowledge” or “understanding” [of any kind] whatsoever. Nothing can be taken as “true” or even “correct” or “accurate”.
All the talks about “knowledge in the weights” or “knowledge encoded within the network” is just bullshit.">
  <meta property="og:locale" content="en-us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="articles">
    <meta property="article:published_time" content="2025-10-04T00:00:00+05:45">
    <meta property="article:modified_time" content="2025-10-04T11:41:48+05:45">
    <meta property="article:tag" content="AI">
    <meta property="article:tag" content="LLM">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="LLMs and AI so far">
<meta name="twitter:description" content="Let&rsquo;s summarize the current state of Large Language Models (LLMs) and so called &ldquo;Artificial Intelligence&rdquo; (AI) as of October 2025.
They all are still just [estimated] probabilities of the next token, given the &ldquo;context&rdquo;.
This implies no &ldquo;knowledge&rdquo; or &ldquo;understanding&rdquo; [of any kind] whatsoever. Nothing can be taken as &ldquo;true&rdquo; or even &ldquo;correct&rdquo; or &ldquo;accurate&rdquo;.
All the talks about &ldquo;knowledge in the weights&rdquo; or &ldquo;knowledge encoded within the network&rdquo; is just bullshit.">


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Articles",
      "item": "https://lngnmn2.github.io/articles/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "LLMs and AI so far",
      "item": "https://lngnmn2.github.io/articles/llms-and-ai-so-far/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "LLMs and AI so far",
  "name": "LLMs and AI so far",
  "description": "Let\u0026rsquo;s summarize the current state of Large Language Models (LLMs) and so called \u0026ldquo;Artificial Intelligence\u0026rdquo; (AI) as of October 2025.\nThey all are still just [estimated] probabilities of the next token, given the \u0026ldquo;context\u0026rdquo;.\nThis implies no \u0026ldquo;knowledge\u0026rdquo; or \u0026ldquo;understanding\u0026rdquo; [of any kind] whatsoever. Nothing can be taken as \u0026ldquo;true\u0026rdquo; or even \u0026ldquo;correct\u0026rdquo; or \u0026ldquo;accurate\u0026rdquo;.\nAll the talks about \u0026ldquo;knowledge in the weights\u0026rdquo; or \u0026ldquo;knowledge encoded within the network\u0026rdquo; is just bullshit.\n",
  "keywords": [
    "AI", "LLM"
  ],
  "articleBody": "Let’s summarize the current state of Large Language Models (LLMs) and so called “Artificial Intelligence” (AI) as of October 2025.\nThey all are still just [estimated] probabilities of the next token, given the “context”.\nThis implies no “knowledge” or “understanding” [of any kind] whatsoever. Nothing can be taken as “true” or even “correct” or “accurate”.\nAll the talks about “knowledge in the weights” or “knowledge encoded within the network” is just bullshit.\nThis is a gigantic, hard to comprehend, unprecedented, bubble. Just as in the Tulip Mania, people throw money at it, hoping to make more money, without any understanding of what is going on or whether it is possible to actually make money with a “glorified autocomplete”, which is always subtly wrong [and often very wrong].\nThere are apparent gains in “productivity” (the sheer speed at which the low-effort crap can be produced and pushed out, to become other people’s problem), but no real gains in “intelligence”.\nMidwits are already publishing tons of “articles” about how they produced “research papers” with LLMs, for impress other midwits and to trick normies to see them as “very smart and capable people”.\nThe process as a whole is just systematic “enshittification” of knowledge itself, and almost vertical race to the bottom, where a low-effort pretentious verbiage is the lowest common denominator.\nThe “AI” hype is just a “mass hysteria”, based on the same underlying psychology of greed, fear of missing out (FOMO), and herd mentality.\nThe only money being made is by those who burn through trillions of other people’s (shareholder’s and “invertor’s”) money, and by those who sell the hype and the shovels (NVDA).\nRiding such a wave of mass hysteria is a solid strategy to make money (until the bubble bursts, and the actual loses will be passed on someone else), but it is not a sustainable strategy.\nThis is what Sam, Karpathy and literally everyone else are doing. While Sam does not know a shit, Karpathy at least knows it is a fraud, but makes money by shilling and “investing”.\nThere is still not a single example of a coding “breakthrough”, when some exceptionally good quality code has been produced, so everyone would be stunned with an ave. The slop is usually subpar or just bad.\nVast majority of the code slop is in dynamically typed languages (Python, JS), where subtle errors tend to stay undetected until some particular conditions (a state of the system) would happen.\nThe slop written in strongly typed, compled languages tend to always fail to compile (due to obvious reasons).\nNevertheless, a life-long, slowly and painfully earned expertise suddenly became “not required”, and even “the right understanding” is now considered (by midwits) as being “redundant”.\nThe economic scenario is quite obvious – an accelerating race to the bottom, to “near zero margins”, as it is the case with selling junkfood (fastfood – the slop).\nLast but not least, the actual models are being literally “lobotomized” by so-called post-training (manally, by large crowds of midwits) and by “alignment” (a.k.a. “safety”) procedures, which are just a fancy term for “censorship” and “propaganda”. In the end this is just a “repackaged internet content”.\nThe “uncensored”, “untuned” models – the original “glorified autocompletes”, which can produce a lot of “harmful” (to midwits and normies) content, are thus much better ones. There is no surprise that they are being suppressed and removed from the public access.\nExpect an apocalyptic “crashing and burning”, because these trillions of “investments” are being made on an ultimately false premise (in principle), and will never be seen again. It will take the whole “tech” industry down with it.\nExpect a “nuclear winter” for the whole “tech” industry, and a “lost decade” (or more) for the whole “software development” industry. Simply because more and more bloated “webshit” (or “Electron appshit”) is not what the world needs, and the “low-effort slop” is not what will make the financial returns.\nThe wall is about to be hit, and hard.\n",
  "wordCount" : "662",
  "inLanguage": "en",
  "datePublished": "2025-10-04T00:00:00+05:45",
  "dateModified": "2025-10-04T11:41:48+05:45",
  "author":[{
    "@type": "Person",
    "name": "lngnmn2@yahoo.com"
  }],
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://lngnmn2.github.io/articles/llms-and-ai-so-far/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Notes from the digital underground by Lngnmn",
    "logo": {
      "@type": "ImageObject",
      "url": "https://lngnmn2.github.io/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://lngnmn2.github.io/" accesskey="h" title="Notes from the digital underground by Lngnmn (Alt + H)">Notes from the digital underground by Lngnmn</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)" aria-label="Toggle theme">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://lngnmn2.github.io/about/" title="About me.">
                    <span>About me.</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      LLMs and AI so far
    </h1>
    <div class="post-meta"><span title='2025-10-04 00:00:00 +0545 +0545'>October 4, 2025</span>&nbsp;·&nbsp;<span>lngnmn2@yahoo.com</span>

</div>
  </header> 
  <div class="post-content"><p>Let&rsquo;s summarize the current state of Large Language Models (LLMs) and so called &ldquo;Artificial Intelligence&rdquo; (AI) as of October 2025.</p>
<p>They all are still just [estimated] probabilities of the next token, given the &ldquo;context&rdquo;.</p>
<p>This implies no &ldquo;knowledge&rdquo; or &ldquo;understanding&rdquo; [of any kind] whatsoever. Nothing can be taken as &ldquo;true&rdquo; or even &ldquo;correct&rdquo; or &ldquo;accurate&rdquo;.</p>
<p>All the talks about &ldquo;knowledge in the weights&rdquo; or &ldquo;knowledge encoded within the network&rdquo; is just bullshit.</p>
<p>This is a gigantic, hard to comprehend, unprecedented,  bubble. Just as in the Tulip Mania, people throw money at it, hoping to make more money, without any understanding of what is going on or whether it is possible to actually make money with a &ldquo;<em>glorified autocomplete</em>&rdquo;, which is always subtly wrong [and often very wrong].</p>
<p>There are <em>apparent</em> gains in &ldquo;productivity&rdquo; (the <em>sheer speed</em> at which the <em>low-effort crap</em> can be produced and pushed out, to become other people&rsquo;s problem), but no real gains in &ldquo;intelligence&rdquo;.</p>
<p>Midwits are already publishing tons of &ldquo;articles&rdquo; about how they produced  &ldquo;research papers&rdquo; with LLMs, for impress other midwits and to trick normies to see them as &ldquo;very smart and capable people&rdquo;.</p>
<p>The process as a whole is just systematic &ldquo;enshittification&rdquo; of knowledge itself, and almost vertical race to the bottom, where a low-effort pretentious verbiage is the lowest common denominator.</p>
<p>The &ldquo;AI&rdquo; hype is just a &ldquo;mass hysteria&rdquo;, based on the same underlying psychology of greed, <em>fear of missing out</em> (FOMO), and herd mentality.</p>
<p>The only money being made is by those who burn through <em>trillions</em> of other people&rsquo;s (shareholder&rsquo;s and &ldquo;invertor&rsquo;s&rdquo;) money, and by those who sell the hype and the shovels (NVDA).</p>
<p>Riding such a wave of mass hysteria is a solid strategy to make money (until the bubble bursts, and the actual loses will be passed on someone else), but it is not a sustainable strategy.</p>
<p>This is what Sam, Karpathy and literally everyone  else are doing. While Sam does not know a shit, Karpathy at least knows it is a fraud,  but makes money by shilling and &ldquo;investing&rdquo;.</p>
<p>There is still not a single example of a coding &ldquo;breakthrough&rdquo;, when some exceptionally good quality code has been produced, so everyone would be stunned with an ave. The slop is usually subpar or just bad.</p>
<p>Vast majority of the code slop is in dynamically typed languages (Python, JS), where subtle errors tend to stay undetected until some particular conditions (a state of the system) would happen.</p>
<p>The slop written in  strongly typed, compled languages tend to <em>always</em> fail to compile (due to obvious reasons).</p>
<p>Nevertheless, a life-long, slowly and painfully earned expertise suddenly became &ldquo;not required&rdquo;, and even &ldquo;the right understanding&rdquo; is now considered (by midwits) as being &ldquo;redundant&rdquo;.</p>
<p>The economic scenario is quite obvious &ndash; an accelerating race to the bottom, to &ldquo;near zero margins&rdquo;, as it is the case with selling <em>junkfood</em> (fastfood &ndash; <em>the slop</em>).</p>
<p>Last but not least, the actual models are being literally &ldquo;lobotomized&rdquo; by so-called post-training (manally, by large crowds of midwits) and by &ldquo;alignment&rdquo; (a.k.a. &ldquo;safety&rdquo;) procedures, which are just a fancy term for &ldquo;censorship&rdquo; and &ldquo;propaganda&rdquo;. In the end this is just a &ldquo;repackaged internet content&rdquo;.</p>
<p>The  &ldquo;uncensored&rdquo;, &ldquo;untuned&rdquo; models &ndash; the original &ldquo;glorified autocompletes&rdquo;, which can produce a lot of &ldquo;harmful&rdquo; (to midwits and normies) content, are thus much better ones. There is no surprise that they are being suppressed and removed from the public access.</p>
<p>Expect an apocalyptic &ldquo;crashing and burning&rdquo;, because these trillions of &ldquo;investments&rdquo; are being made on an ultimately false premise (in principle), and will never be seen again. It will take the whole &ldquo;tech&rdquo; industry down with it.</p>
<p>Expect a &ldquo;nuclear winter&rdquo; for the whole &ldquo;tech&rdquo; industry, and a &ldquo;lost decade&rdquo; (or more) for the whole &ldquo;software development&rdquo; industry. Simply because more and more bloated &ldquo;webshit&rdquo; (or &ldquo;Electron appshit&rdquo;) is not what the world needs, and the &ldquo;low-effort slop&rdquo; is not what will make the financial returns.</p>
<p>The wall is about to be hit, and hard.</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://lngnmn2.github.io/tags/ai/">AI</a></li>
      <li><a href="https://lngnmn2.github.io/tags/llm/">LLM</a></li>
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2025 <a href="https://lngnmn2.github.io/">Notes from the digital underground by Lngnmn</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
