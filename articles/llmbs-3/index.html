<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>LLM Bullshit-3 | Notes from the digital underground by Lngnmn</title>
<meta name="keywords" content="">
<meta name="description" content="It is more or less obvious why AI and LLM bubble is so huge - imagine just charging money for every https request to a RESTful API, without, literally, being responsible about the quality of the responce (it is not out fault if a LLM returned bullshit to you, or, which is much worse &ndash; a highly sophisiticated, convincing subtle bullshit).
Again, there is not enough good code to train a model on it. MIT Scheme, Haskell, Ocaml, Scala and Go compilers and standard libraries, and this is basically it. Everything else is an outrageously low-effort amateur crap &ndash; piles upon piles of it, without any attempts to do thinfs &ldquo;just right&rdquo; (as in the classic languages).">
<meta name="author" content="&amp;lt;lngnmn2@yahoo.com&amp;gt;">
<link rel="canonical" href="https://lngnmn2.github.io/articles/llmbs-3/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.2211ca3164be7830024f6aad2b3a2e520843a64f8f048445c3401c1249aa051d.css" integrity="sha256-IhHKMWS&#43;eDACT2qtKzouUghDpk&#43;PBIRFw0AcEkmqBR0=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://lngnmn2.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://lngnmn2.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://lngnmn2.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://lngnmn2.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://lngnmn2.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://lngnmn2.github.io/articles/llmbs-3/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Source+Code+Pro:wght@300&display=swap" rel="stylesheet">
<link href="https://fonts.googleapis.com/css2?family=Noto+Sans:wght@300&display=swap" rel="stylesheet">
<link href="https://fonts.googleapis.com/css2?family=Noto+Serif:wght@300&display=swap" rel="stylesheet">
<style>
font-family: 'Noto Serif', serif;
font-family: 'Noto Sans', sans-serif;
font-family: 'Source Code Pro', monospace;
</style>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script type="text/javascript" id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script><meta property="og:url" content="https://lngnmn2.github.io/articles/llmbs-3/">
  <meta property="og:site_name" content="Notes from the digital underground by Lngnmn">
  <meta property="og:title" content="LLM Bullshit-3">
  <meta property="og:description" content="It is more or less obvious why AI and LLM bubble is so huge - imagine just charging money for every https request to a RESTful API, without, literally, being responsible about the quality of the responce (it is not out fault if a LLM returned bullshit to you, or, which is much worse – a highly sophisiticated, convincing subtle bullshit).
Again, there is not enough good code to train a model on it. MIT Scheme, Haskell, Ocaml, Scala and Go compilers and standard libraries, and this is basically it. Everything else is an outrageously low-effort amateur crap – piles upon piles of it, without any attempts to do thinfs “just right” (as in the classic languages).">
  <meta property="og:locale" content="en-us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="articles">
    <meta property="article:published_time" content="2023-10-02T00:00:00+05:45">
    <meta property="article:modified_time" content="2023-10-02T14:03:06+05:45">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="LLM Bullshit-3">
<meta name="twitter:description" content="It is more or less obvious why AI and LLM bubble is so huge - imagine just charging money for every https request to a RESTful API, without, literally, being responsible about the quality of the responce (it is not out fault if a LLM returned bullshit to you, or, which is much worse &ndash; a highly sophisiticated, convincing subtle bullshit).
Again, there is not enough good code to train a model on it. MIT Scheme, Haskell, Ocaml, Scala and Go compilers and standard libraries, and this is basically it. Everything else is an outrageously low-effort amateur crap &ndash; piles upon piles of it, without any attempts to do thinfs &ldquo;just right&rdquo; (as in the classic languages).">


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Articles",
      "item": "https://lngnmn2.github.io/articles/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "LLM Bullshit-3",
      "item": "https://lngnmn2.github.io/articles/llmbs-3/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "LLM Bullshit-3",
  "name": "LLM Bullshit-3",
  "description": "It is more or less obvious why AI and LLM bubble is so huge - imagine just charging money for every https request to a RESTful API, without, literally, being responsible about the quality of the responce (it is not out fault if a LLM returned bullshit to you, or, which is much worse \u0026ndash; a highly sophisiticated, convincing subtle bullshit).\nAgain, there is not enough good code to train a model on it. MIT Scheme, Haskell, Ocaml, Scala and Go compilers and standard libraries, and this is basically it. Everything else is an outrageously low-effort amateur crap \u0026ndash; piles upon piles of it, without any attempts to do thinfs \u0026ldquo;just right\u0026rdquo; (as in the classic languages).\n",
  "keywords": [
    
  ],
  "articleBody": "It is more or less obvious why AI and LLM bubble is so huge - imagine just charging money for every https request to a RESTful API, without, literally, being responsible about the quality of the responce (it is not out fault if a LLM returned bullshit to you, or, which is much worse – a highly sophisiticated, convincing subtle bullshit).\nAgain, there is not enough good code to train a model on it. MIT Scheme, Haskell, Ocaml, Scala and Go compilers and standard libraries, and this is basically it. Everything else is an outrageously low-effort amateur crap – piles upon piles of it, without any attempts to do thinfs “just right” (as in the classic languages).\nThere is a fundamental principle behind the fact that a machine translation without understanding work reasonably well – there is the same underlying reality behind every human language, more-or-less the same environmental and social constraints (with all the differences between tribes near the north pole and uncontacted tribes of Amazon forrests).\nThere is a simple (and the only correct) translation algorithm, then – reduce the verbalization (encoding) to the environmental aspect it refers to, and then select the verbalization for this notion in a target language. That will be just one-to-one correspondence to nouns (things) such as a “cat” (assuming they have cats in Alaska), and most of nature-related verbs (actions) and adjectinves (colors, etc).\nThis is a gross over-simplification, but the principle is the right one.\nEven better realization of this very principle is the tools called pandoc. It converts (translates) between major structured text formats, by parsing into a fundamental commonstrucure – an AST (such as nested blocks of text) along with attributes (such as italic and so on) and then generates the target format.\nIt works because there is a commonality among most of the supported formats.\nWhat corresponds to the universal common building blocks of programming languages? Well, this is already well-understood.\nAll you need is lambda Recursion ADTs and interfaces (type-signatures) in general Algebraic data types, including GADTS To be precise, the intermediate language of GHC is precisely what is needed (to what everything is reducible to). At a CPU level we have comparisons, loops, moves and procedure calls, but this is too low-level.\nNow you probably got the idea. If (notice this if) we wish to train a model, we have to train it on this kind of intermediate language (of GHC), not on all the syntactic zoo plus low-effort crappy libraries by unqualified amateurs. And definitely not jammed into some 7B “snapshot”.\nThat would be (and really is) is an extremely detailed “molecular level snapshot” of the famous central garbage dump in New Delhi, to which paid API requests could be made.\nNow pay attention. This is not just a dramatic metaphor, this is the closeset possible analogy which is NOT wrong. All the LLMs are snapshots of a whole garbage dump, not of any knowledge which underlies it. I am the same guy who explained it back when the hype only began, and my reasoning is still valid and only get more evidences.\nI do not want to be threated by a doctor who reads LLM bullshit (without understanding), even for a “suggestion”, and to rely on any code pasted from a model without understanding. Yes, it is, perhaps, the biggest corner-cutting tech in human history, but the consequences would be on the same scale.\nJust as math cannot be done by taking a snapshot of a dump, neither programming could. We are almost “solved it” with all the theory which underlies Haskell, and it tell us, if at all, that imperative programming with mutable state is just wrong. Everything works (including this Chrome browser) by a chance and lots of luck.\nSo, with all that genuine autistic persistence popularized in the “Big Short” – this is just bullshit (and a bubble). Pay attention.\n",
  "wordCount" : "649",
  "inLanguage": "en",
  "datePublished": "2023-10-02T00:00:00+05:45",
  "dateModified": "2023-10-02T14:03:06+05:45",
  "author":[{
    "@type": "Person",
    "name": "\u0026lt;lngnmn2@yahoo.com\u0026gt;"
  }],
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://lngnmn2.github.io/articles/llmbs-3/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Notes from the digital underground by Lngnmn",
    "logo": {
      "@type": "ImageObject",
      "url": "https://lngnmn2.github.io/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://lngnmn2.github.io/" accesskey="h" title="Notes from the digital underground by Lngnmn (Alt + H)">Notes from the digital underground by Lngnmn</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)" aria-label="Toggle theme">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://lngnmn2.github.io/about/" title="About me.">
                    <span>About me.</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      LLM Bullshit-3
    </h1>
    <div class="post-meta"><span title='2023-10-02 00:00:00 +0545 +0545'>October 2, 2023</span>&nbsp;·&nbsp;&amp;lt;lngnmn2@yahoo.com&amp;gt;

</div>
  </header> 
  <div class="post-content"><p>It is more or less obvious why AI and LLM bubble is so huge - imagine just charging money for every <code>https</code> request to a <code>RESTful</code> API, without, literally, being responsible about the quality of the responce (it is not out fault if a LLM returned bullshit to you, or, which is much worse &ndash; a highly sophisiticated, convincing subtle bullshit).</p>
<p>Again, there is not enough good code to train a model on it. MIT Scheme, Haskell, Ocaml, Scala and Go compilers and standard libraries, and this is basically it. Everything else is an outrageously low-effort amateur crap &ndash; piles upon piles of it, without any attempts to do thinfs &ldquo;just right&rdquo; (as in the classic languages).</p>
<p>There is a fundamental principle behind the fact that a machine translation without understanding work reasonably well &ndash; there is the same underlying reality behind every human language, more-or-less the same environmental and social constraints (with all the differences between tribes near the north pole and uncontacted tribes of Amazon forrests).</p>
<p>There is a simple (and the only correct) translation algorithm, then &ndash; reduce the verbalization (encoding) to the environmental aspect it refers to, and then select the verbalization for this notion in a target language. That will be just one-to-one correspondence to nouns (things) such as a &ldquo;cat&rdquo; (assuming they have cats in Alaska), and most of nature-related verbs (actions) and adjectinves (colors, etc).</p>
<p>This is a gross over-simplification, but the principle is the right one.</p>
<p>Even better realization of this very principle is the tools called <code>pandoc</code>. It converts (translates) between major structured text formats, by parsing into a <em>fundamental commonstrucure &ndash; an AST</em> (such as nested blocks of text) along with attributes (such as <em>italic</em> and so on) and then generates the target format.</p>
<p>It works because there is a commonality among most of the supported formats.</p>
<p>What corresponds to the universal common building blocks of programming languages? Well, this is already well-understood.</p>
<ul>
<li>All you need is <em>lambda</em></li>
<li>Recursion</li>
<li>ADTs and interfaces (type-signatures) in general</li>
<li>Algebraic data types, including GADTS</li>
</ul>
<p>To be precise, the <em>intermediate language</em> of GHC is precisely what is needed (to what everything is reducible to). At a CPU level we have comparisons, loops, moves and procedure calls, but this is too low-level.</p>
<p>Now you probably got the idea. If (notice this if) we wish to train a model, we have to train it on this kind of intermediate language (of GHC), not on all the syntactic zoo plus low-effort crappy libraries by unqualified amateurs. And definitely not jammed into some 7B &ldquo;snapshot&rdquo;.</p>
<p>That would be (and really is) is an extremely detailed &ldquo;molecular level snapshot&rdquo; of the famous central garbage dump in New Delhi, to which paid API requests could be made.</p>
<p>Now pay attention. This is not just a dramatic metaphor, this is the closeset possible analogy which is NOT wrong. All the LLMs are snapshots of a whole garbage dump, not of any knowledge which underlies it. I am the same guy who explained it back when the hype only began, and my reasoning is still valid and only get more evidences.</p>
<p>I do not want to be threated by a doctor who reads LLM bullshit (without understanding), even for a &ldquo;suggestion&rdquo;, and to rely on any code pasted from a model without understanding. Yes, it is, perhaps, the biggest corner-cutting tech in human history, but the consequences would be on the same scale.</p>
<p>Just as math cannot be done by taking a snapshot of a dump, neither programming could. We are almost &ldquo;solved it&rdquo; with all the theory which underlies Haskell, and it tell us, if at all, that imperative programming with mutable state is just wrong. Everything works (including this Chrome browser) by a chance and lots of luck.</p>
<p>So, with all that genuine autistic persistence popularized in the &ldquo;Big Short&rdquo; &ndash; this is just bullshit (and a bubble). Pay attention.</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2025 <a href="https://lngnmn2.github.io/">Notes from the digital underground by Lngnmn</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
