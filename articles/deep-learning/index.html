<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Deep Learning | Notes from the digital underground by Lngnmn</title>
<meta name="keywords" content="machine learning, deep learning, neural network, patrial derivative">
<meta name="description" content="Understanding the underlying universal principles.">
<meta name="author" content="&amp;lt;lngnmn2@yahoo.com&amp;gt;">
<link rel="canonical" href="https://lngnmn2.github.io/articles/deep-learning/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.b609c58d5c11bb90b1a54e04005d74ad1ddf22165eb79f5533967e57df9c3b50.css" integrity="sha256-tgnFjVwRu5CxpU4EAF10rR3fIhZet59VM5Z&#43;V9&#43;cO1A=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://lngnmn2.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://lngnmn2.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://lngnmn2.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://lngnmn2.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://lngnmn2.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Source+Code+Pro:wght@300&display=swap" rel="stylesheet">
<link href="https://fonts.googleapis.com/css2?family=Noto+Sans:wght@300&display=swap" rel="stylesheet">
<link href="https://fonts.googleapis.com/css2?family=Noto+Serif:wght@300&display=swap" rel="stylesheet">
<style>
font-family: 'Noto Serif', serif;
font-family: 'Noto Sans', sans-serif;
font-family: 'Source Code Pro', monospace;
</style>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script type="text/javascript" id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script><meta property="og:title" content="Deep Learning" />
<meta property="og:description" content="Understanding the underlying universal principles." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://lngnmn2.github.io/articles/deep-learning/" /><meta property="article:section" content="articles" />
<meta property="article:published_time" content="2023-08-12T00:00:00+05:45" />
<meta property="article:modified_time" content="2023-08-20T20:33:20+05:45" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Deep Learning"/>
<meta name="twitter:description" content="Understanding the underlying universal principles."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Articles",
      "item": "https://lngnmn2.github.io/articles/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Deep Learning",
      "item": "https://lngnmn2.github.io/articles/deep-learning/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Deep Learning",
  "name": "Deep Learning",
  "description": "Understanding the underlying universal principles.",
  "keywords": [
    "machine learning", "deep learning", "neural network", "patrial derivative"
  ],
  "articleBody": "Overview A valid (less wrong) intuitive metaphor is that we “learn” a “surface” which will match (will cover, up to the last wrinkle) the whole actual Himalaya.\nThis notion “generalizes to any number of dimensions” meme (differences, distances and derivatives do not care about Mind’s abstract bullshit)\nThe Himalayas (Truth) has to be “out there”.\nA good generalization is a bucket-sort, which can be thought off as a specific example of a classification problem. Bucket sort, however, is clearly captures the essence.A functions thus outputs correct labels for a given input. The handwritten digit recognition task is a canonical example.\nPattern-recognition is another valid generalization, in which the inputs are matched against a “learned” common pattern. Image classification tasks are in this category.\nThe most successful and straightforward applications of Deep Learning are, indeed, some classification problems in a supervised learning setting.\nThe underlying fundamental principle, however, is that the “patterns” has to be real and stable. Digits is a stable small set, and every human has a face with distinct common patterns (eyes-nose-ears-mouth) which even birds (crows) are able to easily “track”.\nAnother (wrong) formulation is a “search for the “best” function (a mapping) in a Set of all possible functions”.\nThe first thing to realize is that such a function usually has tens or even hundreds “arguments” (inputs). The abstract technique of “currying” is especially handy there.\nThink of a very large table (“features” as columns, actual examples as rows), and we have to “learn” all the complex relations which makes this table valid, assuming it is valid beforehand.\nIt is necessary to re-iterate again and again - TRUTH MUST BE OUT THERE.\nThere is an implication:\nWhen underlying relations among inputs change after training is completed, the model will “infere” or “predict” bullshit. Immutability of relationships among inputs is required.\nThis principle is, of course, related to the principle of immutability (and persistence) of the data bindings in functional programming, and in math, which is necessary for a computation to always be correct.\nThis, in turn, implies that application of machine learning algorithms and deep learning in particular to a partially-observable, stochastic environment will always yield bullshit - “approximations” which are guaranteed to be wrong at some point (when change in the underlying environment will be significant).\nIgnorance of this principle is what ruined all the algorithmic traders and some day will ruin them all.\nThe fundamental problem In logic a “process” that infers a general rule from a set of specific examples is known as inductive reasoning.\nThe concept of inductive reasoning is seemingly related to machine learning because a machine learning algorithm induces (or extracts) a general rule (a function) from a set of specific examples (the dataset).\nThis is fundamentally wrong in principle. A merely collecting observations and even forming some “inner representation” based on them is not enough to establish any actual causality which is the only base of a valid reasoning.\nEven seemingly abstract mathematical and algebraic rules can easily be traced back to the underlying reality, from which they have been captured and properly generalized.\nAddition, the notion of a Semigroup and of a Monoid are generalized from reality, so is the notion of a Set which is a valid generalization of how the mind of an external observer categorizes its “sensory inputs”, and thus of “how things really are” in the Universe.\nThe Upanishadic seers knew how to trace everything in the mind back to “reality” and why this is absolutely necessary to distinguish what is “real”. This, by the way, is the only way.\n“Generalizing” The main theme in the applications of Machine Learning and Deep Learning is to “generalize to new data” (which was not in the training set).\nOf course, we want to “recognize” all human faces, after “seeing” just a few. This is the whole point - we want to be able to correctly deal with the inputs we have never seen before.\nNature and Evolution came up with the “training from experience” of an “evolved pre-defined neural structures” within the brain. (The neural tissues of specialized brain centers are not arbitrary – they have evolved to “match” particular kinds of “inputs”).\nIn short, everything is shaped by the constraints of the environment in which is has been evolved (by the decentralized macro process of trial and error).\nFeedback loops The universal “generalized pattern” (from biological systems) for staying up-to-date by actually learning from each new experience (“example”) is to have a feedback loop when a “sucessuful experience” is being used as a valid source for learning - it becomes an another “example”.\nLots of complex neural structures and even a simplest muscle tissue are getting physically altered (updated) with complex feedback mechanisms.\n“Neuro Myelination” is such actual biological mechanism which is the basis of all learning from experiences within the brain.\nA feedback loop is a properly generalized universal pattern and it is in algorithms (the “accumulator pattern” of recursion) - each loop carries some state within it, and is the basic building block of digital circuits.\nThe Universal principles There are some universal principles behind Deep Learning.\na breadth-first search process which terminates on a good-enough approximation the same universal notion which has been captured by the Newton’s method biology “uses” something very similar with its “biochemical” feed-back loops General principles\nbased on implicit feed-back loops from the environment implicit pruning, just like brain (zero weights) conceptually, a “curve/surface” fitting least square errors (reducing a “distance”) convergence due to an “error minimization” Just like pure math and FP\neach “neuron” is a simple mathematical function (expression) the whole “network” is a function composition (deep nesting) pure math and FP under the hood - well-defined semantics properly abstracted, this is “just a bunch of arrows” (like FP) Supervised\nLearning a representation by trial-and-error (literally) Supervised learning from given “the right answers” Having an implicit feed-back loop (“the right answers”) No explicit programming (back propagation) Representation can be examined and used (updated) Optimizations of the structure of a network (“topology”) Reinforcement\nReinforcement is learning by doing (games, sports) Representation gets refined with each “experience” Implicit feedback loop by evaluating performace Recurrent for linear structure’s (induction) Related to the Bayesian “beliefs”. Representations\nWe “learn” updated terms of pure mathematical expressions Mathematical expressions are represented as an AST an AST can be manipulated (a well-understood problem) Symbolic differentiation since early LISPs Computing derivatives packaged as libraries (autograds) Mutable structures (no persistence). Architecture\nThe “architecture” is “fully connected layers” Theoretically it is the right thing to do. Some weights will become zeroes (“pruning”) Pruning is a fundamental notion (child’s brains do it) Deep learning enables data-driven decisions by identifying and extracting patterns from large datasets that accurately map from sets of complex inputs to good decision outcomes.\nThis implies that the actual, non-imaginary signal (the set of complex inputs) must be “out there”.\nA data-set is a table (or a set of relations), each row is a single “example”, each column is a distinct “feature” or a relation (like a ratio) between features.\nThe principle is that the data (in a table) must be consistent.\nAn algorithm defines a process (as a declarative description or a “template”).\nA function is a deterministic mapping (can be thought off as a “table”) which corresponds to some relation between the values in its domain and its range.\n\\[\\x \\mapsto 2x + 1\\]\nIs a mapping (\\[\\forall x\\]) and a particular relation (multiply by 2 and then add 1).\nMost of the time we want to approximate (to learn a representation of) functions of multiple (many) variables – big tables with many related features.\nThis is the whole point - what is difficult to be explicitly programmed can be approximated (“learned” as a “structure”) by a generalized set of algorithms.\nThe goal is a particular set of “parameters” and “weights” in a “learned” representation of a “network” of a particular shape (“architecture”).\nThe shape of a network has the same number of inputs and an output as the function (set of mappings or “arrows”) we want to approximate (learn a representation of).\nIt is worth noting this abstract correspondence - a “set of arrows” being approximated by a “network of arrows” (a directed graph).\nAs the inputs “flow through the network” and the outputs come out of the “black box” – always the same for the same inputs – this arrangement, just like a function, can be thought off as a “mechanical machine”.\nThe fundamental difference is that we do not define the “function’s body” expression ahead of the time, but gradually improve (“learn”) its representation inside a “black box” by feeding the data and the “right answers” to a learning algorightm.\nThere are lots of analogies of this kind of a process, ranging from a bunch of people doing something by trial-and-error (trying to come up with a robust and efficient aircraft engine) to a whole process of evolution, which, in a sense, “learns” stable molecular arrangements (of enzymes, say, and everything else).\nThis is the right understanding. Notice that the “inputs” (the molecules and ions) has to be “stable”, as the physical (electo-chemical) properties of their combinations (“relations among them”).\nThis is the universal principle – the “building blocks” has to be stable and actually “out there” (non-imaginable).\nThe “mechanics” Each “neuron” is a function (a mapping from a set of inputs to an output) – a mathematical expression. It is represented inside a computer as an abstract syntax tree.\nAn expression is a syntactic closure, which captures all its bound variables and constants (if any) as the “leafs” of an AST.\nThe process of back-propagation (defined by a particular algorithm) traverses the whole network and modifies (updates) the values of these bound variables by computing the partial derivatives for each variable recursively.\nAll the “operators” has to be differentiable (do a partial derivative can be taken).\nSo it is a learning algorithm that updates the “terms” of a vastly complex, deeply nested pure mathematical expression.\nAnd, viewed as a graph, it is a “bunch of arrows between simple functions (“neurons”) which are lexical closures that capture its bound variables”. There is no “free variables” in this context.\nSo what we actually “learn” is this set of “weights” inside these “closures”, which represent the terms of pure mathematical expressions – mappings from inputs to an output.\nDifferentiable Now what is differentiable? Two or more “arrows come together” (this is a universal shape or a “pattern” of multiple causality, of a weighted sum, etc, etc.), and a “contribution” (a “weight” or a “steepness of a slope”) of each “arrow” can be determined.\nProgramming The ability to zoom through the layers (of a hierarchy) of abstractions (from general to specific and bottom-up) and to switch between an abstraction and its representation is what makes a good programmer. It is not “knowing” some PHP or Javascript.\n",
  "wordCount" : "1812",
  "inLanguage": "en",
  "datePublished": "2023-08-12T00:00:00+05:45",
  "dateModified": "2023-08-20T20:33:20+05:45",
  "author":[{
    "@type": "Person",
    "name": "\u0026lt;lngnmn2@yahoo.com\u0026gt;"
  }],
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://lngnmn2.github.io/articles/deep-learning/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Notes from the digital underground by Lngnmn",
    "logo": {
      "@type": "ImageObject",
      "url": "https://lngnmn2.github.io/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://lngnmn2.github.io/" accesskey="h" title="Notes from the digital underground by Lngnmn (Alt + H)">Notes from the digital underground by Lngnmn</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://lngnmn2.github.io/about/" title="About me.">
                    <span>About me.</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      Deep Learning
    </h1>
    <div class="post-description">
      Understanding the underlying universal principles.
    </div>
    <div class="post-meta"><span title='2023-08-12 00:00:00 +0545 +0545'>August 12, 2023</span>&nbsp;·&nbsp;&amp;lt;lngnmn2@yahoo.com&amp;gt;

</div>
  </header> 
  <div class="post-content"><h2 id="overview">Overview<a hidden class="anchor" aria-hidden="true" href="#overview">#</a></h2>
<p>A valid (less wrong) <em>intuitive</em> metaphor is that we &ldquo;learn&rdquo; a &ldquo;surface&rdquo; which will match (will cover, up to the last wrinkle) the whole actual Himalaya.</p>
<p>This notion &ldquo;generalizes to any number of dimensions&rdquo; meme (differences, distances and derivatives do not care about Mind&rsquo;s abstract bullshit)</p>
<p>The Himalayas (Truth) has to be &ldquo;out there&rdquo;.</p>
<p>A good generalization is a <em>bucket-sort</em>, which can be thought off as a specific example of a <em>classification problem</em>. Bucket sort, however, is clearly captures the essence.A functions thus outputs correct <em>labels</em> for a given input. The handwritten digit recognition task is a canonical example.</p>
<p><em>Pattern-recognition</em> is another valid generalization, in which the inputs are <em>matched against a &ldquo;learned&rdquo; common pattern</em>. Image classification tasks are in this category.</p>
<p>The most successful and straightforward applications of Deep Learning are,  indeed, some classification problems in a <em>supervised learning</em> setting.</p>
<p>The underlying fundamental principle, however, is that the &ldquo;patterns&rdquo; has to be real and stable. Digits is a stable small set, and every human has a face with distinct common patterns (eyes-nose-ears-mouth) which even birds (crows) are able to easily &ldquo;track&rdquo;.</p>
<p>Another (wrong) formulation is a &ldquo;search for the &ldquo;best&rdquo; function (a mapping) in a Set of all possible functions&rdquo;.</p>
<p>The first thing to realize is that such a function usually has tens or even hundreds &ldquo;arguments&rdquo; (inputs). The abstract technique of &ldquo;currying&rdquo; is especially handy there.</p>
<p>Think of a very large <em>table</em> (&ldquo;features&rdquo; as columns, actual examples as rows), and we have to &ldquo;learn&rdquo; all the <em>complex relations</em> which makes this table <em>valid</em>, assuming it <em>is valid</em> beforehand.</p>
<p>It is necessary to re-iterate again and again - <em>TRUTH MUST BE OUT THERE</em>.</p>
<p>There is an  implication:</p>
<p>When underlying relations among inputs <em>change</em> after training is completed, the model will &ldquo;infere&rdquo; or &ldquo;predict&rdquo; bullshit. Immutability of relationships among inputs is <em>required</em>.</p>
<p>This principle is, of course, related to the principle of immutability (and persistence) of the data bindings in functional programming, and in math, which is <em>necessary</em> for a computation to always be correct.</p>
<p>This, in turn, implies that application of machine learning algorithms and deep learning in particular to a <em>partially-observable, stochastic environment</em> will always yield bullshit - &ldquo;approximations&rdquo; which are <em>guaranteed to be wrong at some point</em> (when change in the  underlying environment will be significant).</p>
<p>Ignorance of this principle is what ruined all the algorithmic traders and some day will ruin them all.</p>
<h2 id="the-fundamental-problem">The fundamental problem<a hidden class="anchor" aria-hidden="true" href="#the-fundamental-problem">#</a></h2>
<p>In logic a &ldquo;process&rdquo; that <em>infers a general rule from a set of specific examples</em> is known as
inductive reasoning.</p>
<p>The concept of <em>inductive reasoning</em> is seemingly related to machine learning because a machine learning algorithm induces (or extracts) a general rule (a function) from a set of specific examples (the dataset).</p>
<p>This is fundamentally wrong in principle. A merely collecting observations and even forming some &ldquo;inner representation&rdquo; based on them is not enough to establish any actual causality which is the only base of a valid reasoning.</p>
<p>Even seemingly <em>abstract</em> mathematical and algebraic rules can easily be traced back to the underlying reality, from which they have been <em>captured and properly generalized</em>.</p>
<p>Addition, the notion of a <em>Semigroup</em> and of a <em>Monoid</em> are generalized from reality, so is the notion of a <em>Set</em> which is a valid generalization of how the <em>mind of an external observer</em> categorizes its &ldquo;sensory inputs&rdquo;, and thus of &ldquo;how things really are&rdquo; in the Universe.</p>
<p>The <em>Upanishadic seers</em> knew how to trace everything in the mind back to &ldquo;reality&rdquo; and why this is absolutely necessary to distinguish what is &ldquo;real&rdquo;. This, by the way, is the only way.</p>
<h2 id="generalizing">&ldquo;Generalizing&rdquo;<a hidden class="anchor" aria-hidden="true" href="#generalizing">#</a></h2>
<p>The main theme in the applications of Machine Learning and Deep Learning is to &ldquo;generalize to new data&rdquo; (which was not in the training set).</p>
<p>Of course, we want to &ldquo;recognize&rdquo; all human faces, after &ldquo;seeing&rdquo; just a few. This is the whole point - we want to be able to correctly deal with the inputs we have never seen before.</p>
<p>Nature and Evolution came up with the &ldquo;training from experience&rdquo; of an &ldquo;evolved pre-defined neural structures&rdquo; within the brain. (The neural tissues of specialized brain centers are not arbitrary &ndash; they have evolved to &ldquo;match&rdquo; particular kinds of &ldquo;inputs&rdquo;).</p>
<p>In short, everything is shaped by the constraints of the environment in which is has been evolved (by the decentralized macro process of <em>trial and error</em>).</p>
<h2 id="feedback-loops">Feedback loops<a hidden class="anchor" aria-hidden="true" href="#feedback-loops">#</a></h2>
<p>The universal &ldquo;generalized pattern&rdquo; (from biological systems) for <em>staying up-to-date</em> by actually <em>learning from each new experience</em> (&ldquo;example&rdquo;) is to have a <em>feedback loop</em> when a &ldquo;sucessuful experience&rdquo; is being used as a valid source for learning - it becomes an another &ldquo;example&rdquo;.</p>
<p>Lots of complex neural structures and even a simplest muscle tissue are getting physically altered (updated) with complex feedback mechanisms.</p>
<p><em>&ldquo;Neuro Myelination&rdquo;</em> is such actual biological mechanism which is <em>the basis</em> of all <em>learning from experiences</em> within the brain.</p>
<p>A feedback loop is a <em>properly generalized universal pattern</em> and it is in algorithms (the &ldquo;accumulator pattern&rdquo; of recursion) - each loop carries some state within it, and is the basic building block of digital circuits.</p>
<h2 id="the-universal-principles">The Universal principles<a hidden class="anchor" aria-hidden="true" href="#the-universal-principles">#</a></h2>
<p>There are some <em>universal principles</em> behind Deep Learning.</p>
<ul>
<li>a <em>breadth-first search process</em> which terminates on a <em>good-enough approximation</em></li>
<li>the same universal notion which has been <em>captured</em> by the Newton&rsquo;s method</li>
<li>biology &ldquo;uses&rdquo; something very similar with its &ldquo;biochemical&rdquo; feed-back loops</li>
</ul>
<p>General principles</p>
<ul>
<li>based on implicit feed-back loops from the environment</li>
<li>implicit pruning, just like brain (zero weights)</li>
<li>conceptually, a &ldquo;curve/surface&rdquo; fitting</li>
<li>least square errors (reducing a &ldquo;distance&rdquo;)</li>
<li>convergence due to an &ldquo;error minimization&rdquo;</li>
</ul>
<p>Just like pure math and FP</p>
<ul>
<li>each &ldquo;neuron&rdquo; is a simple mathematical function (expression)</li>
<li>the whole &ldquo;network&rdquo; is a <em>function composition</em> (deep nesting)</li>
<li>pure math and FP under the hood - well-defined semantics</li>
<li>properly abstracted, this is &ldquo;just a bunch of arrows&rdquo; (like FP)</li>
</ul>
<p>Supervised</p>
<ul>
<li>Learning a representation by trial-and-error (literally)</li>
<li>Supervised learning from given &ldquo;the right answers&rdquo;</li>
<li>Having an implicit <em>feed-back loop</em> (&ldquo;the right answers&rdquo;)</li>
<li>No explicit programming (<em>back propagation</em>)</li>
<li><em>Representation</em> can be examined and used (updated)</li>
<li>Optimizations of the structure of a network (&ldquo;topology&rdquo;)</li>
</ul>
<p>Reinforcement</p>
<ul>
<li>Reinforcement is <em>learning by doing</em> (games, sports)</li>
<li>Representation gets <em>refined</em> with each &ldquo;experience&rdquo;</li>
<li>Implicit feedback loop by <em>evaluating performace</em></li>
<li>Recurrent for linear structure&rsquo;s (induction)</li>
<li>Related to the Bayesian &ldquo;beliefs&rdquo;.</li>
</ul>
<p>Representations</p>
<ul>
<li>We &ldquo;learn&rdquo; updated terms of <em>pure</em> mathematical expressions</li>
<li>Mathematical expressions are represented as an AST</li>
<li>an AST can be manipulated (a well-understood problem)</li>
<li><em>Symbolic differentiation</em> since early LISPs</li>
<li>Computing derivatives packaged as libraries (<em>autograds</em>)</li>
<li>Mutable structures (no persistence).</li>
</ul>
<p>Architecture</p>
<ul>
<li>The &ldquo;architecture&rdquo; is &ldquo;fully connected layers&rdquo;</li>
<li>Theoretically it is the right thing to do.</li>
<li>Some weights will become zeroes (&ldquo;pruning&rdquo;)</li>
<li>Pruning is a fundamental notion (child&rsquo;s brains do it)</li>
</ul>
<p>Deep learning enables <em>data-driven</em> decisions by <em>identifying and extracting patterns</em> from large datasets that <em>accurately map</em> from sets of complex inputs to good decision outcomes.</p>
<p>This implies that the actual, non-imaginary signal (the set of complex inputs) must be &ldquo;out there&rdquo;.</p>
<p>A data-set is a <em>table</em> (or a set of relations), each row is a single &ldquo;example&rdquo;, each column is a distinct &ldquo;feature&rdquo; or a relation (like a ratio) between features.</p>
<p>The principle is that the data (in a table) must be <em>consistent</em>.</p>
<p>An algorithm defines a process (as a declarative description or a <em>&ldquo;template&rdquo;</em>).</p>
<p>A function is a <em>deterministic mapping</em> (can be thought off as a <em>&ldquo;table&rdquo;</em>) which corresponds to some <em>relation</em> between the values in its <em>domain</em> and its <em>range</em>.</p>
<p>\[\x \mapsto 2x + 1\]</p>
<p>Is a <em>mapping</em> (\[\forall x\]) and a particular <em>relation</em> (multiply by 2 and then add 1).</p>
<p>Most of the time we want to approximate (to learn a representation of) functions of multiple (many) variables &ndash; big tables with <em>many related features</em>.</p>
<p>This is the whole point - what is difficult to be explicitly programmed can be approximated (&ldquo;learned&rdquo; as a &ldquo;structure&rdquo;) by a generalized set of algorithms.</p>
<p>The goal is a particular set of &ldquo;parameters&rdquo; and &ldquo;weights&rdquo; in a &ldquo;learned&rdquo; <em>representation</em> of a &ldquo;network&rdquo; of a particular <em>shape</em> (&ldquo;architecture&rdquo;).</p>
<p>The <em>shape</em> of a network has the same number of inputs and an output as the <em>function</em> (set of mappings or &ldquo;arrows&rdquo;) we want to approximate (learn a representation of).</p>
<p>It is worth noting this abstract correspondence - a &ldquo;set of arrows&rdquo; being approximated by a &ldquo;network of arrows&rdquo; (a directed graph).</p>
<p>As the inputs &ldquo;flow through the network&rdquo; and the outputs come out of the &ldquo;black box&rdquo; &ndash;  always the same for the same inputs &ndash; this <em>arrangement</em>, just like a function, can be thought off as a &ldquo;mechanical machine&rdquo;.</p>
<p>The fundamental difference is that we do not define the &ldquo;function&rsquo;s body&rdquo; expression ahead of the time, but gradually improve (&ldquo;learn&rdquo;) its <em>representation</em> inside a &ldquo;black box&rdquo; by feeding the data and the &ldquo;right answers&rdquo; to a <em>learning algorightm</em>.</p>
<p>There are lots of analogies of this kind of a process, ranging from a bunch of people doing something by trial-and-error (trying to come up with a robust and efficient aircraft engine) to a whole process of evolution, which, in a sense, &ldquo;learns&rdquo; stable molecular arrangements (of enzymes, say, and everything else).</p>
<p>This is the right understanding. Notice that the &ldquo;inputs&rdquo; (the molecules and ions) has to be &ldquo;stable&rdquo;, as the physical (electo-chemical) properties of their combinations (&ldquo;relations among them&rdquo;).</p>
<p>This is the universal principle &ndash; the &ldquo;building blocks&rdquo; has to be stable and actually &ldquo;out there&rdquo; (non-imaginable).</p>
<h2 id="the-mechanics">The &ldquo;mechanics&rdquo;<a hidden class="anchor" aria-hidden="true" href="#the-mechanics">#</a></h2>
<p>Each &ldquo;neuron&rdquo; is a function (a mapping from a set of inputs to an output) &ndash; a <em>mathematical expression</em>. It is represented inside a computer as an <em>abstract syntax tree</em>.</p>
<p>An expression is a <em>syntactic closure</em>, which captures all its <em>bound variables</em> and constants (if any) as the &ldquo;leafs&rdquo; of an AST.</p>
<p>The process of back-propagation (defined by a particular algorithm) traverses the whole network and modifies (updates) the values of these bound variables by computing the partial derivatives for each variable <em>recursively</em>.</p>
<p>All the &ldquo;operators&rdquo; has to be <em>differentiable</em> (do a partial derivative can be taken).</p>
<p>So it is a <em>learning algorithm</em> that updates the &ldquo;terms&rdquo; of a vastly complex, deeply nested pure mathematical expression.</p>
<p>And, viewed as a graph, it is a &ldquo;bunch of arrows between simple functions (&ldquo;neurons&rdquo;) which are <em>lexical closures</em> that capture its bound variables&rdquo;. There is no &ldquo;free variables&rdquo; in this context.</p>
<p>So what we actually &ldquo;learn&rdquo; is this set of &ldquo;weights&rdquo; inside these &ldquo;closures&rdquo;, which <em>represent the terms of pure mathematical expressions &ndash; mappings from inputs to an output</em>.</p>
<h2 id="differentiable">Differentiable<a hidden class="anchor" aria-hidden="true" href="#differentiable">#</a></h2>
<p>Now what is <em>differentiable</em>? Two or more &ldquo;arrows come together&rdquo; (this is a universal  <em>shape</em> or a &ldquo;pattern&rdquo; of multiple causality, of a weighted sum, etc, etc.), and a &ldquo;contribution&rdquo; (a &ldquo;weight&rdquo; or a &ldquo;steepness of a slope&rdquo;) of each &ldquo;arrow&rdquo; can be determined.</p>
<h2 id="programming">Programming<a hidden class="anchor" aria-hidden="true" href="#programming">#</a></h2>
<p>The ability to zoom through the layers (of a hierarchy) of abstractions (from general to specific and bottom-up) and to switch between an abstraction and its representation is what makes a good programmer. It is not &ldquo;knowing&rdquo; some PHP or Javascript.</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://lngnmn2.github.io/tags/machine-learning/">machine learning</a></li>
      <li><a href="https://lngnmn2.github.io/tags/deep-learning/">deep learning</a></li>
      <li><a href="https://lngnmn2.github.io/tags/neural-network/">neural network</a></li>
      <li><a href="https://lngnmn2.github.io/tags/patrial-derivative/">patrial derivative</a></li>
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2024 <a href="https://lngnmn2.github.io/">Notes from the digital underground by Lngnmn</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
