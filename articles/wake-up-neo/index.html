<!DOCTYPE html>
<html lang="en" dir="auto" data-theme="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Wake up, Neo | Notes from the digital underground by Lngnmn</title>
<meta name="keywords" content="AI, LLM, bullshit">
<meta name="description" content="So, this is the why all the megacorps suddenly building AI data-centers and purchase nuclear power plants to feed them with electricity and book all the DRAM and VRAM production and in the whole world.
The reason is this. Remember Google reCAPTCHA - that window when you are forced to select all the cars or traffic lights to view the website you wanted (for an expected revard through a dopamine release).">
<meta name="author" content="lngnmn2@yahoo.com">
<link rel="canonical" href="https://lngnmn2.github.io/articles/wake-up-neo/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.a5781257de4197b8e3d54346acdf1dd55a9ba4cb91dcace192fc1baf228c08b5.css" integrity="sha256-pXgSV95Bl7jj1UNGrN8d1VqbpMuR3KzhkvwbryKMCLU=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://lngnmn2.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://lngnmn2.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://lngnmn2.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://lngnmn2.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://lngnmn2.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://lngnmn2.github.io/articles/wake-up-neo/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
                color-scheme: dark;
            }

            .list {
                background: var(--theme);
            }

            .toc {
                background: var(--entry);
            }
        }

        @media (prefers-color-scheme: light) {
            .list::-webkit-scrollbar-thumb {
                border-color: var(--code-bg);
            }
        }

    </style>
</noscript>
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.querySelector("html").dataset.theme = 'dark';
    } else if (localStorage.getItem("pref-theme") === "light") {
       document.querySelector("html").dataset.theme = 'light';
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.querySelector("html").dataset.theme = 'dark';
    } else {
        document.querySelector("html").dataset.theme = 'light';
    }

</script><link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Source+Code+Pro:wght@300&display=swap" rel="stylesheet">
<link href="https://fonts.googleapis.com/css2?family=Noto+Sans:wght@300&display=swap" rel="stylesheet">
<link href="https://fonts.googleapis.com/css2?family=Noto+Serif:wght@300&display=swap" rel="stylesheet">
<style>
font-family: 'Noto Serif', serif;
font-family: 'Noto Sans', sans-serif;
font-family: 'Source Code Pro', monospace;
</style>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script type="text/javascript" id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script><meta property="og:url" content="https://lngnmn2.github.io/articles/wake-up-neo/">
  <meta property="og:site_name" content="Notes from the digital underground by Lngnmn">
  <meta property="og:title" content="Wake up, Neo">
  <meta property="og:description" content="So, this is the why all the megacorps suddenly building AI data-centers and purchase nuclear power plants to feed them with electricity and book all the DRAM and VRAM production and in the whole world.
The reason is this. Remember Google reCAPTCHA - that window when you are forced to select all the cars or traffic lights to view the website you wanted (for an expected revard through a dopamine release).">
  <meta property="og:locale" content="en-us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="articles">
    <meta property="article:published_time" content="2026-01-13T00:00:00+05:45">
    <meta property="article:modified_time" content="2026-01-13T15:09:49+05:45">
    <meta property="article:tag" content="AI">
    <meta property="article:tag" content="LLM">
    <meta property="article:tag" content="Bullshit">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Wake up, Neo">
<meta name="twitter:description" content="So, this is the why all the megacorps suddenly building AI data-centers and purchase nuclear power plants to feed them with electricity and book all the DRAM and VRAM production and in the whole world.
The reason is this. Remember Google reCAPTCHA - that window when you are forced to select all the cars or traffic lights to view the website you wanted (for an expected revard through a dopamine release).">


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Articles",
      "item": "https://lngnmn2.github.io/articles/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Wake up, Neo",
      "item": "https://lngnmn2.github.io/articles/wake-up-neo/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Wake up, Neo",
  "name": "Wake up, Neo",
  "description": "So, this is the why all the megacorps suddenly building AI data-centers and purchase nuclear power plants to feed them with electricity and book all the DRAM and VRAM production and in the whole world.\nThe reason is this. Remember Google reCAPTCHA - that window when you are forced to select all the cars or traffic lights to view the website you wanted (for an expected revard through a dopamine release).\n",
  "keywords": [
    "AI", "LLM", "bullshit"
  ],
  "articleBody": "So, this is the why all the megacorps suddenly building AI data-centers and purchase nuclear power plants to feed them with electricity and book all the DRAM and VRAM production and in the whole world.\nThe reason is this. Remember Google reCAPTCHA - that window when you are forced to select all the cars or traffic lights to view the website you wanted (for an expected revard through a dopamine release).\nWhat you actually doing is cleaning up Google’s wast data-set of images for free, verifying the previous labeling.\nHere is how it works – there are some vague, error prone automatic labeling, based on patten-recognition (so called Computer Vision), which produced some labels for a dataset, which have some greater than 0,5 probability to be correct. Just this, no semantic knowledge whatsoever. Then they load it into reCAPTCHA, and you, by clicking on thumbals, systematically and consistently increase the probability of correct labeling (they could run the same image set through hundreds of iterations) for free.\nAt so-called “internet scale” this is not just individual monkeys with typewriters, trying to come up with the complete works of Shakespeare, but millions of monkeys, each one pick up a typewriter where the previous one left t, and there are millions of such typewriters, working in parallel, to increase the theoretical proability of hypothetical convergence to “To Be, Or Not To Be”.\nNow exactly the same processes, but on a much larger scale, are being run by AI divisions of major tech corporations . There are millions of monkeys (Yous) are continuously, in massive parallel architecture, are refining slop-generator inner representations, so it, hopefully, will eventually converge on something meaningful (instad of producing millions of local-optima dead-ends).\nThey stated with an utter crap taken from Github and somehow turned into a “coding model” (which produce an utter trash, lost context between iterations and hallucinates and makes up shit all the time). Neverheless, to (You) it appears as a meaningful activity, and that you are making a progress or even learn something, improving, and above all, have the same neuromodulator spikes running, as with a real activity. but much intense, since it is all compressed in a tight feedback loop.\nThe outcome of all this is that each your textual feedback notches the knobs little bit in the “right direction” - the prompt, the prompt you gave, the resulting slop and your reaction and cognitive feedback to it is being feed back as the training data, so the utter crap undergoes a slow gradual process of continuous refining (of the was inner Artificial Neural Nets representations). The scale is enormous – of every single possible token as an “entry point”.\nTheoretically, every single “session” with the slop generator improves its representation on the topic (subject) of conversation, without any semantic understanding – just slightly increasing the probabilities of being “right” (above 0,5), and then it back-propagates, without understanding, of course.\nThis is why they are all in. Their bets is that it will eventually converge onto something “more than the sum of its parts” (nope), and if not, they will steal half of the money by the time it bursts. Strictly MBA thinking.\nOne more time – there is no understanding or meaning involved whatsoever – the process is to find better numbers than they are right now, assuming that these numbers represents the actual probabilities of “more correct answers”. No one knows how, they just observe (and even “measure” by the rate of “successes” to “failures”) that the slop appears to be more consistent and coherent than before. That is it.\nThe real optimization begins when (You) are going to interact with the slop generator and give it your cognitive feedback, whatever it may be (no one notices or cares, it will eventually move to the right direction, just as an implication of the law of big numbers – it will converge not on an overage, but on more than 0,5 by design).\nSee, it is not even them, but the millions of monkeys who actually improve their AI representations by just “pushing it in the right direction all together”.\nIt worth repeating again – the slop it produces do not even compile, leave alone come up as correct or even consistent. This is not the goal. The goal is to make (You) to correct it somehow (not important) and to feed it back as the new training data in an automated process. The slop then automatically becomes more and more usable, with [probabilistically] a bit less errors than before, without any understanding of any kind whatsoever.\nThe whole shitshow runs on your very own dopamine and serotonin spikes and crashes, though (You) are not a battery, (You) are a monkey with a typewriter, because the appearance (Maya) is very persuasive, it appears to be “intelligent”, and even more intelligent than (You), until you “wake up” and try to actually examine and validate the slop, which turns out of being a fucking trash that doesn’t even compile, and breaks with each new “iteration” by losing the coherence from the previous contexts.\nThis is your AI, in principle.\n",
  "wordCount" : "855",
  "inLanguage": "en",
  "datePublished": "2026-01-13T00:00:00+05:45",
  "dateModified": "2026-01-13T15:09:49+05:45",
  "author":[{
    "@type": "Person",
    "name": "lngnmn2@yahoo.com"
  }],
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://lngnmn2.github.io/articles/wake-up-neo/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Notes from the digital underground by Lngnmn",
    "logo": {
      "@type": "ImageObject",
      "url": "https://lngnmn2.github.io/favicon.ico"
    }
  }
}
</script>
</head>
<body id="top">
    <header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://lngnmn2.github.io/" accesskey="h" title="Notes from the digital underground by Lngnmn (Alt + H)">Notes from the digital underground by Lngnmn</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)" aria-label="Toggle theme">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://lngnmn2.github.io/about/" title="About me.">
                    <span>About me.</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      Wake up, Neo
    </h1>
    <div class="post-meta"><span title='2026-01-13 00:00:00 +0545 +0545'>January 13, 2026</span>&nbsp;·&nbsp;<span>lngnmn2@yahoo.com</span>

</div>
  </header> 
  <div class="post-content"><p>So, this is <em>the why</em> all the megacorps suddenly building AI data-centers and purchase nuclear power plants to feed them with electricity and book all the DRAM and VRAM production and in the whole world.</p>
<p>The reason is this. Remember Google reCAPTCHA - that window when you are forced to select all the cars or traffic lights to view the website you wanted (for an expected revard through a dopamine release).</p>
<p>What you actually doing is cleaning up Google&rsquo;s wast data-set of images for free, verifying the previous labeling.</p>
<p>Here is how it works &ndash; there are some vague, error prone automatic labeling, based on patten-recognition (so called Computer Vision), which produced some labels for a dataset, which have some greater than <code>0,5</code> probability to be correct. Just this, no semantic knowledge whatsoever. Then they load it into reCAPTCHA, and you, by clicking on thumbals, <em>systematically and  consistently increase the probability of correct labeling</em> (they could run the same image set through hundreds of iterations) for free.</p>
<p>At so-called &ldquo;internet scale&rdquo; this is not just individual monkeys with typewriters, trying to come up with the complete works of Shakespeare, but millions of monkeys, each one pick up a typewriter where the previous one left t, and there are millions of such typewriters, working in parallel, to increase the theoretical proability of hypothetical convergence to &ldquo;To Be, Or Not To Be&rdquo;.</p>
<p>Now exactly the same processes, but on a much larger scale, are being run by AI divisions of major tech corporations . There are  millions of monkeys (Yous) are continuously, in massive parallel architecture, are refining slop-generator inner representations, so it, hopefully, will eventually converge on something meaningful (instad of producing millions of  local-optima dead-ends).</p>
<p>They stated with an utter crap taken from Github and somehow turned into a &ldquo;coding model&rdquo; (which produce an utter trash, lost context between iterations and hallucinates and makes up shit all the time). Neverheless, to (You) it appears as a meaningful activity, and that you are making a progress or even learn something, improving, and above all, have the same neuromodulator spikes running, as with a real activity. but much intense, since it is all compressed in a tight feedback loop.</p>
<p>The outcome of all this is that each your textual feedback notches the knobs little bit in the &ldquo;right direction&rdquo; - the prompt, the prompt you gave, the resulting slop and <em>your reaction and cognitive feedback to it</em> is being feed back as the training data, so the utter crap undergoes a slow gradual process of continuous refining (of the was inner Artificial Neural Nets representations). The scale is enormous &ndash; of every single possible token as an &ldquo;entry point&rdquo;.</p>
<p>Theoretically, every single &ldquo;session&rdquo; with the slop generator improves its representation on the topic (subject) of conversation, without any semantic understanding &ndash; just slightly increasing the probabilities of being  &ldquo;right&rdquo; (above 0,5), and then it back-propagates, without understanding, of course.</p>
<p>This is <em>why</em> they are all in. Their bets is that it will eventually converge onto something &ldquo;more than the sum of its parts&rdquo; (nope), and if not, they will steal half of the money by the time it bursts. Strictly MBA thinking.</p>
<p>One more time &ndash; there is no <em>understanding</em> or meaning involved whatsoever &ndash; the process is to find <em>better numbers</em> than they are right now, assuming that these numbers represents the actual probabilities of &ldquo;more correct answers&rdquo;. No one knows how, they just observe (and even &ldquo;measure&rdquo; by the rate of &ldquo;successes&rdquo; to &ldquo;failures&rdquo;) that the slop appears to be more consistent and coherent than before. That is it.</p>
<p>The real optimization begins when (You) are going to interact with the slop generator and give it your cognitive feedback, whatever it may be (no one notices or cares, it will eventually move to the right direction, just as an implication of the law of big numbers &ndash; it will converge not on an overage, but on more than <code>0,5</code> by design).</p>
<p>See, it is not even them, but the millions of monkeys who actually improve their AI representations by just &ldquo;pushing it in the right direction all together&rdquo;.</p>
<p>It worth repeating again &ndash; the slop it produces do not even compile, leave alone come up as correct or even consistent. This is not the goal. The goal is to make (You) to correct it somehow (not important) and to feed it back as the new training data in an automated process. The slop then <em>automatically</em> becomes more and more usable, with [probabilistically] a bit less errors than before, <em>without any understanding of any kind whatsoever</em>.</p>
<p>The whole shitshow runs on your very own dopamine and serotonin spikes and crashes, though (You) are not a battery, (You) are a monkey with a typewriter, because the appearance (Maya) is very persuasive, it appears to be &ldquo;intelligent&rdquo;, and even more intelligent than (You), until you &ldquo;wake up&rdquo; and try to  actually examine and validate the slop, which turns out of being a fucking trash that doesn&rsquo;t even compile, and breaks with each new &ldquo;iteration&rdquo;  by losing the coherence from the  previous contexts.</p>
<p>This is your AI, in principle.</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://lngnmn2.github.io/tags/ai/">AI</a></li>
      <li><a href="https://lngnmn2.github.io/tags/llm/">LLM</a></li>
      <li><a href="https://lngnmn2.github.io/tags/bullshit/">Bullshit</a></li>
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2026 <a href="https://lngnmn2.github.io/">Notes from the digital underground by Lngnmn</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu');
    if (menu) {
        
        const scrollPosition = localStorage.getItem("menu-scroll-position");
        if (scrollPosition) {
            menu.scrollLeft = parseInt(scrollPosition, 10);
        }
        
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        const html = document.querySelector("html");
        if (html.dataset.theme === "dark") {
            html.dataset.theme = 'light';
            localStorage.setItem("pref-theme", 'light');
        } else {
            html.dataset.theme = 'dark';
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
