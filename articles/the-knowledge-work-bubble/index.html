<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>The Knowledge Work Bubble | Notes from the digital underground by Lngnmn</title>
<meta name="keywords" content="AI, LLM">
<meta name="description" content="  The end of the &#34;knowledge work&#34; as we know it.
  ">
<meta name="author" content="&amp;lt;lngnmn2@yahoo.com&amp;gt;">
<link rel="canonical" href="https://lngnmn2.github.io/articles/the-knowledge-work-bubble/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.d0049500090a8b5b522a30f4bc70f815df41595125d25503dff47281216974cb.css" integrity="sha256-0ASVAAkKi1tSKjD0vHD4Fd9BWVEl0lUD3/RygSFpdMs=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://lngnmn2.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://lngnmn2.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://lngnmn2.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://lngnmn2.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://lngnmn2.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://lngnmn2.github.io/articles/the-knowledge-work-bubble/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Source+Code+Pro:wght@300&display=swap" rel="stylesheet">
<link href="https://fonts.googleapis.com/css2?family=Noto+Sans:wght@300&display=swap" rel="stylesheet">
<link href="https://fonts.googleapis.com/css2?family=Noto+Serif:wght@300&display=swap" rel="stylesheet">
<style>
font-family: 'Noto Serif', serif;
font-family: 'Noto Sans', sans-serif;
font-family: 'Source Code Pro', monospace;
</style>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script type="text/javascript" id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script><meta property="og:url" content="https://lngnmn2.github.io/articles/the-knowledge-work-bubble/">
  <meta property="og:site_name" content="Notes from the digital underground by Lngnmn">
  <meta property="og:title" content="The Knowledge Work Bubble">
  <meta property="og:description" content="  The end of the &#34;knowledge work&#34; as we know it.
  ">
  <meta property="og:locale" content="en-us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="articles">
    <meta property="article:published_time" content="2025-08-02T00:00:00+05:45">
    <meta property="article:modified_time" content="2025-08-02T18:46:22+05:45">
    <meta property="article:tag" content="AI">
    <meta property="article:tag" content="LLM">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="The Knowledge Work Bubble">
<meta name="twitter:description" content="  The end of the &#34;knowledge work&#34; as we know it.
  ">


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Articles",
      "item": "https://lngnmn2.github.io/articles/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "The Knowledge Work Bubble",
      "item": "https://lngnmn2.github.io/articles/the-knowledge-work-bubble/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "The Knowledge Work Bubble",
  "name": "The Knowledge Work Bubble",
  "description": "  The end of the \"knowledge work\" as we know it.\n  ",
  "keywords": [
    "AI", "LLM"
  ],
  "articleBody": "We are living through a paradigmatic shift, the one described in the “Scientific Revolution” by Thomas Kuhn. As I mentioned many times, texts and even crappy code became very, very cheap, just like a processed junk-food or a low-effort street-food slop. This is the “shift” and the end of so-called “knowledge work” as we know it. At least this is the end of the pretentious “knowledge work”, when one just pretends to be an expert is social settings, using very straightforward verbal and non-verbal cues to signal their “knowledge” and “expertise”, just as a priest would do in the not so distant past.\nLots of people have already realized that good writing is a hard, labour-intensive work, which is now being replaced by a nearly zero-cost AI-generated slop. Just like a pretentious writing by an imposer, the AI-generated slop is often too abstract and too general, the proverbal “hand-waving” and a “word salad”, which is, again, goes back to doctrinal and dogmatic texts and speeches, which very few people could understand to be an utter made-believe bullshit.\nGood writing is as hard as writing a quality mathematical proofs, meaningful poetry (which actually captures something worthy in a beautiful form) or even a prose – something after reading which other people would overwhelmingly say “wow”. We all knew some good writers from the golden age of the English Fiction, at least some very good parts of some good books.\nWith the source code the criteria are even simpler – it has to be correct, just like any written mathematics. Correctness is exactly where these probability-based LLMs are, in principle (and by definition of the underlying algorithms), inherently bad. And this very correctness is exactly what we expect and want from them, and being correct (without errors) is precisely what a non-bullshit “knowledge work” is all about.\nNowadays, however, what would pass as a “knowledge” is just a exuberant verbiage about the subject in general, almost always with some references to “limitations of rigorous sciences” and difficulties (and the costs) of conducting properly designed, reproducible experiments/, which, just like proper mathematical proofs, are necessary, and never optional.\nAll these modern media formats, especially pop-sci podcasts (which make millions on product placements, narrative building and plain ads) and crappy fast-print tech “books” are just manifestations of the “knowledge work bubble”, which is now bursting, just like the dot-com bubble in the early 2000s. The “knowledge work” is not a “work” at all, it is just a pretentious and often meaningless verbal and non-verbal signalling, which is now being replaced by AI-generated slop.\nThis is the paradigmatic shift, which is now happening, and it is not going to be reversed.\nThe question is, of course ~What To Be Done?- Now What?\nUnlike mathematics with errors, a generated code with errors are “almost right” and “acceptable”, due to its near-zero costs. It has even a reasonable (and the only) use case – to generate a vebose boilerplate code of crappy, badly designed OO APIs, archaic and legacy (like Win32) or just stupid ones (as in webshit frameworks). Auto-completing such vebose crap (as per “glorified autocomplete”), even with occasional minor errors, is the only reasonable use case for these LLMs, which is not a “knowledge”, leave alone “thinking” or “reasoning” at all, but just, again, a glorified autocomplete.\nGenerating a boilerplate code and “skeletons” of modules (or verbose, over-abstracted class hierarchies) is a very real, measurable by all the common metrics, productivity boost – we just have to admit that this (and only this) is what keeps the gigantic unprecedented AI bubble from bursting, at least for now. Using several LLMs “in parallel” to generate slop for the same prompt is even better, because it allows one to see the alternatives without being able to come up with them on their own, which is a very real productivity boost, too.\nGo and watch these ~@karpathy videos on YouTube, where he explains how to use LLMs to generate code, and you will see that he is not even trying to hide the fact that this is just a glorified autocomplete, and only creates a very convincing illusion of “thinking” and “reasoning”.\nBTW, the infamous “Turing Test”, which is based on “cannot tell the difference whether it is a human or a machine”, turned out to be a naive bullshit, suitable only for Liberal Arts majors and people who use the word “creative” way too often, and this is not a test of “intelligence” at all, but just a test of good-enough, convincing illusion (the ancient “fundamental” Maya, if you will).\nThe problem, however, is that the slop would be accepted and chosen over actual life-long painfully-attained expertise, based on excessive reading (which takes a lot of time), intelligent analysis and actual experience. No one needs all this anymore, when the slop is cheap and almost useful.\nI could go on about the “crappy books” industry, and these narcissistic “Cal Newports”, who, after coming up with a few good generalizations, keep producing streams of a subpar printend verbiage, not unlike these LLMs. I would see a webshit becoming even more bloated, even more verbose with the salad of necessary and redundant abstractions, which is now being generated by these LLMs, and which is now being accepted as a “knowledge work” and “expertise”. The problem is that something way worse that webshit or “calnewportism” is already a “New Normal”.\nAgain, while the programming syntax errors can be routinely caught by the tools, simple semantic errors can be caught by some low-paid H1Bs or even oursourced (with kickbacks) to somewhere in the third-world, the actual correctness of the code is not something that can be easily checked. Understanding cannot be outsourced, in principle. When it does, all we get is some form of a disaster, be it obesity (cell ’s chronic metabolic disorder) epidemics or something similar.\nThe real problem is in the low-effort “plain texts”, which nowadays they generate and send to each other without underlying understanding. There is no way to “mechanically” catch the subtle errors and “hallucinations” which only an actual expert can spot on. This ongoing accumulation of errors and hallucinations is what we call “enshittification of knowledge itself”, which is as bad as an actual “information loss”.\nAnd yes. all these “IMO gold-medal level” announcements are just manifestations of a very sophisticated and computationally intensive text-based cognitive illusion, no more, no less.\n",
  "wordCount" : "1067",
  "inLanguage": "en",
  "datePublished": "2025-08-02T00:00:00+05:45",
  "dateModified": "2025-08-02T18:46:22+05:45",
  "author":[{
    "@type": "Person",
    "name": "\u0026lt;lngnmn2@yahoo.com\u0026gt;"
  }],
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://lngnmn2.github.io/articles/the-knowledge-work-bubble/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Notes from the digital underground by Lngnmn",
    "logo": {
      "@type": "ImageObject",
      "url": "https://lngnmn2.github.io/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://lngnmn2.github.io/" accesskey="h" title="Notes from the digital underground by Lngnmn (Alt + H)">Notes from the digital underground by Lngnmn</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)" aria-label="Toggle theme">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://lngnmn2.github.io/about/" title="About me.">
                    <span>About me.</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      The Knowledge Work Bubble
    </h1>
    <div class="post-description">
        The end of the &#34;knowledge work&#34; as we know it.
  
    </div>
    <div class="post-meta"><span title='2025-08-02 00:00:00 +0545 +0545'>August 2, 2025</span>&nbsp;·&nbsp;<span>&amp;lt;lngnmn2@yahoo.com&amp;gt;</span>

</div>
  </header> 
  <div class="post-content"><p>We are living through a paradigmatic shift, the one described in the &ldquo;Scientific Revolution&rdquo; by Thomas Kuhn. As I mentioned many times, texts and even crappy code became very, very cheap, just like a processed junk-food or a low-effort street-food slop. This is the &ldquo;shift&rdquo; and the end of so-called &ldquo;knowledge work&rdquo; as we know it. At least this is the end of the pretentious &ldquo;knowledge work&rdquo;, when one just pretends to be an expert is social settings, using very straightforward verbal and non-verbal cues to signal their &ldquo;knowledge&rdquo; and &ldquo;expertise&rdquo;, just as a priest would do in the not so distant past.</p>
<p>Lots of people have already realized that good writing is a hard, labour-intensive work, which is now being replaced by a nearly zero-cost AI-generated slop.  Just like a pretentious writing by an imposer, the AI-generated slop is often too abstract and too general, the proverbal &ldquo;hand-waving&rdquo; and a &ldquo;word salad&rdquo;, which is, again, goes back to doctrinal and dogmatic texts and speeches, which very few people could understand to be an utter made-believe bullshit.</p>
<p>Good writing is as hard as writing a quality mathematical proofs, meaningful poetry (which actually captures something worthy in a beautiful form) or even a prose &ndash; something after reading which other people would overwhelmingly say &ldquo;wow&rdquo;. We all knew some good writers from the golden age of the English Fiction, at least some very good parts of some good books.</p>
<p>With the source code the criteria are even simpler &ndash; it has to be <em>correct</em>, just like any written mathematics. Correctness is exactly where these probability-based LLMs are, in principle (and by definition of the underlying algorithms), inherently bad. And <em>this very correctness</em>  is exactly what we expect and want from them, and <em>being correct</em> (without errors) is precisely what a non-bullshit &ldquo;knowledge work&rdquo; is all about.</p>
<p>Nowadays, however, what would pass  as a &ldquo;knowledge&rdquo; is just a exuberant verbiage about the subject in general, almost always with some references to &ldquo;limitations of rigorous sciences&rdquo; and difficulties (and the costs) of conducting  properly designed, <em>reproducible experiments/</em>, which, just like proper mathematical proofs, are necessary, and never optional.</p>
<p>All these modern media formats, especially pop-sci podcasts (which make millions on product placements, narrative building  and plain ads) and crappy fast-print tech &ldquo;books&rdquo; are just manifestations of the &ldquo;knowledge work bubble&rdquo;, which is now bursting, just like the dot-com bubble in the early 2000s. The &ldquo;knowledge work&rdquo; is not a &ldquo;work&rdquo; at all, it is just a pretentious and often meaningless verbal and non-verbal signalling, which is now being replaced by AI-generated slop.</p>
<p>This is the paradigmatic shift, which is now happening, and it is not going to be reversed.</p>
<p>The question is, of course ~What To Be Done?-  <em>Now What?</em></p>
<p>Unlike mathematics with errors, a generated code with errors are &ldquo;almost right&rdquo; and &ldquo;acceptable&rdquo;, due to its near-zero costs. It has even a reasonable (and the only) use case &ndash; to generate a vebose boilerplate code of crappy, badly designed OO APIs, archaic and legacy (like Win32) or just stupid ones (as in webshit frameworks). Auto-completing such vebose crap (as per &ldquo;glorified autocomplete&rdquo;), even with occasional minor errors, is the only reasonable use case for these LLMs, which is not a &ldquo;knowledge&rdquo;, leave alone &ldquo;thinking&rdquo; or &ldquo;reasoning&rdquo; at all, but just, again, a <em>glorified autocomplete</em>.</p>
<p>Generating a boilerplate code and &ldquo;skeletons&rdquo; of modules (or verbose, over-abstracted class hierarchies) is a very real, measurable by all the common metrics, productivity boost &ndash; we just have to admit that this (and only this) is what keeps the gigantic unprecedented AI bubble from bursting, at least for now. Using several LLMs  &ldquo;in parallel&rdquo; to generate slop for the same prompt is even better, because it allows one to see the alternatives without being able to come up with them on their own, which is a very real productivity boost, too.</p>
<p>Go and watch these ~@karpathy videos on YouTube, where he explains how to use LLMs to generate code, and you will see that he is not even trying to hide the fact that this is just a glorified autocomplete, and only creates a very convincing illusion of &ldquo;thinking&rdquo; and &ldquo;reasoning&rdquo;.</p>
<p>BTW, the infamous &ldquo;Turing Test&rdquo;, which is based on &ldquo;cannot tell the difference whether it is a human or a machine&rdquo;, turned out to be a naive bullshit, suitable only for Liberal Arts majors and people who use the word &ldquo;creative&rdquo; way too often, and this  is not a test of &ldquo;intelligence&rdquo; at all, but just a test of good-enough, convincing illusion (the ancient &ldquo;fundamental&rdquo; Maya, if you will).</p>
<p>The problem, however, is that the slop would be accepted and chosen over actual life-long painfully-attained expertise, based on excessive reading (which takes <em>a lot</em> of time), intelligent analysis and actual experience. No one needs all this anymore, when the slop is cheap and almost useful.</p>
<p>I could go on about the &ldquo;crappy books&rdquo; industry, and these narcissistic &ldquo;Cal Newports&rdquo;, who, after coming up with a few good generalizations, keep producing streams of a subpar printend verbiage, not unlike these  LLMs. I would see a webshit becoming even more bloated, even more verbose with the salad of necessary and redundant abstractions, which is now being generated by these LLMs, and which is now being accepted as a &ldquo;knowledge work&rdquo; and &ldquo;expertise&rdquo;. The problem is that something way worse that webshit or &ldquo;calnewportism&rdquo;  is already a &ldquo;New Normal&rdquo;.</p>
<p>Again, while the programming syntax errors can be routinely caught by the tools, simple semantic errors can be caught by some low-paid H1Bs or even oursourced (with kickbacks) to somewhere in the third-world,  the actual correctness of the code is not something that can be easily checked. Understanding cannot be outsourced, in principle. When it does, all we get is some form of a disaster, be it obesity (cell &rsquo;s chronic metabolic disorder)  epidemics or something similar.</p>
<p>The real problem is in the low-effort &ldquo;plain texts&rdquo;,  which nowadays they generate and send to each other without underlying understanding. There is no way to &ldquo;mechanically&rdquo; catch the subtle errors and &ldquo;hallucinations&rdquo; which only an actual expert can spot on. This ongoing accumulation of errors and hallucinations is what we call &ldquo;enshittification of knowledge itself&rdquo;, which is as bad as an actual &ldquo;information loss&rdquo;.</p>
<p>And yes. all these &ldquo;IMO gold-medal level&rdquo; announcements are just manifestations of a very sophisticated and computationally intensive <em>text-based cognitive illusion</em>, no more, no less.</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://lngnmn2.github.io/tags/ai/">AI</a></li>
      <li><a href="https://lngnmn2.github.io/tags/llm/">LLM</a></li>
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2025 <a href="https://lngnmn2.github.io/">Notes from the digital underground by Lngnmn</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
